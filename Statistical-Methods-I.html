<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Introduction to Statistical Methodology, Second Edition</title>
  <meta name="description" content="Introduction to Statistical Methodology, Second Edition" />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Introduction to Statistical Methodology, Second Edition" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="dereksonderegger/570_II" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Statistical Methodology, Second Edition" />
  
  
  

<meta name="author" content="Derek L. Sonderegger &amp; Robert Buscaglia" />


<meta name="date" content="2019-08-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Introduction to Statistical Methodology, Second Edition</h1>
<p class="author"><em>Derek L. Sonderegger &amp; Robert Buscaglia</em></p>
<p class="date"><em>August 27, 2019</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#preface">Preface</a><ul>
<li><a href="#acknowledgements">Acknowledgements</a></li>
</ul></li>
<li><a href="#summary-statistics-and-graphing"><span class="toc-section-number">1</span> Summary Statistics and Graphing</a><ul>
<li><a href="#graphical-summaries-of-data"><span class="toc-section-number">1.1</span> Graphical summaries of data</a><ul>
<li><a href="#univariate---categorical"><span class="toc-section-number">1.1.1</span> Univariate - Categorical</a></li>
<li><a href="#univariate---continuous"><span class="toc-section-number">1.1.2</span> Univariate - Continuous</a></li>
<li><a href="#bivariate---categorical-vs-continuous"><span class="toc-section-number">1.1.3</span> Bivariate - Categorical vs Continuous</a></li>
<li><a href="#bivariate---continuous-vs-continuous"><span class="toc-section-number">1.1.4</span> Bivariate - Continuous vs Continuous</a></li>
</ul></li>
<li><a href="#measures-of-centrality"><span class="toc-section-number">1.2</span> Measures of Centrality</a><ul>
<li><a href="#mean"><span class="toc-section-number">1.2.1</span> Mean</a></li>
<li><a href="#median"><span class="toc-section-number">1.2.2</span> Median</a></li>
<li><a href="#mode"><span class="toc-section-number">1.2.3</span> Mode</a></li>
<li><a href="#examples"><span class="toc-section-number">1.2.4</span> Examples</a></li>
</ul></li>
<li><a href="#measures-of-spread"><span class="toc-section-number">1.3</span> Measures of Spread</a><ul>
<li><a href="#range"><span class="toc-section-number">1.3.1</span> Range</a></li>
<li><a href="#inter-quartile-range"><span class="toc-section-number">1.3.2</span> Inter-Quartile Range</a></li>
<li><a href="#variance"><span class="toc-section-number">1.3.3</span> Variance</a></li>
<li><a href="#standard-deviation"><span class="toc-section-number">1.3.4</span> Standard Deviation</a></li>
<li><a href="#coefficient-of-variation"><span class="toc-section-number">1.3.5</span> Coefficient of Variation</a></li>
<li><a href="#empirical-rule-of-thumb"><span class="toc-section-number">1.3.6</span> Empirical Rule of Thumb</a></li>
</ul></li>
<li><a href="#shape"><span class="toc-section-number">1.4</span> Shape</a><ul>
<li><a href="#symmetry"><span class="toc-section-number">1.4.1</span> Symmetry</a></li>
<li><a href="#unimodal-or-multi-modal"><span class="toc-section-number">1.4.2</span> Unimodal or Multi-modal</a></li>
<li><a href="#skew"><span class="toc-section-number">1.4.3</span> Skew</a></li>
</ul></li>
<li><a href="#exercises"><span class="toc-section-number">1.5</span> Exercises</a></li>
</ul></li>
<li><a href="#probability"><span class="toc-section-number">2</span> Probability</a><ul>
<li><a href="#introduction-to-set-theory"><span class="toc-section-number">2.1</span> Introduction to Set Theory</a><ul>
<li><a href="#composition-of-events"><span class="toc-section-number">2.1.1</span> Composition of events</a></li>
</ul></li>
<li><a href="#probability-rules"><span class="toc-section-number">2.2</span> Probability Rules</a><ul>
<li><a href="#simple-rules"><span class="toc-section-number">2.2.1</span> Simple Rules</a></li>
<li><a href="#conditional-probability"><span class="toc-section-number">2.2.2</span> Conditional Probability</a></li>
<li><a href="#summary-of-probability-rules"><span class="toc-section-number">2.2.3</span> Summary of Probability Rules</a></li>
</ul></li>
<li><a href="#discrete-random-variables"><span class="toc-section-number">2.3</span> Discrete Random Variables</a><ul>
<li><a href="#introduction-to-discrete-random-variables"><span class="toc-section-number">2.3.1</span> Introduction to Discrete Random Variables</a></li>
</ul></li>
<li><a href="#common-discrete-distributions"><span class="toc-section-number">2.4</span> Common Discrete Distributions</a><ul>
<li><a href="#binomial-distribution"><span class="toc-section-number">2.4.1</span> Binomial Distribution</a></li>
<li><a href="#poisson-distribution"><span class="toc-section-number">2.4.2</span> Poisson Distribution</a></li>
</ul></li>
<li><a href="#continuous-random-variables"><span class="toc-section-number">2.5</span> Continuous Random Variables</a><ul>
<li><a href="#uniform01-distribution"><span class="toc-section-number">2.5.1</span> Uniform(0,1) Distribution</a></li>
<li><a href="#exponential-distribution"><span class="toc-section-number">2.5.2</span> Exponential Distribution</a></li>
<li><a href="#normal-distribution"><span class="toc-section-number">2.5.3</span> Normal Distribution</a></li>
<li><a href="#standardizing"><span class="toc-section-number">2.5.4</span> Standardizing</a></li>
</ul></li>
<li><a href="#exercises-1"><span class="toc-section-number">2.6</span> Exercises</a></li>
</ul></li>
<li><a href="#confidence-intervals-via-bootstrapping"><span class="toc-section-number">3</span> Confidence Intervals via Bootstrapping</a><ul>
<li><a href="#theory-of-bootstrapping"><span class="toc-section-number">3.1</span> Theory of Bootstrapping</a></li>
<li><a href="#quantile-based-confidence-intervals"><span class="toc-section-number">3.2</span> Quantile-based Confidence Intervals</a></li>
<li><a href="#exercises-2"><span class="toc-section-number">3.3</span> Exercises</a></li>
</ul></li>
<li><a href="#sampling-distribution-of-barx"><span class="toc-section-number">4</span> Sampling Distribution of <span class="math inline">\(\bar{X}\)</span></a><ul>
<li><a href="#enlightening-example"><span class="toc-section-number">4.1</span> Enlightening Example</a></li>
<li><a href="#mathematical-details"><span class="toc-section-number">4.2</span> Mathematical details</a><ul>
<li><a href="#probability-rules-for-expectations-and-variances"><span class="toc-section-number">4.2.1</span> Probability Rules for Expectations and Variances</a></li>
<li><a href="#mean-and-variance-of-the-sample-mean"><span class="toc-section-number">4.2.2</span> Mean and Variance of the Sample Mean</a></li>
</ul></li>
<li><a href="#distribution-of-barx"><span class="toc-section-number">4.3</span> Distribution of <span class="math inline">\(\bar{X}\)</span></a></li>
<li><a href="#central-limit-theorem"><span class="toc-section-number">4.4</span> Central Limit Theorem</a></li>
<li><a href="#exercises-3"><span class="toc-section-number">4.5</span> Exercises</a></li>
</ul></li>
<li><a href="#confidence-intervals-for-mu"><span class="toc-section-number">5</span> Confidence Intervals for <span class="math inline">\(\mu\)</span></a><ul>
<li><a href="#asymptotic-result-sigma-known"><span class="toc-section-number">5.1</span> Asymptotic result (<span class="math inline">\(\sigma\)</span> known)</a></li>
<li><a href="#asymptotoic-result-sigma-unknown"><span class="toc-section-number">5.2</span> Asymptotoic result (<span class="math inline">\(\sigma\)</span> unknown)</a></li>
<li><a href="#sample-size-selection"><span class="toc-section-number">5.3</span> Sample Size Selection</a></li>
<li><a href="#exercises-4"><span class="toc-section-number">5.4</span> Exercises</a></li>
</ul></li>
<li><a href="#hypothesis-tests-for-the-mean-of-a-population"><span class="toc-section-number">6</span> Hypothesis Tests for the mean of a population</a><ul>
<li><a href="#writing-hypotheses"><span class="toc-section-number">6.1</span> Writing Hypotheses</a><ul>
<li><a href="#null-and-alternative-hypotheses"><span class="toc-section-number">6.1.1</span> Null and alternative hypotheses</a></li>
<li><a href="#error"><span class="toc-section-number">6.1.2</span> Error</a></li>
<li><a href="#why-should-hypotheses-use-mu-and-not-barx"><span class="toc-section-number">6.1.3</span> Why should hypotheses use <span class="math inline">\(\mu\)</span> and not <span class="math inline">\(\bar{x}\)</span>?</a></li>
<li><a href="#calculating-p-values"><span class="toc-section-number">6.1.4</span> Calculating p-values</a></li>
<li><a href="#calculating-p-values-vs-cutoff-values"><span class="toc-section-number">6.1.5</span> Calculating p-values vs cutoff values</a></li>
<li><a href="#t-tests-in-r"><span class="toc-section-number">6.1.6</span> t-tests in R</a></li>
</ul></li>
<li><a href="#type-i-and-type-ii-errors"><span class="toc-section-number">6.2</span> Type I and Type II Errors</a><ul>
<li><a href="#power-and-sample-size-selection"><span class="toc-section-number">6.2.1</span> Power and Sample Size Selection</a></li>
</ul></li>
<li><a href="#exercises-5"><span class="toc-section-number">6.3</span> Exercises</a></li>
</ul></li>
<li><a href="#two-sample-hypothesis-tests-and-confidence-intervals"><span class="toc-section-number">7</span> Two-Sample Hypothesis Tests and Confidence Intervals</a><ul>
<li><a href="#difference-in-means-between-two-groups"><span class="toc-section-number">7.1</span> Difference in means between two groups</a><ul>
<li><a href="#inference-via-resampling"><span class="toc-section-number">7.1.1</span> Inference via resampling</a></li>
<li><a href="#inference-via-asymptotic-results-unequal-variance-assumption"><span class="toc-section-number">7.1.2</span> Inference via asymptotic results (unequal variance assumption)</a></li>
<li><a href="#inference-via-asymptotic-results-equal-variance-assumption"><span class="toc-section-number">7.1.3</span> Inference via asymptotic results (equal variance assumption)</a></li>
</ul></li>
<li><a href="#difference-in-means-between-two-groups-paired-data"><span class="toc-section-number">7.2</span> Difference in means between two groups: Paired Data</a></li>
<li><a href="#exercises-6"><span class="toc-section-number">7.3</span> Exercises</a></li>
</ul></li>
<li><a href="#testing-model-assumptions"><span class="toc-section-number">8</span> Testing Model Assumptions</a><ul>
<li><a href="#testing-normality"><span class="toc-section-number">8.1</span> Testing Normality</a><ul>
<li><a href="#visual-inspection---qqplots"><span class="toc-section-number">8.1.1</span> Visual Inspection - QQplots</a></li>
<li><a href="#tests-for-normality"><span class="toc-section-number">8.1.2</span> Tests for Normality</a></li>
</ul></li>
<li><a href="#testing-equal-variance"><span class="toc-section-number">8.2</span> Testing Equal Variance</a><ul>
<li><a href="#visual-inspection"><span class="toc-section-number">8.2.1</span> Visual Inspection</a></li>
<li><a href="#tests-for-equal-variance"><span class="toc-section-number">8.2.2</span> Tests for Equal Variance</a></li>
<li><a href="#symmetry-of-the-f-distribution"><span class="toc-section-number">8.2.3</span> Symmetry of the F-distribution</a></li>
</ul></li>
<li><a href="#power-of-the-f-test"><span class="toc-section-number">8.3</span> Power of the F-test</a></li>
<li><a href="#theoretical-distribution-vs-bootstrap"><span class="toc-section-number">8.4</span> Theoretical distribution vs bootstrap</a></li>
<li><a href="#exercises-7"><span class="toc-section-number">8.5</span> Exercises</a></li>
</ul></li>
<li><a href="#analysis-of-variance-anova"><span class="toc-section-number">9</span> Analysis of Variance (ANOVA)</a><ul>
<li><a href="#model"><span class="toc-section-number">9.1</span> Model</a></li>
<li><a href="#theory"><span class="toc-section-number">9.2</span> Theory</a><ul>
<li><a href="#anova-table"><span class="toc-section-number">9.2.1</span> Anova Table</a></li>
<li><a href="#anova-using-simple-vs-complex-models."><span class="toc-section-number">9.2.2</span> ANOVA using Simple vs Complex models.</a></li>
<li><a href="#parameter-estimates-and-confidence-intervals"><span class="toc-section-number">9.2.3</span> Parameter Estimates and Confidence Intervals</a></li>
</ul></li>
<li><a href="#anova-in-r"><span class="toc-section-number">9.3</span> Anova in R</a></li>
<li><a href="#multiple-comparisons"><span class="toc-section-number">9.4</span> Multiple comparisons</a></li>
<li><a href="#different-model-representations"><span class="toc-section-number">9.5</span> Different Model Representations</a><ul>
<li><a href="#theory-1"><span class="toc-section-number">9.5.1</span> Theory</a></li>
<li><a href="#model-representations-in-r"><span class="toc-section-number">9.5.2</span> Model Representations in R</a></li>
<li><a href="#implications-on-the-anova-table"><span class="toc-section-number">9.5.3</span> Implications on the ANOVA table</a></li>
</ul></li>
<li><a href="#exercises-8"><span class="toc-section-number">9.6</span> Exercises</a></li>
</ul></li>
<li><a href="#regression"><span class="toc-section-number">10</span> Regression</a><ul>
<li><a href="#pearsons-correlation-coefficient"><span class="toc-section-number">10.1</span> Pearson’s Correlation Coefficient</a></li>
<li><a href="#model-theory"><span class="toc-section-number">10.2</span> Model Theory</a><ul>
<li><a href="#anova-interpretation"><span class="toc-section-number">10.2.1</span> Anova Interpretation</a></li>
<li><a href="#confidence-intervals-vs-prediction-intervals"><span class="toc-section-number">10.2.2</span> Confidence Intervals vs Prediction Intervals</a></li>
</ul></li>
<li><a href="#extrapolation"><span class="toc-section-number">10.3</span> Extrapolation</a></li>
<li><a href="#checking-model-assumptions"><span class="toc-section-number">10.4</span> Checking Model Assumptions</a></li>
<li><a href="#common-problems"><span class="toc-section-number">10.5</span> Common Problems</a><ul>
<li><a href="#influential-points"><span class="toc-section-number">10.5.1</span> Influential Points</a></li>
<li><a href="#transformations"><span class="toc-section-number">10.5.2</span> Transformations</a></li>
</ul></li>
<li><a href="#exercises-9"><span class="toc-section-number">10.6</span> Exercises</a></li>
</ul></li>
<li><a href="#resampling-linear-models"><span class="toc-section-number">11</span> Resampling Linear Models</a><ul>
<li><a href="#using-lm-for-many-analyses"><span class="toc-section-number">11.1</span> Using <code>lm()</code> for many analyses</a><ul>
<li><a href="#one-sample-t-tests"><span class="toc-section-number">11.1.1</span> One-sample t-tests</a></li>
<li><a href="#two-sample-t-tests"><span class="toc-section-number">11.1.2</span> Two-sample t-tests</a></li>
</ul></li>
<li><a href="#creating-simulated-data"><span class="toc-section-number">11.2</span> Creating Simulated Data</a><ul>
<li><a href="#observational-studies-vs-designed-experiments"><span class="toc-section-number">11.2.1</span> Observational Studies vs Designed Experiments</a></li>
</ul></li>
<li><a href="#confidence-interval-types"><span class="toc-section-number">11.3</span> Confidence Interval Types</a><ul>
<li><a href="#normal-intervals"><span class="toc-section-number">11.3.1</span> Normal intervals</a></li>
<li><a href="#percentile-intervals"><span class="toc-section-number">11.3.2</span> Percentile intervals</a></li>
<li><a href="#basic-intervals"><span class="toc-section-number">11.3.3</span> Basic intervals</a></li>
<li><a href="#towards-bias-corrected-and-accelerated-intervals-bca"><span class="toc-section-number">11.3.4</span> Towards bias-corrected and accelerated intervals (BCa)</a></li>
</ul></li>
<li><a href="#bootstrap-confidence-intervals-in-r"><span class="toc-section-number">11.4</span> Bootstrap Confidence Intervals in R</a><ul>
<li><a href="#using-carboot-function"><span class="toc-section-number">11.4.1</span> Using <code>car::Boot()</code> function</a></li>
<li><a href="#using-the-boot-package"><span class="toc-section-number">11.4.2</span> Using the <code>boot</code> package</a></li>
</ul></li>
<li><a href="#exercises-10"><span class="toc-section-number">11.5</span> Exercises</a></li>
</ul></li>
<li><a href="#contingency-tables"><span class="toc-section-number">12</span> Contingency Tables</a><ul>
<li><a href="#expected-counts"><span class="toc-section-number">12.1</span> Expected Counts</a></li>
<li><a href="#hypothesis-testing"><span class="toc-section-number">12.2</span> Hypothesis Testing</a></li>
<li><a href="#rxc-tables"><span class="toc-section-number">12.3</span> RxC tables</a></li>
</ul></li>
<li><a href="#r-we-will-use-a-function-from-the-package-fifer-chisq.post.hoc-wants-the-table-arranged-with-the-factor-you-want-to-pairwise-contasts-as-the-rows-t-tab-transpose-the-rows-and-columns-result---fiferchisq.post.hoc-ttab-testchisq.test-simulate.p.valuetrue-b10000-result"><span class="toc-section-number">13</span> <code>{r} # # # We will use a function from the package fifer # # # chisq.post.hoc  wants the table arranged with the  # # # factor you want to pairwise contasts as the rows # # t( tab )   # transpose the rows and columns # # result &lt;- fifer::chisq.post.hoc( t(tab), # #     test=chisq.test, simulate.p.value=TRUE, B=10000 )  # # result #</code></a></li>
<li><a href="#r-we-really-want-to-get-the-compact-letter-display-for-graphing-purposes-but-there-is-some-annoying-details-that-we-really-ought-not-have-to-think-about.-so-lets-make-a-little-function-to-handle-this-stuff.-librarydplyr-librarystringr-librarymultcompview-cld.chisq.post.hoc---function-obj-name-p.values---objadj.p-just-the-p-values-contrasts---objcomparison-as.character-str_replace-patternfixed-vs.-replacement-fixed--namesp.values---contrasts-finally-we-can-pass-p.values-into-a-letters-function-my.letters---multcompviewmultcomplettersp.values-letter.df---data.frame-tempnamesmy.lettersletters-.group-my.lettersletters-colnamesletter.df1---name-rownamesletter.df---null-returnletter.df"><span class="toc-section-number">14</span> <code>{r} # # We really want to get the compact letter display for  # # graphing purposes, but there is some annoying details # # that we really ought not have to think about.  So lets # # make a little function to handle this stuff. # library(dplyr) # library(stringr) # library(multcompView) # # cld.chisq.post.hoc &lt;- function( obj, name ){ # #   p.values &lt;- obj$adj.p                # just the p-values # #   contrasts &lt;- obj$comparison %&gt;% # #     as.character( ) %&gt;% # #     str_replace( pattern=fixed(' vs. '), replacement = fixed('-')) # #   names(p.values) &lt;- contrasts # #  # #   # finally we can pass p.values into a letters function # #   my.letters &lt;- multcompView::multcompLetters(p.values) # #   letter.df &lt;- data.frame( TEMP=names(my.letters$Letters),  # #                            .group = my.letters$Letters )  # #   colnames(letter.df)[1] &lt;- name # #   rownames(letter.df) &lt;- NULL # #   return(letter.df) # # }   #</code></a></li>
<li><a href="#r-cld.chisq.post.hocresult-race"><span class="toc-section-number">15</span> <code>{r} # cld.chisq.post.hoc(result, 'Race') #</code></a><ul>
<li><a href="#exercises-11"><span class="toc-section-number">15.1</span> Exercises</a></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistical Methodology, Second Edition</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<p>These notes were originally written for an introductory statistics course for grad students in the physical sciences.</p>
<p>The problem with most introductory statistics courses is that they don’t prepare the student for the use of advanced statistics. Rote hand calculation is easy to test, easy to grade, and easy for students to learn to do, but is useless for actually understanding how to apply statistics. Since students pursuing a Ph.D. will likely be using statistics for the rest of their professional careers, we feel that this sort of course should attempt to steer away from a “cookbook” undergraduate pedagogy, and give the student enough theoretical background to continue their statistical studies at a high level while staying away from the painful mathematical details that statisticians must work through.</p>
<p>Statistical software has progressed by leaps and bounds over the last decades. Scientists need access to reliable software that is flexible enough to handle new problems, with minimal headaches. R has become a widely used, and extremely robust Open Source platform for statistical computing and most new methodologies will appear in R before being incorporated into commercial software. Second, data exploration is the first step of any analysis and a user friendly yet powerful mechanism for graphing is a critical component in a researchers toolbox. R succeeds in this area with the most flexible graphing library of any statistical software and and basic plotting that can be executed quickly and easily. The only downside is that there is a substantial learning curve to scripting, particularly for students without any programming background. The use of R software is introduced with as little pain as possible, but some frustration is inevitable.</p>
<p>Because the mathematical and statistical background of physical science students varies widely, the course seems to have a split-personality disorder. We wish to talk about using calculus to maximize the likelihood function and define the expectation of a continuous random variable, but also must spend time defining how to calculate a mean. We attempt to address both audiences, but recognize that it is not ideal.</p>
<p>We hope you’ll find these notes useful.</p>
<div id="acknowledgements" class="section level2 unnumbered">
<h2>Acknowledgements</h2>
<p><em>Derek Sonderegger</em>: I have had the pleasure of interacting with a great number of talented mathematicians and statisticians in my schooling. In particular I am deeply indebted to Dr Robert Boik and Dr Warren Esty as well as my Ph.D. adviser Dr Jan Hannig.</p>
<p>As a professor at Northern Arizona University, I am grateful for the feedback and comradery of my fellow statisticians, particularly Dr St. Laurent and Dr. Buscaglia.</p>
<p>Finally, I am deeply appreciative of the support given to me by my wife, Aubrey.</p>
<p><em>Robert Buscaglia</em>: I am thankful for Dr. Sonderegger allowing me to be a part of this online textbook. I would like to thank my graduate advisers, Dr. Jonathan B. Chaires and Dr. Yiannis Kamarianakis, who helped me achieve my goal of becoming a professor at Northern Arizona University. I would also be lost without the patience and kindness I receive from my family, especially my caring wife, Kelly.</p>
<!--chapter:end:index.Rmd-->
</div>
</div>
<div id="summary-statistics-and-graphing" class="section level1">
<h1><span class="header-section-number">1</span> Summary Statistics and Graphing</h1>
<p>When confronted with a large amount of data, we seek to summarize the data into statistics that capture the essence of the data with as few numbers as possible. Graphing the data has a similar goal: to reduce the data to an image that represents all the key aspects of the raw data. In short, we seek to simplify the data in order to understand the trends while not obscuring important structure.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Every chapter, we will load all the librarys we will use at the beginning</span>
<span class="co"># of the chapter. These commands will start most every homework assignment</span>
<span class="co"># for this class, and likely, every R script you write.</span>
<span class="kw">library</span>(ggplot2)    <span class="co"># graphing functions</span>
<span class="kw">library</span>(dplyr)      <span class="co"># data summary tools</span>

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<p>For this chapter, we will consider data from a the 2005 Cherry Blossom 10 mile run that occurs in Washington DC. This data set has 8636 observations that includes the runners state of residence, official time (gun to finish, in seconds), net time (start line to finish, in seconds), age, and gender of the runners.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>( TenMileRace, <span class="dt">package=</span><span class="st">&#39;mosaicData&#39;</span>)
<span class="kw">head</span>(TenMileRace)   <span class="co"># examine the first few rows of the data</span></code></pre></div>
<pre><code>##   state time  net age sex
## 1    VA 6060 5978  12   M
## 2    MD 4515 4457  13   M
## 3    VA 5026 4928  13   M
## 4    MD 4229 4229  14   M
## 5    MD 5293 5076  14   M
## 6    VA 6234 5968  14   M</code></pre>
<p>In general, I often need to make a distinction between two types of data.</p>
<ul>
<li>Discrete (also called Categorical) data is data that can only take a small set of particular values. For example a college student’s grade can be either A, B, C, D, or F. A person’s sex can be only Male or Female.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Discrete data could also be numeric, for example a bird could lay 1, 2, 3, … eggs in a breeding season.</li>
</ul>
<ul>
<li>Continuous data is data that can take on an infinite number of numerical values. For example a person’s height could be 68 inches, 68.2 inches, 68.23212 inches.</li>
</ul>
<p>To decided if a data attribute is discrete or continuous, I often as “Does a fraction of a value make sense?” If so, then the data is continuous.</p>
<div id="graphical-summaries-of-data" class="section level2">
<h2><span class="header-section-number">1.1</span> Graphical summaries of data</h2>
<div id="univariate---categorical" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Univariate - Categorical</h3>
<p>If we have univariate data about a number of groups, often the best way to display it is using barplots. They have the advantage over pie-charts that groups are easily compared.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>sex)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>()</code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>One thing that can be misleading is if the zero on the y-axis is removed. In the following graph it looks like there are twice as many female runners as male until you examine the y-axis closely. In general, the following is a very misleading graph.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>sex)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">4300</span>, <span class="dv">4330</span>))</code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="univariate---continuous" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Univariate - Continuous</h3>
<p>A histogram looks very similar to a bar plot, but is used to represent continuous data instead of categorical and therefore the bars will actually be touching.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>net)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>()</code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Often when a histogram is presented, the y-axis is labeled as “frequency” or “count” which is the number of observations that fall within a particular bin. However, it is often desirable to scale the y-axis so that if we were to sum up the area <span class="math inline">\((height * width)\)</span> then the total area would sum to 1. The re-scaling that accomplishes this is <span class="math display">\[density=\frac{\#\;observations\;in\;bin}{total\;number\;observations}\cdot\frac{1}{bin\;width}\]</span></p>
</div>
<div id="bivariate---categorical-vs-continuous" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Bivariate - Categorical vs Continuous</h3>
<p>We often wish to compare response levels from two or more groups of interest. To do this, we often use side-by-side boxplots. Notice that each observation is associated with a continuous response value and a categorical value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>sex, <span class="dt">y=</span>net)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>In this graph, the edges of the box are defined by the 25% and 75% percentiles. That is to say, 25% of the data is to the below of the box, 50% of the data is in the box, and the final 25% of the data is to the above of the box. The line in the center of the box represents the 50% percentile. The dots are data points that traditionally considered outliers. We will define the Inter-Quartile Range (IQR) as the length of the box. It is conventional to define any observation more than 1.5*IQR from the box as an considered an outlier. In the above graph it is easy to see that the median time for the males is lower than for females, but the box width (one measure of the spread of the data) is approximately the same.</p>
<p>Because boxplots simplify the distribution to just 5 numbers, looking at side-by-side histograms might give similar information.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>net)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>( . <span class="op">~</span><span class="st"> </span>sex )  <span class="co"># side-by-side plots based on sex</span></code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Orientation of graphs can certainly matter. In this case, it makes sense to stack the two graphs to facilitate comparisons in where the centers are and it is more obvious that the center of the female distribution is about 500 to 600 seconds higher than then center of the male distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>net)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>( sex <span class="op">~</span><span class="st"> </span>. )  <span class="co"># side-by-side plots based on sex</span></code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="bivariate---continuous-vs-continuous" class="section level3">
<h3><span class="header-section-number">1.1.4</span> Bivariate - Continuous vs Continuous</h3>
<p>Finally we might want to examine the relationship between two continuous random variables. For example, we might wish to explore the relationship between a runners age and their net time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TenMileRace, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>net, <span class="dt">color=</span>sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="measures-of-centrality" class="section level2">
<h2><span class="header-section-number">1.2</span> Measures of Centrality</h2>
<p>The most basic question to ask of any dataset is ‘What is the typical value?’ There are several ways to answer that question and they should be familiar to most students.</p>
<div id="mean" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Mean</h3>
<p>Often called the average, or arithmetic mean, we will denote this special statistic with a bar. We define <span class="math display">\[\bar{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}=\frac{1}{n}\left(x_{1}+x_{2}+\dots+x_{n}\right)\]</span></p>
<p>If we want to find the mean of five numbers <span class="math inline">\(\left\{ 3,6,4,8,2\right\}\)</span> the calculation is <span class="math display">\[\bar{x}   =   \frac{1}{5}\left(3+6+4+8+2\right)
    =   \frac{1}{5}\left(23\right)
    =   23/5
    =   4.6\]</span></p>
<p>This can easily be calculated in R by using the function <code>mean()</code>. We first extract the column we are interested in using the notation: <code>DataSet$ColumnName</code> where the $ signifies grabbing the column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TenMileRace$net  is the set of data to calculate the mean of. </span>
<span class="kw">mean</span>( TenMileRace<span class="op">$</span>net ) <span class="co"># Simplest way of doing this calculation</span></code></pre></div>
<pre><code>## [1] 5599.065</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Using the dplyr package we first specify the data set </span>
<span class="co"># Then specify we wish to summarize() the data set</span>
<span class="co"># The summary we want to do is to calculate the mean of the &#39;net&#39; column.</span>
<span class="co"># and we want to name what we are about to create as Calculated.Mean</span>
TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">Calculated.Mean =</span> <span class="kw">mean</span>(net) )  </code></pre></div>
<pre><code>##   Calculated.Mean
## 1        5599.065</code></pre>
</div>
<div id="median" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Median</h3>
<p>If the data were to be ordered, the median would be the middle most observation (or, in the case that <span class="math inline">\(n\)</span> is even, the mean of the two middle most values).</p>
<p>In our simple case of five observations <span class="math inline">\(\left\{ 3,6,4,8,2\right\}\)</span>, we first sort the data into <span class="math inline">\(\left\{ 2,3,4,6,8\right\}\)</span> and then the middle observation is clearly <span class="math inline">\(4\)</span>.</p>
<p>In R the median is easily calculated by the function <code>median()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the median() function to calculate the median for us.</span>
<span class="co"># median( TenMileRace$net )</span>
TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">Median =</span> <span class="kw">median</span>(net) ) </code></pre></div>
<pre><code>##   Median
## 1   5555</code></pre>
</div>
<div id="mode" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Mode</h3>
<p>This is peak in the distribution. A distribution might have a single peak or multiple peaks.This measure of “center” is not often used in quantitative analyses, but is often helps provide a nice description.</p>
<p>When creating a histogram from a set of data, often the choice of binwidth will affect the modes of the graph. Consider the following graphs of <span class="math inline">\(n=200\)</span> data points, where we have slightly different binwidths.</p>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>With the two smaller binwidths, sample randomness between adjacent bins obscures the overall shape and we have many different modes. However the <em>larger</em> binwidth results in a histogram that more effectively communicates the shape of the distribution and has just a single mode at around 6000 seconds (= 100 minutes = 1 hour 40 minutes). When making histograms the choice of binwidth (or equivalently, the number of bins) should not be ignored and a balance should be struck between simplifying the data too much vs seeing too much of the noise resulting from the sample randomess.</p>
</div>
<div id="examples" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Examples</h3>
<ul>
<li>Suppose a retired professor my father were to become bored and enroll into the the author’s STA 570 course, how would that affect the mean and median age of the STA 570 students?
<ul>
<li>The mean would move much more than the median. Suppose the class has 5 people right now, ages 21, 22, 23, 23, 24 and therefore the median is 23. When the retired professor joins, the ages will be 21, 22, 23, 23, 24, 72 and the median will remain 23. However, the mean would move because we add in such a large outlier. Whenever we are dealing with skewed data, the mean is pulled toward the outlying observations.</li>
</ul></li>
<li>In 2010 during a player’s strike in the NFL, the median NFL player salary was $770,000 while the mean salary was $1.9 million. Clearly the player’s union would talk about the median while the team owners prefered to talk about the mean. Why is there such a difference?
<ul>
<li>Because salary data contains outliers (e.g. superstar players with salaries in excess of 20 million) and the minimum salary for a rookie is $375,000. Financial data often reflects a highly skewed distribution and the median is often a better measure of centrality in these cases.</li>
</ul></li>
</ul>
</div>
</div>
<div id="measures-of-spread" class="section level2">
<h2><span class="header-section-number">1.3</span> Measures of Spread</h2>
<p>The second question to ask of a dataset is ‘How much spead is in the data?’ The fancier (and eventually more technical) word for spread is ‘variability’. As with centrality, there are several ways to measure this.</p>
<div id="range" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Range</h3>
<p>Range is the distance from the largest to the smallest value in the dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># max( TenMileRace$net ) - min( TenMileRace$net )</span>
TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">Range =</span> <span class="kw">max</span>(net) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(net) )</code></pre></div>
<pre><code>##   Range
## 1  7722</code></pre>
<p>In general, this method is highly sensitive to outlier observations and isn’t often used.</p>
</div>
<div id="inter-quartile-range" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Inter-Quartile Range</h3>
<p>The p-th percentile is the observation (or observations) that has at most <span class="math inline">\(p\)</span> percent of the observations below it and <span class="math inline">\((1-p)\)</span> above it, where <span class="math inline">\(p\)</span> is between 0 and 100. The median is the <span class="math inline">\(50\)</span>th percentile. Often we are interested in splitting the data into four equal sections using the <span class="math inline">\(25\)</span>th, <span class="math inline">\(50\)</span>th, and <span class="math inline">\(75\)</span>th percentiles (which, because it splits the data into four sections, we often call these the <span class="math inline">\(1\)</span>st, <span class="math inline">\(2\)</span>nd, and <span class="math inline">\(3\)</span>rd quartiles).</p>
<p>In general we could be interested in dividing the data up into an arbitrary number of sections, and refer to those as quantiles of my data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>( TenMileRace<span class="op">$</span>net ) <span class="co"># gives the 5-number summary by default</span></code></pre></div>
<pre><code>##    0%   25%   50%   75%  100% 
##  2814  4950  5555  6169 10536</code></pre>
<p>The inter-quartile range (IQR) is defined as the distance from the <span class="math inline">\(3\)</span>rd quartile to the <span class="math inline">\(1\)</span>st.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># IQR( TenMileRace$net )</span>
TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">CalcIQR =</span> <span class="kw">IQR</span>(net) ) </code></pre></div>
<pre><code>##   CalcIQR
## 1    1219</code></pre>
<p>Notice that we’ve defined IQR before when we looked at box-and-whisker plots and this is exactly the length of the box part of a box-and-whisker plot.</p>
</div>
<div id="variance" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Variance</h3>
<p>One way to measure the spread of a distribution is to ask “what is the typical distance of an observation to the mean?” We could define the <span class="math inline">\(i\)</span>th deviate as <span class="math display">\[e_{i}=x_{i}-\bar{x}\]</span> and then ask what is the average deviate? The problem with this approach is that the sum (and thus the average) of all deviates is always 0. <span class="math display">\[\sum_{i=1}^{n}(x_{i}-\bar{x}) =   \sum_{i=1}^{n}x_{i}-\sum_{i=1}^{n}\bar{x}
    =   n\frac{1}{n}\sum_{i=1}^{n}x_{i}-n\bar{x}
    =   n\bar{x}-n\bar{x}
    =   0\]</span></p>
<p>The big problem is that about half the deviates are negative and the others are positive. What we really care is the distance from the mean, not the sign. So we could either take the absolute value, or square it.</p>
<p>There are some really good theoretical reasons to chose the square option. Squared terms are easier to deal with compared to absolute values, but more importantly, the spread of the normal distribution is parameterized via squared distances from the mean. Because the normal distribution is so important, we’ve chosen to define the sample variance so it matches up with the natural spread parameter of the normal distribution. So we square the deviates and then find the average deviate size (approximately) and call that the sample variance. <span class="math display">\[s^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\]</span> Why do we divide by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>?</p>
<ol style="list-style-type: decimal">
<li>If we divide by <span class="math inline">\(n\)</span>, then on average, we would tend to underestimate the population variance <span class="math inline">\(\sigma^{2}\)</span>.</li>
<li>The reason is because we are using the same set of data to estimate <span class="math inline">\(\sigma^{2}\)</span> as we did to estimate the population mean (<span class="math inline">\(\mu\)</span>). If we could use<br />
<span class="math display">\[\frac{1}{n}\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}\]</span> as the estimator, we would be fine. But because we have to replace <span class="math inline">\(\mu\)</span> with <span class="math inline">\(\bar{x}\)</span> we have to pay a price.</li>
<li>Because the estimation of <span class="math inline">\(\sigma^{2}\)</span> requires the estimation of one other quantity, and using using that quantity, you only need <span class="math inline">\(n-1\)</span> data points and can then figure out the last one, we have used one degree of freedom on estimating the mean and we need to adjust the formula accordingly.</li>
</ol>
<p>In later chapters we’ll give this quantity a different name, so we’ll introduce the necessary vocabulary here. Let <span class="math inline">\(e_{i}=x_{i}-\bar{x}\)</span> be the error left after fitting the sample mean. This is the deviation from the observed value to the “expected value” <span class="math inline">\(\bar{x}\)</span>. We can then define the Sum of Squared Error as <span class="math display">\[SSE=\sum_{i=1}^{n}e_{i}^{2}\]</span> and the Mean Squared Error as <span class="math display">\[MSE=\frac{SSE}{df}=\frac{SSE}{n-1}=s^{2}\]</span> where <span class="math inline">\(df=n-1\)</span> is the appropriate degrees of freedom.</p>
<p>Calculating the variance of our small sample of five observations <span class="math inline">\(\left\{ 3,6,4,8,2\right\}\)</span>, recall that the sample mean was <span class="math inline">\(\bar{x}=4.6\)</span></p>
<table style="width:68%;">
<colgroup>
<col width="11%" />
<col width="27%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(x_i\)</span></th>
<th><span class="math inline">\((x_i-\bar{x})\)</span></th>
<th><span class="math inline">\((x_i-\bar{x})^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>3</p></td>
<td><pre><code>  -1.6</code></pre></td>
<td><p>2.56</p></td>
</tr>
<tr class="even">
<td><p>6</p></td>
<td><pre><code>   1.4</code></pre></td>
<td><p>1.96</p></td>
</tr>
<tr class="odd">
<td><p>4</p></td>
<td><pre><code>  -0.6</code></pre></td>
<td><p>0.36</p></td>
</tr>
<tr class="even">
<td><p>8</p></td>
<td><pre><code>   3.4</code></pre></td>
<td><p>11.56</p></td>
</tr>
<tr class="odd">
<td><p>2</p></td>
<td><pre><code>  -2.6</code></pre></td>
<td><p>6.76</p></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>SSE = 23.2</td>
</tr>
</tbody>
</table>
<p>and so the sample variance is <span class="math display">\[s^2 = \frac{SSE}{n-1} = \frac{23.2}{(n-1)} = \frac{23.2}{4}=5.8\]</span></p>
<p>Clearly this calculation would get very tedious to do by hand and computers will be much more accurate in these calculations. In R, the sample variance is easily calculated by the function <code>var()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ToyData &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">6</span>,<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">2</span>) )
<span class="co"># var( ToyData$x )</span>
ToyData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">s2 =</span> <span class="kw">var</span>(x) )</code></pre></div>
<pre><code>##    s2
## 1 5.8</code></pre>
<p>For the larger TenMileRace data set, the variance is just as easily calculated.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># var( TenMileRace$net )</span>
TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">s2 =</span> <span class="kw">var</span>(net) )</code></pre></div>
<pre><code>##         s2
## 1 940233.5</code></pre>
</div>
<div id="standard-deviation" class="section level3">
<h3><span class="header-section-number">1.3.4</span> Standard Deviation</h3>
<p>The biggest problem with the sample variance statistic is that the units are in the original units-squared. That means if you are looking at data about car fuel efficiency, then the values would be in mpg<span class="math inline">\(^{2}\)</span> which are units that I can’t really understand. The solution is to take the positive square root, which we will call the sample standard deviation. <span class="math display">\[s=\sqrt{s^{2}}\]</span> But why do we take the jog through through variance? Mathematically the variance is more useful and most distributions (such as the normal) are defined by the variance term. Practically though, standard deviation is easier to think about.</p>
<p>The sample standard deviation is important enough for R to have a function <code>sd()</code> that will calculate it for you.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># sd( TenMileRace$net )</span>
TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">s =</span> <span class="kw">sd</span>(net) )</code></pre></div>
<pre><code>##          s
## 1 969.6564</code></pre>
</div>
<div id="coefficient-of-variation" class="section level3">
<h3><span class="header-section-number">1.3.5</span> Coefficient of Variation</h3>
<p>Suppose we had a group of animals and the sample standard deviation of the animals lengths was 15 cm. If the animals were elephants, you would be amazed at their uniformity in size, but if they were insects, you would be astounded at the variability. To account for that, the coefficient of variation takes the sample standard deviation and divides by the absolute value of the sample mean (to keep everything positive)</p>
<p><span class="math display">\[CV=\frac{s}{\vert\bar{x}\vert}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">TenMileRace <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">s =</span> <span class="kw">sd</span>(net),
                           <span class="dt">xbar =</span> <span class="kw">mean</span>(net),
                           <span class="dt">cv =</span> s <span class="op">/</span><span class="st"> </span><span class="kw">abs</span>(xbar) )</code></pre></div>
<pre><code>##          s     xbar        cv
## 1 969.6564 5599.065 0.1731818</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Previously using dplyr notation didn&#39;t help too much, but if we wanted</span>
<span class="co"># to calculate the statistics separately for each sex, the dplyr solution</span>
<span class="co"># is MUCH easier.</span>
TenMileRace <span class="op">%&gt;%</span><span class="st">                     </span><span class="co"># Summarize the Ten Mile Race Data</span>
<span class="st">  </span><span class="kw">group_by</span>(sex) <span class="op">%&gt;%</span><span class="st">                 </span><span class="co"># Subsequent actions are done seperately </span>
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">xbar =</span> <span class="kw">mean</span>(net),      <span class="co">#    for each gender</span>
             <span class="dt">s    =</span> <span class="kw">sd</span>(net),        <span class="co">#</span>
             <span class="dt">cv   =</span> s <span class="op">/</span><span class="st"> </span><span class="kw">abs</span>(xbar) ) <span class="co"># Calculate three different summary stats</span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##   sex    xbar     s    cv
##   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 F     5916.  902. 0.152
## 2 M     5281.  930. 0.176</code></pre>
</div>
<div id="empirical-rule-of-thumb" class="section level3">
<h3><span class="header-section-number">1.3.6</span> Empirical Rule of Thumb</h3>
<p>For any mound-shaped sample of data the following is a reasonable rule of thumb:</p>
<table>
<thead>
<tr class="header">
<th align="center">Interval</th>
<th align="center">Approximate percent of Measurements</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\bar{x}\pm s\)</span></td>
<td align="center">68%</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\bar{x}\pm 2s\)</span></td>
<td align="center">95%</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\bar{x}\pm 3s\)</span></td>
<td align="center">99.7%</td>
</tr>
</tbody>
</table>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
</div>
<div id="shape" class="section level2">
<h2><span class="header-section-number">1.4</span> Shape</h2>
<p>We want to be able to describe the shape of a distribution and this section introduces the standard vocabulary.</p>
<div id="symmetry" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Symmetry</h3>
<p>A distribution is said to be symetric if there is a point along the x-axis (which we’ll call <span class="math inline">\(\mu\)</span>) which acts as a mirror and <span class="math inline">\(f( -|x-\mu| ) = f( |x-\mu| )\)</span>. In the following graphs, the point of symmetry is marked with a red line. <img src="01_Data_Summary_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>A distribution that is not symetric is said to be asymmetric.</p>
</div>
<div id="unimodal-or-multi-modal" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Unimodal or Multi-modal</h3>
<p>Recall one measure of centrality was mode. If there is just a single mode, then we refer to the distribution as unimodal. If there is two or more we would refer to it as bimodal or multi-modal.</p>
</div>
<div id="skew" class="section level3">
<h3><span class="header-section-number">1.4.3</span> Skew</h3>
<p>If a distribution has a heavier tail on one side or the other, we refer to it as a <em>skewed</em> distribution and the direction of the skew is towards the heavier tail. Usually (but not always), an asymmetric is skewed.</p>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
</div>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">1.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>O&amp;L 3.21. The ratio of DDE (related to DDT) to PCB concentrations in bird eggs has been shown to have had a number of biological implications. The ratio is used as an indication of the movement of contamination through the food chain. The paper “The ratio of DDE to PCB concentrations in Great Lakes herring gull eggs and its us in interpreting contaminants data” reports the following ratios for eggs collected at 13 study sites from the five Great Lakes. The eggs were collected from both terrestrial and aquatic feeding birds.</p>
<table>
<colgroup>
<col width="21%" />
<col width="78%" />
</colgroup>
<tbody>
<tr class="odd">
<td><p>Source Type</p></td>
<td><p>DDE to PCB Ratio</p></td>
</tr>
<tr class="even">
<td><p><strong>Terrestrial</strong></p></td>
<td><p>76.50, 6.03, 3.51, 9.96, 4.24, 7.74, 9.54, 41.70, 1.84, 2.5, 1.54</p></td>
</tr>
<tr class="odd">
<td><p><strong>Aquatic</strong></p></td>
<td><p>0.27, 0.61, 0.54, 0.14, 0.63, 0.23, 0.56, 0.48, 0.16, 0.18</p></td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>By hand, compute the mean and median separately for each type of feeder.</li>
<li>Using your results from part (a), comment on the relative sensitivity of the mean and median to extreme values in a data set.</li>
<li>Which measure, mean or median, would you recommend as the most appropriate measure of the DDE to PCB level for both types of feeders? Explain your answer.</li>
</ol></li>
<li><p>O&amp;L 3.31. Consumer Reports in its June 1998 issue reports on the typical daily room rate at six luxury and nine budget hotels. The room rates are given in the following table.</p>
<table>
<thead>
<tr class="header">
<th align="center">Hotel Type</th>
<th align="center">Nightly Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Luxury</td>
<td align="center">$175, $180, $120, $150, $120, $125</td>
</tr>
<tr class="even">
<td align="center">Budget</td>
<td align="center">$50, $50, $49, $45, $36, $45, $50, $50, $40</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>By hand, compute the means and standard deviations of the room rates for each class of hotel.</li>
<li>Give a practical reason why luxury hotels might have higher variability than the budget hotels. (Don’t just say the standard deviation is higher because there is more spread in the data, but rather think about the Hotel Industry and why you might see greater price variability for upscale goods compared to budget items.)</li>
</ol></li>
<li>Suppose that we have two groups of individuals, each with a mean value <span class="math inline">\(\bar{x}_i\)</span>. We wish to combine the two groups together and find the mean value for the combined group (denoted <span class="math inline">\(\bar{x}_c\)</span>).
<ol style="list-style-type: lower-alpha">
<li>Suppose <span class="math inline">\(n_1=1\)</span> and <span class="math inline">\(n_2=1\)</span> (i.e. there is one individual in each group) and the means of the two groups are <span class="math inline">\(\bar{x}_1 = 10\)</span> and <span class="math inline">\(\bar{x}_2=14\)</span>. What is the sum of the ages of indivuals in the combined group? What is the mean age of the combined group?</li>
<li>Suppose that <span class="math inline">\(n_1=50\)</span>? What is the mean age of the combined group?</li>
<li>Finally suppose that <span class="math inline">\(n_2=75\)</span>. What is the mean age of the combined group?</li>
<li>Write a formula for the weighted average of the mean of the combined group as <span class="math display">\[\bar{x}_c = w_1 \bar{x}_1 + w_2 \bar{x}_2 = \sum_{i=1}^2 w_i \bar{x}_i\]</span> by defining the group <em>weighting factors</em> <span class="math inline">\(w_i\)</span>.</li>
<li>Explain why the weights represent the relative contribution to the overall mean for each group.</li>
</ol></li>
<li><p>Use R to confirm your calculations in problem 1 (the pollution data). Show the code you used and the subsequent output. It will often be convenient for me to give you code that generates a data frame instead of uploading an Excel file and having you read it in. The data can be generated using the following commands:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">PolutionRatios &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Ratio =</span> <span class="kw">c</span>(<span class="fl">76.50</span>, <span class="fl">6.03</span>, <span class="fl">3.51</span>, <span class="fl">9.96</span>, <span class="fl">4.24</span>, <span class="fl">7.74</span>, <span class="fl">9.54</span>, <span class="fl">41.70</span>, <span class="fl">1.84</span>, <span class="fl">2.5</span>, <span class="fl">1.54</span>,
             <span class="fl">0.27</span>, <span class="fl">0.61</span>, <span class="fl">0.54</span>, <span class="fl">0.14</span>, <span class="fl">0.63</span>, <span class="fl">0.23</span>, <span class="fl">0.56</span>,  <span class="fl">0.48</span>, <span class="fl">0.16</span>, <span class="fl">0.18</span>       ),
  <span class="dt">Type  =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;Terrestrial&#39;</span>,<span class="dv">11</span>), <span class="kw">rep</span>(<span class="st">&#39;Aquatic&#39;</span>,<span class="dv">10</span>) ) )

<span class="co"># Print out some of the data to confirm what the column names are</span>
<span class="kw">head</span>( PolutionRatios )</code></pre></div>
<pre><code>##   Ratio        Type
## 1 76.50 Terrestrial
## 2  6.03 Terrestrial
## 3  3.51 Terrestrial
## 4  9.96 Terrestrial
## 5  4.24 Terrestrial
## 6  7.74 Terrestrial</code></pre>
<p><em>Hint: for computing the means and medians for each type of feeder separately, the <code>group_by()</code> command we demonstated earlier in the chapter is convenient.</em></p></li>
<li><p>Use R to confirm your calculations in problem 2 (the hotel data). Show the code you used and the subsequent output. The data can be loaded into a data frame using the following commands Show the code you used and the subsequent output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hotels &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Price =</span> <span class="kw">c</span>(<span class="dv">175</span>, <span class="dv">180</span>, <span class="dv">120</span>, <span class="dv">150</span>, <span class="dv">120</span>, <span class="dv">125</span>, <span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">49</span>, <span class="dv">45</span>, <span class="dv">36</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">40</span>),
  <span class="dt">Type  =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;Luxury&#39;</span>,<span class="dv">6</span>),  <span class="kw">rep</span>(<span class="st">&#39;Budget&#39;</span>, <span class="dv">9</span>) ) )

<span class="co"># Print out some of the data to confirm what the column names are</span>
<span class="kw">head</span>( Hotels )</code></pre></div>
<pre><code>##   Price   Type
## 1   175 Luxury
## 2   180 Luxury
## 3   120 Luxury
## 4   150 Luxury
## 5   120 Luxury
## 6   125 Luxury</code></pre></li>
<li><p>For the hotel data, create side-by-side box-and-whisker plots to compare the prices.</p></li>
<li><p>Match the following histograms to the appropriate boxplot.</p>
<p><img src="01_Data_Summary_files/figure-html/unnamed-chunk-27-1.png" width="672" /> <img src="01_Data_Summary_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<ol style="list-style-type: lower-alpha">
<li>Histogram A goes with boxplot __________</li>
<li>Histogram B goes with boxplot __________</li>
<li>Histogram C goes with boxplot __________</li>
<li>Histogram D goes with boxplot __________</li>
</ol></li>
<li><p>Twenty-five employees of a corporation have a mean salary of $62,000 and the sample standard deviation of those salaries is $15,000. If each employee receives a bonus of $1,000, does the standard deviation of the salaries change? Explain your reasoning.</p></li>
<li><p>Histograms of the salaries of two corportations. They have the same mean salary, but very different shapes. Use the shape of the distributions to justify which has a lower median salary.</p></li>
<li><p>The chemicals in clay used to make pottery can differ depending on the geographical region where the clay originated. Sometimes, archaeologists use a chemical analysis of clay to help identify where a piece of pottery originated. Such an analysis measures the amount of a chemical in the clay as a percent of the total weight of the piece of pottery. The boxplots below summarize analyses done for three chemicals—X, Y, and Z—on pieces of pottery that originated at one of three sites: I, II, or III.</p>
<img src="01_Data_Summary_files/figure-html/unnamed-chunk-29-1.png" width="672" />
<ol style="list-style-type: lower-alpha">
<li>For chemical Z, describe how the percents found in the pieces of pottery are similar and how they differ among the three sites.</li>
<li>Consider a piece of pottery known to have originated at one of the three sites, but the actual site is not known.
<ol style="list-style-type: lower-roman">
<li>Suppose an analysis of the clay reveals that the sum of the percents of the three chemicals X, Y, and Z is <span class="math inline">\(20.5\%\)</span>. Based on the boxplots, which site—I, II, or III—is the most likely site where the piece of pottery originated? Justify your choice.</li>
<li>Suppose only one chemical could be analyzed in the piece of pottery. Which chemical—X, Y, or Z— would be the most useful in identifying the site where the piece of pottery originated? Justify your choice.</li>
</ol></li>
</ol></li>
</ol>
<!--chapter:end:01_Data_Summary.Rmd-->
</div>
</div>
<div id="probability" class="section level1">
<h1><span class="header-section-number">2</span> Probability</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Every chapter, we will load all the librarys we will use at the beginning</span>
<span class="co"># of the chapter. </span>
<span class="kw">library</span>(ggplot2)    <span class="co"># graphing functions</span>
<span class="kw">library</span>(dplyr)      <span class="co"># data summary tools</span>

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<p>We need to work out the mathematics of what we mean by probability. To begin with we first define an outcome. An outcome is one observation from a random process or event. For example we might be interested in a single roll of a six-side die. Alternatively we might be interested in selecting one NAU student at random from the entire population of NAU students.</p>
<div id="introduction-to-set-theory" class="section level2">
<h2><span class="header-section-number">2.1</span> Introduction to Set Theory</h2>
<p>Before we jump into probability, it is useful to review a little bit of set theory.</p>
<p>Events are properties of a particular outcome. For a coin flip, the event “Heads” would be the event that a heads was flipped. For the single roll of a six-sided die, a possible event might be that the result is even. For the NAU student, we might be interested in the event that the student is a biology student. A second event of interest might be if the student is an undergraduate.</p>
<p>1.1.1 Venn Diagrams</p>
<p>Let <span class="math inline">\(S\)</span> be the set of all outcomes of my random trial. Suppose I am interested in two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. The traditional way of representing these events is using a Venn diagram.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>For example, suppose that my random experiment is rolling a fair 6-sided die once. The possible outcomes are <span class="math inline">\(S=\{1,2,3,4,5,6\}\)</span>. Suppose I then define events <span class="math inline">\(A=\)</span> roll is odd and <span class="math inline">\(B=\)</span> roll is 5 or greater. In this case our picture is:</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>All of our possible events are present, and distributed among our possible events.</p>
<div id="composition-of-events" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Composition of events</h3>
<p>I am often interested in discussing the composition of two events and we give the common set operations below.</p>
<ul>
<li>Union: Denote the event that either <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> occurs as <span class="math inline">\(A\cup B\)</span>.</li>
</ul>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<ul>
<li>Denote the event that <strong>both</strong> <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occur as <span class="math inline">\(A\cap B\)</span></li>
</ul>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<ul>
<li>Denote the event that <span class="math inline">\(A\)</span> does not occur as <span class="math inline">\(\bar{A}\)</span> or <span class="math inline">\(A^{C}\)</span> (different people use different notations)</li>
</ul>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p><strong>Definition 1</strong>. Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be mutually exclusive (or disjoint) if the occurrence of one event precludes the occurrence of the other. For example, on a single roll of a die, a two and a five cannot both come up. For a second example, define <span class="math inline">\(A\)</span> to be the event that the die is even, and <span class="math inline">\(B\)</span> to be the event that the die comes up as a <span class="math inline">\(5\)</span>.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="probability-rules" class="section level2">
<h2><span class="header-section-number">2.2</span> Probability Rules</h2>
<div id="simple-rules" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Simple Rules</h3>
<p>We now take our Venn diagrams and use them to understand the rules of probability. The underlying idea that we will use is the the probability of an event is the area in the Venn diagram.</p>
<p><strong>Definition 2</strong>. Probability is the proportion of times an event occurs in many repeated trials of a random phenomenon. In other words, probability is the long-term relative frequency.</p>
<p><strong>Fact</strong>. <em>For any event <span class="math inline">\(A\)</span> the probability of the event <span class="math inline">\(P(A)\)</span> satisfies <span class="math inline">\(0\le P(A) \le 1\)</span> because proportions always lie in <span class="math inline">\([0,1]\)</span>.</em></p>
<p>Because <span class="math inline">\(S\)</span> is the set of all events that might occur, the area of our bounding rectangle will be <span class="math inline">\(1\)</span> and the probability of event <span class="math inline">\(A\)</span> occurring will be represented by the area in the circle <span class="math inline">\(A\)</span>.</p>
<p><strong>Fact</strong>. <em>If two events are mutually exclusive, then <span class="math inline">\(P(A\cup B)=P(A)+P(B)\)</span></em></p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p><strong>Example</strong>. Let <span class="math inline">\(R\)</span> be the sum of two different colored dice. Suppose we are interested in <span class="math inline">\(P(R \le 4)\)</span>. Notice that the pair of dice can fall 36 different ways (6 ways for the first die and six for the second results in 6x6 possible outcomes, and each way has equal probability <span class="math inline">\(1/36\)</span>. Because the dice cannot simultaneously sum to <span class="math inline">\(2\)</span> and to <span class="math inline">\(3\)</span>, we could write <span class="math display">\[\begin{aligned} P(R \le 4 )   
  &amp;=    P(R=2)+P(R=3)+P(R=4) \\
    &amp;=  P(\left\{ 1,1\right\} )+P(\left\{ 1,2\right\} \mathrm{\textrm{ or }}\left\{ 2,1\right\} )+P(\{1,3\}\textrm{ or }\{2,2\}\textrm{ or }\{3,1\}) \\
    &amp;=  \frac{1}{36}+\frac{2}{36}+\frac{3}{36} \\
    &amp;=  \frac{6}{36} \\
    &amp;=  \frac{1}{6} \end{aligned}\]</span></p>
<p><strong>Fact</strong>. <span class="math inline">\(P(A)+P(\bar{A})=1\)</span></p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>The above statement is true because the probability of whole space <span class="math inline">\(S\)</span> is one (remember <span class="math inline">\(S\)</span> is all possible outcomes), then either we get an outcome in which <span class="math inline">\(A\)</span> occurs or we get an outcome in which <span class="math inline">\(A\)</span> does not occur.</p>
<p><strong>Fact</strong>. <span class="math inline">\(P(A\cup B)=P(A)+P(B)-P(A\cap B)\)</span></p>
<p>The reason behind this fact is that if there is if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not disjoint, then some area is added twice when I calculate <span class="math inline">\(P\left(A\right)+P\left(B\right)\)</span>. To account for this, I simply subtract off the area that was double counted.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p><strong>Fact 3</strong>. <span class="math inline">\(P(A)=P(A\cap B)+P(A\cap\bar{B})\)</span></p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>This identity is just breaking the event <span class="math inline">\(A\)</span> into two disjoint pieces.</p>
</div>
<div id="conditional-probability" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Conditional Probability</h3>
<p>We are given the following data about insurance claims. Notice that the data is given as <span class="math inline">\(P(\;Category\;\cap\;PolicyType\;)\)</span> which is apparent because the sum of all the elements in the table is <span class="math inline">\(100\%\)</span></p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\,\)</span></th>
<th align="center">Fire</th>
<th align="center">Auto</th>
<th align="center">Other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Fraudulant</strong></td>
<td align="center">6%</td>
<td align="center">1%</td>
<td align="center">3%</td>
</tr>
<tr class="even">
<td align="right"><strong>non-Fraudulant</strong></td>
<td align="center">14%</td>
<td align="center">29%</td>
<td align="center">47%</td>
</tr>
</tbody>
</table>
<p>Summing across the rows and columns, we can find the probabilities of for each category and policy type.</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\,\)</span></th>
<th align="center">Fire</th>
<th align="center">Auto</th>
<th align="center">Other</th>
<th align="center"><span class="math inline">\(\,\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Fraudulant</strong></td>
<td align="center">6%</td>
<td align="center">1%</td>
<td align="center">3%</td>
<td align="center"><strong>10%</strong></td>
</tr>
<tr class="even">
<td align="right"><strong>non-Fraudulant</strong></td>
<td align="center">14%</td>
<td align="center">29%</td>
<td align="center">47%</td>
<td align="center"><strong>90%</strong></td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\,\)</span></td>
<td align="center"><strong>20%</strong></td>
<td align="center"><strong>30%</strong></td>
<td align="center"><strong>50%</strong></td>
<td align="center"><strong>100%</strong></td>
</tr>
</tbody>
</table>
<p>It is clear that fire claims are more likely fraudulent than auto or other claims. In fact, the proportion of fraudulent claims, given that the claim is against a fire policy is <span class="math display">\[\begin{aligned}
P(\textrm{ Fraud }|\textrm{ FirePolicy })   &amp;=  \frac{\textrm{proportion of claims that are fire policies and are fraudulent}}{\textrm{proportion of fire claims}} \\
    &amp;=  \frac{6\%}{20\%}\\
    &amp; \\
    &amp;=  0.3
    \end{aligned}\]</span></p>
<p>In general we define conditional probability (assuming <span class="math inline">\(P(B) \ne 0\)</span>) as <span class="math display">\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</span> which can also be rearranged to show <span class="math display">\[\begin{aligned}
P(A\cap B)  &amp;=  P(A\,|\,B)\,P(B) \\
              &amp;=    P(B\,|\,A)\,P(A)
\end{aligned}\]</span> Because the order doesn’t matter and <span class="math inline">\(P\left(A\cap B\right)=P\left(B\cap A\right)\)</span>.</p>
<p>Using this rule, we might calculate the probability that a claim is an Auto policy given that it is not fraudulent. <span class="math display">\[\begin{aligned}
P\left(\,Auto\;|\;NotFraud\,\right) &amp;= \frac{P\left(\,Auto\;\cap\;NotFraud\right)}{P\left(\,NotFraud\,\right)} \\
    &amp;=  \frac{0.29}{0.9} \\
    &amp;   \\
    &amp;=  0.3\bar{2}
    \end{aligned}\]</span></p>
<p><strong>Definition 4</strong>. <em>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be independent if <span class="math inline">\(P(A|B)=P(A)\;\;\textrm{and}\;\;P(B|A)=P(B)\)</span>.</em></p>
<p>What independence is saying that knowing the outcome of event <span class="math inline">\(A\)</span> doesn’t give you any information about the outcome of event <span class="math inline">\(B\)</span>.</p>
<p><em>In simple random sampling, we assume that any two samples are independent. </em> In cluster sampling, we assume that samples within a cluster are not independent, but clusters are independent of each other.</p>
<p><strong>Fact 5</strong>. <em>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent events, then <span class="math inline">\(P(A\cap B) = P(A|B)P(B) = P(A)P(B)\)</span>.</em></p>
<p><strong>Example 6</strong>. Suppose that we are interested in the relationship between the color and the type of car. Specifically I will divide the car world into convertibles and non-convertibles and the colors into red and non-red.</p>
<p>Suppose that convertibles make up just 10% of the domestic automobile market. This is to say <span class="math inline">\(P(\;Convertable\;)=0.10\)</span>. Of the non-convertibles, red is not unheard of but it isn’t common either. So suppose <span class="math inline">\(P(\;Red\;|\;NonConvertable\;)=0.15\)</span>. However red is an extremely popular color for convertibles so let <span class="math inline">\(P(\;Red\;|\;Convertable\;)=0.60\)</span>.</p>
<p>Given the above information, we can create the following table:</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\,\)</span></th>
<th align="center">Convertible</th>
<th align="center">Not Convertible</th>
<th align="center"><span class="math inline">\(\,\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Red</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"><strong>Not Red</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\,\)</span></td>
<td align="center"><strong>10%</strong></td>
<td align="center"><strong>90%</strong></td>
<td align="center"><strong>100%</strong></td>
</tr>
</tbody>
</table>
<p>We can fill in some of the table using our the definition of conditional probability. For example: <span class="math display">\[\begin{aligned}
P\left(Red\,\cap\,Convertable\right)    &amp;= P\left(Red\,|\,Convertable\right)\,P\left(Convertable\right) \\
    &amp;=  0.60*0.10 \\
    &amp;=  0.06
  \end{aligned}\]</span></p>
<p>Lets think about what this conditional probability means. Of the <span class="math inline">\(90\%\)</span> of cars that are not convertibles, <span class="math inline">\(15\%\)</span> those non-convertibles are red and therefore the proportion of cars that are red non-convertibles is <span class="math inline">\(0.90*0.15=0.135\)</span>. Of the <span class="math inline">\(10\%\)</span> of cars that are convertibles, <span class="math inline">\(60\%\)</span> of those are red and therefore proportion of cars that are red convertibles is <span class="math inline">\(0.10*0.60=0.06\)</span>. Thus the total percentage of red cars is actually <span class="math display">\[\begin{aligned}P\left(\,Red\,\right)  
  &amp;= P\left(\;Red\;\cap\;Convertible\;\right)+P\left(\,Red\,\cap\,NonConvertible\,\right)\\
    &amp;= P\left(\,Red\,|\,Convertable\,\right)P\left(\,Convertible\,\right)+P\left(\,Red\,|\,NonConvertible\,\right)P\left(\,NonConvertible\,\right)\\
    &amp;=  0.60*0.10+0.15*0.90\\
    &amp;=  0.06+0.135\\
    &amp;=  0.195
    \end{aligned}\]</span> So when I ask for <span class="math inline">\(P(\;red\;|\;convertable\;)\)</span>, I am narrowing my space of cars to consider only convertibles. While there percentage of cars that are red and convertible is just 6% of all cars, when I restrict myself to convertibles, we see that the percentage of this smaller set of cars that are red is 60%.</p>
<p>Notice that because <span class="math inline">\(P\left(Red\right)=0.195\ne0.60=P\left(Red\,|\,Convertable\right)\)</span> then the events <span class="math inline">\(Red\)</span> and <span class="math inline">\(Convertable\)</span> are not independent.</p>
</div>
<div id="summary-of-probability-rules" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Summary of Probability Rules</h3>
<p><span class="math display">\[0 \le P\left(A\right) \le 1\]</span></p>
<p><span class="math display">\[P\left(A\right)+P\left(\bar{A}\right)=1\]</span> <span class="math display">\[P\left(A\cup B\right) =   P\left(A\right)+P\left(B\right)-P\left(A\cap B\right)\]</span> <span class="math display">\[P\left(A\cap B\right) =   \begin{cases}
P\left(A\,|\,B\right)P\left(B\right)\\
P\left(B\,|\,A\right)P\left(A\right)\\
P(A)P(B)\;\; &amp; \textrm{ if A,B are independent}
\end{cases}\]</span></p>
<p><span class="math display">\[P\left(A\,|\,B\right) =   \frac{P\left(A\cap B\right)}{P\left(B\right)}\]</span></p>
</div>
</div>
<div id="discrete-random-variables" class="section level2">
<h2><span class="header-section-number">2.3</span> Discrete Random Variables</h2>
<p>The different types of probability distributions (and therefore your analysis method) can be divided into two general classes:</p>
<ol style="list-style-type: decimal">
<li><p>Continuous Random Variables - the variable takes on numerical values and could, in principle, take any of an uncountable number of values. In practical terms, if fractions or decimal points in the number make sense, it is usually continuous.</p></li>
<li><p>Discrete Random Variables - the variable takes on one of small set of values (or only a countable number of outcomes). In practical terms, if fractions or decimals points don’t make sense, it is usually discrete.</p></li>
</ol>
<p>Examples:</p>
<ol style="list-style-type: decimal">
<li>Presence or Absence of wolves in a State?</li>
<li>Number of Speeding Tickets received?</li>
<li>Tree girth (in cm)?</li>
<li>Photosynthesis rate?</li>
</ol>
<div id="introduction-to-discrete-random-variables" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Introduction to Discrete Random Variables</h3>
<p>The following facts hold for discrete random variables:</p>
<ol style="list-style-type: decimal">
<li>The probability associated with every value lies between 0 and 1</li>
<li>The sum of all probabilities for all values is equal to 1</li>
<li>Probabilities for discrete RVs are additive. i.e., <span class="math inline">\(P(3\textrm{ or }4)=P(3)+P(4)\)</span></li>
</ol>
<div id="expected-value" class="section level4">
<h4><span class="header-section-number">2.3.1.1</span> Expected Value</h4>
<p>Example: Consider the discrete random variable <span class="math inline">\(S\)</span>, the sum of two fair dice.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>We often want to ask ‘What is expected value of this distribution?’ You might think about taking a really, really large number of samples from this distribution and then taking the mean of that really really big sample. We define the expected value (often denoted by <span class="math inline">\(\mu\)</span>) as a weighted average of the possible values and the weights are the proportions with which those values occur. <span class="math display">\[\mu=E[S]  =   \sum_{\textrm{possible }s}\;s\cdot P\left(S=s\right)\]</span> In this case, we have that <span class="math display">\[\begin{aligned} \mu = E[S] 
&amp;=  \sum_{s=2}^{12}s\cdot P(S=s) \\
&amp;=  2\cdot P\left(S=2\right)+3\cdot P\left(S=3\right)+\dots+11\cdot P\left(S=11\right)+12\cdot P\left(S=12\right) \\
&amp;=  2\left(\frac{1}{36}\right)+3\left(\frac{2}{36}\right)+\dots+11\left(\frac{2}{36}\right)+12\left(\frac{1}{36}\right) \\
&amp;=  7
\end{aligned}\]</span></p>
</div>
<div id="variance-1" class="section level4">
<h4><span class="header-section-number">2.3.1.2</span> Variance</h4>
<p>Similarly we could define the variance of <span class="math inline">\(S\)</span> (which we often denote <span class="math inline">\(\sigma^{2}\)</span>) as a weighted average of the squared-deviations that could occur. <span class="math display">\[ \sigma^{2}=V[S]  = \sum_{\textrm{possible }s}\; (s-\mu)^2 \cdot P\left(S=s\right)\]</span> which in this example can be calculated as <span class="math display">\[\begin{aligned} \sigma^{2}=V[S] 
  &amp;= \sum_{s=2}^{12}\left(s-\mu\right)^{2}P(S=s) \\
    &amp;= (2-7)^{2}\left(\frac{1}{36}\right)+(3-7)^{2}\left(\frac{2}{36}\right)+\dots+(12-7)^{2}\left(\frac{1}{36}\right) \\
    &amp;= \frac{35}{6}=5.8\bar{3}
    \end{aligned}\]</span></p>
<p>We could interpret the expectation as the sample mean of an infinitely large sample, and the variance as the sample variance of the same infinitely large sample. These are two very important numbers that describe the distribution.</p>
<p><strong>Example 7</strong>. My wife is a massage therapist and over the last year, the number of clients she sees per work day (denoted Y) varied according the following table:</p>
<table>
<thead>
<tr class="header">
<th align="right">Number of Clients</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Frequency/Probability</strong></td>
<td align="center">0.30</td>
<td align="center">0.35</td>
<td align="center">0.20</td>
<td align="center">0.10</td>
<td align="center">0.05</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">distr &lt;-<span class="st"> </span><span class="kw">data.frame</span>(    <span class="dt">clients =</span> <span class="kw">c</span>( <span class="dv">0</span>,   <span class="dv">1</span>,    <span class="dv">2</span>,    <span class="dv">3</span>,    <span class="dv">4</span>   ),    <span class="co"># two columns </span>
                    <span class="dt">probability =</span> <span class="kw">c</span>(<span class="fl">0.3</span>, <span class="fl">0.35</span>, <span class="fl">0.20</span>, <span class="fl">0.10</span>, <span class="fl">0.05</span> ) )   <span class="co"># </span>

<span class="kw">ggplot</span>(distr, <span class="kw">aes</span>(<span class="dt">x=</span>clients)) <span class="op">+</span><span class="st">                   </span><span class="co"># graph with clients as the x-axis</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>probability)) <span class="op">+</span><span class="st">                </span><span class="co"># where the dots go</span>
<span class="st">  </span><span class="kw">geom_linerange</span>(<span class="kw">aes</span>(<span class="dt">ymax=</span>probability, <span class="dt">ymin=</span><span class="dv">0</span>)) <span class="op">+</span><span class="st"> </span><span class="co"># the vertical lines       </span>
<span class="st">  </span><span class="kw">theme_bw</span>()                                      <span class="co"># set background color...</span></code></pre></div>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Because this is the long term relative frequency of the number of clients (over 200 working days!), it is appropriate to interpret these frequencies as probabilities. This table and graph is often called a probability mass function (pmf) because it lists how the probability is spread across the possible values of the random variable. We might next ask ourselves what is the average number of clients per day? It looks like it ought to be between 1 and 2 clients per day.</p>
<p><span class="math display">\[\begin{aligned} E\left(Y\right)   
  &amp;=    \sum_{\textrm{possible }y}y\,P\left(Y=y\right) \\
    &amp;=  \sum_{y=0}^{4}y\,P\left(Y=y\right) \\
    &amp;=  0\,P\left(Y=0\right)+1\,P\left(Y=1\right)+2\,P\left(Y=2\right)+3\,P\left(Y=3\right)+4\,P\left(Y=4\right) \\
    &amp;=  0\left(0.3\right)+1\left(0.35\right)+2\left(0.20\right)+3\left(0.10\right)+4\left(0.05\right) \\
    &amp;=  1.25 \end{aligned}\]</span></p>
<p>Notice that this number is not an integer and therefore is not a value that <span class="math inline">\(Y\)</span> could actually take on. You might be tempted to therefore round it to the nearest integer. That would be wrong. The rational is that if we wanted to estimate the number of clients she has per month (and thus her income), we would have a worse estimate if we used the rounded number.</p>
<p>Another example of a case where rounding would be inappropriate is in gambling situations where the amount won or lost per hand isn’t particularly important but the average amount won or lost over hundreds or thousands of plays is what matters. A Roulette wheel has 18 red and 18 black slots along with 2 green. If you bet $1 on red, you could either win a dollar or lose a dollar. However, because the probabilities are</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th align="center">Win ( + $1 )</th>
<th align="center">Lose (- $1)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Probability</strong></td>
<td align="center"><span class="math inline">\(\frac{18}{38}\)</span></td>
<td align="center"><span class="math inline">\(\frac{20}{38}\)</span></td>
</tr>
</tbody>
</table>
<p>then the persons expected winnings per play are:</p>
<p><span class="math display">\[ \begin{aligned}E[W] 
  = \sum_{\textrm{possible }w}w\,P\left(W=w\right) 
  =  1 \left(\frac{18}{38} \right) + -1 \left( \frac{20}{38} \right) 
  =  -0.0526 \end{aligned}\]</span></p>
<p>So for every Black/Red bet, the player should expect to lose 5.2 cents. While this number is small, it is enough to make the casino millions of dollars over the long run.</p>
<p>Returning to the massage therapy example, assuming that successive days are independent (which might be a bad assumption) what is the probability she has two days in a row with no clients? <span class="math display">\[\begin{aligned}P\left(\textrm{0 on day1 }and\textrm{ 0 on day2}\right)    
  &amp;=    P\left(\textrm{0 on day 1}\right)P\left(\textrm{0 on day 2}\right) \\
    &amp;=  \left(0.3\right)\left(0.3\right) \\
    &amp;=  0.09 \end{aligned}\]</span></p>
<p>What is the variance of this distribution? <span class="math display">\[\begin{aligned}V\left(Y\right)    
  &amp;= \sum_{\textrm{possible y}}\,\left(y-\mu\right)^{2}\,P\left(Y=y\right) \\
    &amp;= \sum_{y=0}^{4}\,\left(y-\mu\right)^{2}P\left(Y=y\right) \\
    &amp;=  \left(0-1.25\right)^{2}\left(0.3\right)+\left(1-1.25\right)^{2}\left(0.35\right)+\left(2-1.25\right)^{2}\left(0.20\right)+\left(3-1.25\right)^{2}\left(0.10\right)+\left(4-1.25\right)^{2}\left(0.05\right) \\
    &amp;=  1.2875 \end{aligned}\]</span></p>
<p>Note on Notation: There is a difference between the upper and lower case letters we have been using to denote a random variable. In general, we let the upper case denote the random variable and the lower case as a value that the the variable could possibly take on. So in the massage example, the number of clients seen per day <span class="math inline">\(Y\)</span> could take on values <span class="math inline">\(y=0,1,2,3,\)</span> or <span class="math inline">\(4\)</span>.</p>
</div>
</div>
</div>
<div id="common-discrete-distributions" class="section level2">
<h2><span class="header-section-number">2.4</span> Common Discrete Distributions</h2>
<div id="binomial-distribution" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Binomial Distribution</h3>
<p><strong>Example</strong>: Suppose we are trapping small mammals in the desert and we spread out three traps. Assume that the traps are far enough apart that having one being filled doesn’t affect the probability of the others being filled and that all three traps have the same probability of being filled in an evening. Denote the event that a trap is filled with a critter as <span class="math inline">\(C_{i}\)</span> and denote the event that the trap is empty as <span class="math inline">\(E_{i}\)</span>. Denote the probability that a trap is filled by <span class="math inline">\(\pi=0.8\)</span>. (This sort of random variable is often referred to as a Bernoulli RV.)</p>
<p>The possible outcomes are</p>
<table>
<thead>
<tr class="header">
<th align="center">Outcome</th>
<th align="center"><span class="math inline">\(\,\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, E_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, E_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, C_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(E_1, E_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, C_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, E_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, C_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, C_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
</tbody>
</table>
<p>Because these are far apart enough in space that the outcome of Trap1 is independent of Trap2 and Trap3, then <span class="math display">\[P(E_{1}\cap C_{2}\cap E_{3})  =   P(E_{1})P(C_{2})P(E_{3})
    =   (1-0.8)0.8(1-0.8)
    =   0.032\]</span> <strong>Notice how important the assumption of independence is!!!</strong> Similarly we could calculate the probabilities for the rest of the table.</p>
<table>
<thead>
<tr class="header">
<th align="center">Outcome</th>
<th align="center">Probability</th>
<th align="center"><span class="math inline">\(S\)</span> Outcome</th>
<th align="center">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, E_2, E_3\)</span></td>
<td align="center">0.008</td>
<td align="center"><span class="math inline">\(S=0\)</span></td>
<td align="center">0.008</td>
</tr>
<tr class="even">
<td align="center">——————-</td>
<td align="center">—————</td>
<td align="center">————-</td>
<td align="center">—————</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, E_2, E_3\)</span></td>
<td align="center">0.032</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(E_1, C_2, E_3\)</span></td>
<td align="center">0.032</td>
<td align="center"><span class="math inline">\(S=1\)</span></td>
<td align="center"><span class="math inline">\(3(0.032) = 0.096\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, E_2, C_3\)</span></td>
<td align="center">0.032</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">——————-</td>
<td align="center">—————</td>
<td align="center">————-</td>
<td align="center">—————</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, C_2, E_3\)</span></td>
<td align="center">0.128</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, E_2, C_3\)</span></td>
<td align="center">0.128</td>
<td align="center"><span class="math inline">\(S=2\)</span></td>
<td align="center"><span class="math inline">\(3(0.128) = 0.384\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, C_2, C_3\)</span></td>
<td align="center">0.128</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">——————-</td>
<td align="center">—————</td>
<td align="center">————-</td>
<td align="center">—————</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, C_2, C_3\)</span></td>
<td align="center">0.512</td>
<td align="center"><span class="math inline">\(S=3\)</span></td>
<td align="center"><span class="math inline">\(0.512\)</span></td>
</tr>
</tbody>
</table>
<p>Next we are interested in the random variable <span class="math inline">\(S\)</span>, the number of traps that were filled:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(S\)</span> Outcome</th>
<th align="center">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(S=0\)</span></td>
<td align="center"><span class="math inline">\(0.008\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(S=1\)</span></td>
<td align="center"><span class="math inline">\(0.096\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(S=2\)</span></td>
<td align="center"><span class="math inline">\(0.384\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(S=3\)</span></td>
<td align="center"><span class="math inline">\(0.512\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(S\)</span> is an example of a Binomial Random Variable. A binomial experiment is one that:</p>
<ol style="list-style-type: decimal">
<li>Experiment consists of <span class="math inline">\(n\)</span> identical trials.</li>
<li>Each trial results in one of two outcomes (Heads/Tails, presence/absence). One will be labeled a success and the other a failure.</li>
<li>The probability of success on a single trial is equal to <span class="math inline">\(\pi\)</span> and remains the same from trial to trial.</li>
<li>The trials are independent (this is implied from property 3).</li>
<li>The random variable <span class="math inline">\(Y\)</span> is the number of successes observed during <span class="math inline">\(n\)</span> trials.</li>
</ol>
<p>Recall that the probability mass function (pmf) describes how the probability is spread across the possible outcomes, and in this case, I can describe this via a nice formula. The pmf of a a binomial random variable <span class="math inline">\(X\)</span> taken from <span class="math inline">\(n\)</span> trials each with probability of success <span class="math inline">\(\pi\)</span> is</p>
<p><span class="math display">\[P(X=x)=\underbrace{\frac{n!}{x!(n-x)!}}_{orderings}\;\underbrace{\pi^{x}}_{y\,successes}\;\underbrace{(1-\pi)^{n-x}}_{n-y\,failures}\]</span></p>
<p>where we define <span class="math inline">\(n!=n(n-1)\dots(2)(1)\)</span> and further define <span class="math inline">\(0!=1\)</span>. Often the ordering term is written more compactly as <span class="math display">\[{n \choose x}=\frac{n!}{x!\left(n-x\right)!}\]</span>.</p>
<p>For our small mammal example we can create a graph that shows the binomial distribution with the following R code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dist &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x=</span><span class="dv">0</span><span class="op">:</span><span class="dv">3</span> ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probability =</span> <span class="kw">dbinom</span>(x, <span class="dt">size=</span><span class="dv">3</span>, <span class="dt">prob=</span><span class="fl">0.8</span>))
<span class="kw">ggplot</span>(dist, <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>probability)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_linerange</span>(<span class="kw">aes</span>(<span class="dt">ymax=</span>probability, <span class="dt">ymin=</span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Binomial distribution: n=3, p=0.8&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>To calculate the height of any of these bars, we can evaluate the pmf at the desired point. For example, to calculate the probability the number of full traps is 2, we calculate the following</p>
<p><span class="math display">\[\begin{aligned} P(X=2)    
  &amp;=    {3 \choose 2}\left(0.8\right)^{2}\left(1-0.8\right)^{3-2} \\
    &amp;=  \frac{3!}{2!(3-2)!}(0.8)^{2}(0.2)^{3-2} \\
    &amp;=  \frac{3\cdot2\cdot1}{(2\cdot1)1}\;(0.8)^{2}(0.2) \\
    &amp;=  3(0.128) \\
    &amp;=  0.384 \end{aligned}\]</span></p>
<p>You can use R to calculate these probabilities. In general, for any distribution, the “d-function” gives the distribution function (pmf or pdf). So to get R to do the preceding calculation we use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># If    X ~ Binomial(n=3, pi=0.8)</span>
<span class="co"># Then  P( X = 2 | n=3, pi=0.8 ) =</span>
<span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dt">size=</span><span class="dv">3</span>, <span class="dt">prob=</span><span class="fl">0.8</span>)</code></pre></div>
<pre><code>## [1] 0.384</code></pre>
<p>The expectation of this distribution can be shown to be <span class="math display">\[\begin{aligned}E[X]   
  &amp;=    \sum_{x=0}^{n}x\,P(X=x) \\
    &amp;=  \sum_{x=0}^{n}x\;\frac{n!}{x!\left(n-x\right)!}\pi^{x}\left(1-\pi\right)^{n-x}\\
    &amp;=  \vdots \\
    &amp;=  n\pi \end{aligned}\]</span></p>
<p>and the variance can be similarly calculated <span class="math display">\[\begin{aligned} V[X]  
  &amp;=    \sum_{x=0}^{n}\left(x-E\left[X\right]\right)^{2}\,P\left(X=x|n,\pi\right) \\
    &amp;=  \sum_{x=0}^{n}\left(x-E\left[X\right]\right)^{2}\;\frac{n!}{x!\left(n-x\right)!}\pi^{x}\left(1-\pi\right)^{n-x} \\
    &amp;=  \vdots \\
    &amp;=  n\pi(1-\pi) \end{aligned}\]</span></p>
<p><strong>Example 8</strong>. Suppose a bird survey only captures the presence or absence of a particular bird (say the mountain chickadee). Assuming the true presence proportion at national forest sites around Flagstaff <span class="math display">\[\pi=0.1\]</span>, then for <span class="math inline">\(n=20\)</span> randomly chosen sites, the number of sites in which the bird was observed would have the distribution</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dist &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">20</span> ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probability =</span> <span class="kw">dbinom</span>(x, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="fl">0.1</span>))
<span class="kw">ggplot</span>(dist, <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>probability)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_linerange</span>(<span class="kw">aes</span>(<span class="dt">ymax=</span>probability, <span class="dt">ymin=</span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Binomial distribution: n=20, p=0.1&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Number of Sites Occupied&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Often we are interested in questions such as <span class="math inline">\(P(X\le2)\)</span> which is the probability that we see 2 or fewer of the sites being occupied by mountain chickadee. These calculations can be tedious to calculate by hand but R will calculate these cumulative distribution function values for you using the “p-function”. This cumulative distribution function gives the sum of all values up to and including the number given.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(X=0) + P(X=1) + P(X=2)</span>
sum &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">0</span>, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">       </span><span class="kw">dbinom</span>(<span class="dv">1</span>, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">       </span><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="fl">0.1</span>)
sum</code></pre></div>
<pre><code>## [1] 0.6769268</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(X &lt;= 2)</span>
<span class="kw">pbinom</span>(<span class="dv">2</span>, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="fl">0.1</span>)</code></pre></div>
<pre><code>## [1] 0.6769268</code></pre>
<p>In general we will be interested in asking four different questions about a distribution.</p>
<ol style="list-style-type: decimal">
<li>What is the height of the probability mass function (or probability density function). For discrete variable <span class="math inline">\(Y\)</span> this is <span class="math inline">\(P\left(Y=y\right)\)</span> for whatever value of <span class="math inline">\(y\)</span> we want. In R, this will be the <code>d</code>-function.</li>
<li>What is the probability of observing a value less than or equal to <span class="math inline">\(y\)</span>? In other words, to calculate <span class="math inline">\(P\left(Y\le y\right)\)</span>. In R, this will be the <code>p</code>-function.</li>
<li>What is a particular quantile of a distribution? For example, what value separates the lower <span class="math inline">\(25\%\)</span> from the upper <span class="math inline">\(75\%\)</span>? In R, this will be the <code>q</code>-function.</li>
<li>Generate a random sample of values from a specified distribution. In R, this will be the <code>r</code>-function.</li>
</ol>
</div>
<div id="poisson-distribution" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Poisson Distribution</h3>
<p>A commonly used distribution for count data is the Poisson.</p>
<ol style="list-style-type: decimal">
<li>Number of customers arriving over a 5 minute interval</li>
<li>Number of birds observed during a 10 minute listening period</li>
<li>Number of prairie dog towns per 1000 hectares</li>
<li>Number of alga clumps per cubic meter of lake water</li>
</ol>
<p>For a RV is a Poisson RV if the following conditions apply:</p>
<ol style="list-style-type: decimal">
<li>Two or more events do not occur at precisely the same time or in the same space</li>
<li>The occurrence of an event in a given period of time or region of space is independent of the occurrence of the event in a non overlapping period or region.</li>
<li>The expected number of events during one period or region, <span class="math inline">\(\lambda\)</span>, is the same in all periods or regions of the same size.</li>
</ol>
<p>Assuming that these conditions hold for some count variable <span class="math inline">\(Y\)</span>, the the probability mass function is given by <span class="math display">\[P(Y=y)=\frac{\lambda^{y}e^{-\lambda}}{y!}\]</span> where <span class="math inline">\(\lambda\)</span> is the expected number of events over 1 unit of time or space and <span class="math inline">\(e\)</span> is the constant <span class="math inline">\(2.718281828\dots\)</span>.</p>
<p><span class="math display">\[E[Y]  =   \lambda\]</span> <span class="math display">\[Var[Y]    =   \lambda\]</span></p>
<p><strong>Example 9</strong>. Suppose we are interested in the population size of small mammals in a region. Let <span class="math inline">\(Y\)</span> be the number of small mammals caught in a large trap (multiple traps in the same location?) in a 12 hour period. Finally, suppose that <span class="math inline">\(Y\sim Poi(\lambda=2.3)\)</span>. What is the probability of finding exactly 4 critters in our trap? <span class="math display">\[P(Y=4)    =   \frac{2.3^{4}\,e^{-2.3}}{4!} =  0.1169\]</span> What about the probability of finding at most 4? <span class="math display">\[\begin{aligned} P(Y\le4) 
  &amp;=    P(Y=0)+P(Y=1)+P(Y=2)+P(Y=3)+P(Y=4) \\
    &amp;=  0.1003+0.2306+0.2652+0.2033+0.1169 \\
    &amp;=  0.9163 \end{aligned}\]</span></p>
<p>What about the probability of finding 5 or more? <span class="math display">\[P(Y\ge5)  =   1-P(Y\le4) =    1-0.9163 =  0.0837\]</span></p>
<p>These calculations can be done using the distribution function (d-function) for the Poisson and the cumulative distribution function (p-function).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dist &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">NumCaught =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">10</span> ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">probability =</span> <span class="kw">dpois</span>( NumCaught, <span class="dt">lambda=</span><span class="fl">2.3</span> ) )
<span class="kw">ggplot</span>(dist, <span class="kw">aes</span>(<span class="dt">x=</span>NumCaught)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>( <span class="kw">aes</span>(<span class="dt">y=</span>probability) ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_linerange</span>(<span class="kw">aes</span>( <span class="dt">ymax=</span>probability, <span class="dt">ymin=</span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Poisson Distribution with  &#39;</span>, lambda <span class="op">==</span><span class="st"> </span><span class="fl">2.3</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&#39;Number Caught&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()            </code></pre></div>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P( Y = 4)</span>
<span class="kw">dpois</span>(<span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">2.3</span>)</code></pre></div>
<pre><code>## [1] 0.1169022</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P( Y &lt;= 4)</span>
<span class="kw">ppois</span>(<span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">2.3</span>)</code></pre></div>
<pre><code>## [1] 0.9162493</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1-P(Y &lt;= 4)  ==  P( Y &gt; 4)  ==  P( Y &gt;= 5)</span>
<span class="dv">1</span><span class="op">-</span><span class="kw">ppois</span>(<span class="dv">4</span>, <span class="fl">2.3</span>)</code></pre></div>
<pre><code>## [1] 0.08375072</code></pre>
</div>
</div>
<div id="continuous-random-variables" class="section level2">
<h2><span class="header-section-number">2.5</span> Continuous Random Variables</h2>
<p>Continuous random variables can take on an (uncountably) infinite number of values, and this results in a few obnoxious mathematical differences between how we handle continuous and discrete random variables. In particular, the probability that a continuous random variable <span class="math inline">\(X\)</span> will take on a particular value will be zero, so we will be interested in finding the probability that the random variable is in some interval instead. Wherever we had a summation, <span class="math inline">\(\sum\)</span>, we will instead have an integral, but because many students haven’t had calculus, we will resort to using R or tables of calculated values.</p>
<div id="uniform01-distribution" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Uniform(0,1) Distribution</h3>
<p>Suppose you wish to draw a random number number between 0 and 1 and any two intervals of equal size should have the same probability of the value being in them. This random variable is said to have a Uniform(0,1) distribution.</p>
<p>Because there are an infinite number of rational numbers between 0 and 1, the probability of any particular number being selected is <span class="math inline">\(1/\infty=0\)</span>. But even though each number has 0 probability of being selected, some number must end up being selected. Because of this conundrum, probability theory doesn’t look at the probability of a single number, but rather focuses on a region of numbers.</p>
<p>To make this distinction, we will define the distribution using a probability density function (pdf) instead of the probability mass function. In the discrete case, we had to constrain the probability mass function to sum to 1. In the continuous case, we have to constrain the probability density function to integrate to 1.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Finding the area under the curve of a particular density function <span class="math inline">\(f(x)\)</span> usually requires the use of calculus, but since this isn’t a calculus course, we will resort to using R or tables of calculated values.</p>
</div>
<div id="exponential-distribution" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Exponential Distribution</h3>
<p>The exponential distribution is the continuous analog of the Poisson distribution and is often used to model the time between occurrence of successive events. Perhaps we are modeling time between transmissions on a network, or the time between feeding events or prey capture. If the random variable <span class="math inline">\(X\)</span> has an Exponential distribution, its probability density function is <span class="math display">\[f(x)=\begin{cases}
\lambda e^{-\lambda x} &amp; x\ge0\;\textrm{ and }\;\lambda&gt;0\\
0 &amp; \textrm{otherwise}
\end{cases}\]</span></p>
<p>Analogous to the discrete distributions, we can define the Expectation and Variance of these distributions by replacing the summation with an integral <span class="math display">\[\mu = E[X] =  \int_{0}^{\infty}x\,f(x)\,dx = \dots = \frac{1}{\lambda} \]</span> <span class="math display">\[\sigma^2 = Var[X] =   \int_{0}^{\infty}\left(x-\mu\right)^{2}\,f\left(x\right)\,dx =  \dots = \frac{1}{\lambda^{2}}\]</span></p>
<p>Because the exponential distribution is defined by the rate of occurrence of an event, increasing that rate decreases the time between events. Furthermore because the rate of occurrence cannot be negative, we restrict <span class="math inline">\(\lambda&gt;0\)</span>.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p><strong>Example 10</strong>. Suppose the time between insect captures <span class="math inline">\(X\)</span> during a summer evening for a species of bat follows a exponential distribution with capture rate of <span class="math inline">\(\lambda=2\)</span> insects per minute and therefore the expected waiting time between captures is <span class="math inline">\(1/\lambda=1/2\)</span> minute. Suppose that we are interested in the probability that it takes a bat more than 1 minute to capture its next insect.</p>
<p><span class="math display">\[P(X&gt;1)=\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>,<span class="dt">length=</span><span class="dv">1000</span>), <span class="dt">lambda =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y=</span><span class="kw">dexp</span>(x, <span class="dt">rate =</span> lambda),
         <span class="dt">grp =</span> <span class="kw">ifelse</span>( x <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&#39;&gt; 1&#39;</span>, <span class="st">&#39;&lt;= 1&#39;</span>))
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y, <span class="dt">fill=</span>grp)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&#39;density&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>We now must resort to calculus to find this area. Or use tables of pre-calculated values. Or use R, remembering that p-functions give the area under the curve to the left of the given value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(X &gt; 1)  == 1 - P(X &lt;= 1)</span>
<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pexp</span>(<span class="dv">1</span>, <span class="dt">rate=</span><span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 0.1353353</code></pre>
</div>
<div id="normal-distribution" class="section level3">
<h3><span class="header-section-number">2.5.3</span> Normal Distribution</h3>
<p>Undoubtedly the most important distribution in statistics is the normal distribution. If my RV <span class="math inline">\(X\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, its probability density function is given by <span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left[\frac{-(x-\mu)^{2}}{2\sigma^{2}}\right]\]</span> where <span class="math inline">\(\exp[y]\)</span> is the exponential function <span class="math inline">\(e^{y}\)</span>. We could slightly rearrange the function to</p>
<p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}\right]\]</span></p>
<p>and see this distribution is defined by its expectation <span class="math inline">\(E[X]=\mu\)</span> and its variance <span class="math inline">\(Var[X]=\sigma^{2}\)</span>. Notice I could define it using the standard deviation <span class="math inline">\(\sigma\)</span>, and different software packages will expect it to be defined by one or the other. R defines the normal distribution using the standard deviation.</p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><strong>Example 11</strong>. It is known that the heights of adult males in the US is approximately normal with a mean of 5 feet 10 inches (<span class="math inline">\(\mu=70\)</span> inches) and a standard deviation of <span class="math inline">\(\sigma=3\)</span> inches. Your instructor is a mere 5 feet 4 inches (64 inches). What proportion of the population is shorter than your professor?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">distr &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">57</span>, <span class="dv">82</span>, <span class="dt">length=</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">density =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">70</span>, <span class="dt">sd=</span><span class="dv">3</span>),
          <span class="dt">group =</span> <span class="kw">ifelse</span>(x<span class="op">&lt;=</span><span class="dv">64</span>, <span class="st">&#39;Shorter&#39;</span>,<span class="st">&#39;Taller&#39;</span>) )
<span class="kw">ggplot</span>(distr, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>density, <span class="dt">fill=</span>group)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Using R you can easily find this</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="dv">64</span>, <span class="dt">mean=</span><span class="dv">70</span>, <span class="dt">sd=</span><span class="dv">3</span>)</code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
</div>
<div id="standardizing" class="section level3">
<h3><span class="header-section-number">2.5.4</span> Standardizing</h3>
<p>Before we had computers that could calculate these probabilities for any normal distribution, it was important to know how to convert a probability statement from an arbitrary <span class="math inline">\(N\left(\mu,\sigma^{2}\right)\)</span> distribution to a question about a Standard Normal distribution, which is a normal distribution with mean <span class="math inline">\(\mu=0\)</span> and standard deviation <span class="math inline">\(\sigma=1\)</span>. If we have <span class="math display">\[X\sim N\left(\mu,\sigma^{2}\right)\]</span> then <span class="math display">\[Z=\frac{X-\mu}{\sigma}\sim N\left(0,1\right)\]</span></p>
<p>You might remember doing something similar in an undergraduate statistics course in order to use a table to look up some probability. From the height example, we calculate <span class="math display">\[\begin{aligned}z  
  &amp;=    \frac{64-70}{3} \\
    &amp;=  \frac{-6}{3} \\
    &amp;=  -2 \end{aligned}\]</span> Note that this calculation shows that he is <span class="math inline">\(-2\)</span> standard deviations from the mean. Next we look at a table for <span class="math inline">\(z=-2.00\)</span>. To do this we go down to the <span class="math inline">\(-2.0\)</span> row and over to the <span class="math inline">\(.00\)</span> column and find <span class="math inline">\(0.0228\)</span>. Only slightly over 2% of the adult male population is shorter!</p>
<p>How tall must a person be to be taller than <span class="math inline">\(80\%\)</span> of the rest of the adult male population? To answer that we must use the table in reverse and look for the <span class="math inline">\(0.8\)</span> value. We find the closest value possible <span class="math inline">\((0.7995)\)</span> and the <span class="math inline">\(z\)</span> value associated with it is <span class="math inline">\(z=0.84\)</span>. Next we solve the standardizing equation for <span class="math inline">\(x\)</span> <span class="math display">\[\begin{aligned}
z       &amp;=  \frac{x-\mu}{\sigma} \\
0.84    &amp;=  \frac{x-70}{3} \\
x       &amp;=  3(0.84)+70 \\
        &amp;=  72.49\;\textrm{inches} \end{aligned}\]</span></p>
<p>Alternatively we could use the quantile function for the normal distribution (q-function) in R and avoid the imprecision of using a table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(.<span class="dv">8</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] 0.8416212</code></pre>
<p><strong>Empirical Rule</strong> - It is from the normal distribution that the empirical rule from the previous chapter is derived. If <span class="math inline">\(X\sim N(\mu,\sigma^{2})\)</span> then <span class="math display">\[\begin{aligned} P(\mu-\sigma\le X\le\mu+\sigma)   
  &amp;=    P(-1 \le Z \le 1) \\
    &amp;=  P(Z \le 1) - P(Z \le -1) \\
    &amp;\approx    0.8413-0.1587 \\
    &amp;=  0.6826 \end{aligned}\]</span></p>
<p><img src="02_Probability_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>1.6 R Comments</p>
<p>There will be a variety of distributions we’ll be interested in and R refers to them using the following abbreviations</p>
<table>
<colgroup>
<col width="18%" />
<col width="17%" />
<col width="19%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Stem</th>
<th>Parameters</th>
<th>Parameter Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>Binomial</p></td>
<td><p><code>binom</code></p></td>
<td><p><code>size</code> <code>prob</code></p></td>
<td><p>Number of Trials, Probability of Success (per Trial)</p></td>
</tr>
<tr class="even">
<td><p>Exponential</p></td>
<td><p><code>exp</code></p></td>
<td><p><code>rate</code></p></td>
<td><p>Mean of the distribution</p></td>
</tr>
<tr class="odd">
<td><p>Normal</p></td>
<td><p><code>norm</code></p></td>
<td><p><code>mean=0</code> <code>sd=1</code></p></td>
<td><p>Center of the distribution, Standard deviation</p></td>
</tr>
<tr class="even">
<td><p>Uniform</p></td>
<td><p><code>unif</code></p></td>
<td><p><code>min=0</code> <code>max=1</code></p></td>
<td><p>Minimum and Maximum of the distribution</p></td>
</tr>
</tbody>
</table>
<p>All the probability distributions available in R are accessed in exactly the same way, using a d-function, p-function, q-function, and r-function.</p>
<table>
<colgroup>
<col width="25%" />
<col width="74%" />
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><code>d</code>-function(x)</p></td>
<td><p>The height of the probability distribution/density at <span class="math inline">\(x\)</span></p></td>
</tr>
<tr class="even">
<td><p><code>p</code>-function(x)</p></td>
<td><p><span class="math inline">\(P\left(X\le x\right)\)</span></p></td>
</tr>
<tr class="odd">
<td><p><code>q</code>-function(q)</p></td>
<td><p><span class="math inline">\(x\)</span> such that <span class="math inline">\(P\left(X\le x\right) = q\)</span></p></td>
</tr>
<tr class="even">
<td><p><code>r</code>-function(n)</p></td>
<td><p><span class="math inline">\(n\)</span> random observations from the distribution</p></td>
</tr>
</tbody>
</table>
<p>The <code>mosaic</code> package has versions of the p and q -functions that also print a out nice picture of the probabilities that you ask for. These functions are named by just adding an ‘x’ at the beginning of the function. For example <code>mosaic::xpnorm(-1)</code>.</p>
</div>
</div>
<div id="exercises-1" class="section level2">
<h2><span class="header-section-number">2.6</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>The population distribution of blood donors in the United States based on race/ethnicity and blood type as reported by the American Red Cross is given here:</p>
<table style="width:82%;">
<colgroup>
<col width="18%" />
<col width="12%" />
<col width="13%" />
<col width="12%" />
<col width="12%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(\,\)</span></th>
<th>O</th>
<th>A</th>
<th>B</th>
<th>AB</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><strong>White</strong></p></td>
<td><p>36%</p></td>
<td><p>32.2%</p></td>
<td><p>8.8%</p></td>
<td><p>3.2%</p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
</tr>
<tr class="even">
<td><p><strong>Black</strong></p></td>
<td><p>7%</p></td>
<td><p>2.9%</p></td>
<td><p>2.5%</p></td>
<td><p>0.5%</p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
</tr>
<tr class="odd">
<td><p><strong>Asian</strong></p></td>
<td><p>1.7%</p></td>
<td><p>1.2%</p></td>
<td><p>1%</p></td>
<td><p>0.3%</p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
</tr>
<tr class="even">
<td><p><strong>Other</strong></p></td>
<td><p>1.5%</p></td>
<td><p>0.8%</p></td>
<td><p>0.3%</p></td>
<td><p>0.1%</p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
</tr>
<tr class="odd">
<td><p><span class="math inline">\(\,\)</span></p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
<td><p><span class="math inline">\(\,\)</span></p></td>
<td><p>100%</p></td>
</tr>
</tbody>
</table>
Notice that the numbers given in the table sum to 100%, so the data presented are the probability of a particular ethnicity and blood type.
<ol style="list-style-type: lower-alpha">
<li>Fill in the column and row totals.</li>
<li>What is the probability that a randomly selected donor will be Asian and have Type O blood? That is to say, given a donor is randomly selected from the list of all donors, what is the probability that the selected donor will Asian with Type O?</li>
<li>What is the probability that a randomly selected donor is white? That is to say, given a donor is randomly selected from the list of all donors, what is the probability that the selected donor is white?</li>
<li>What is the probability that a randomly selected donor has Type A blood? That is to say, given a donor is selected from the list of all donors, what is the probability that the selected donor has Type A blood?</li>
<li>What is the probability that a white donor will have Type A blood? That is to say, given a donor is randomly selected from the list of all the white donors, what is the probability that the selected donor has Type A blood? (Notice we already know the donor is white because we restricted ourselves to that subset!)</li>
<li>Is blood type and ethnicity independent? Justify your response mathematically using your responses from the previous answers.</li>
</ol></li>
<li>For each of the following, mark if it is Continuous or Discrete.
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> Milliliters of tea drunk per day.</li>
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> Different brands of soda drunk over the course of a year.</li>
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> Number of days per week that you are on-campus for any amount of time.</li>
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> Number of grizzly bears individuals genetically identified from a grid of hair traps in Glacier National Park.</li>
</ol></li>
<li>For each scenario, state whether the event should be modeled via a binomial or Poisson distribution.
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> Number of M&amp;Ms I eat per hour while grading homework</li>
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> The number of mornings in the coming 7 days that I change my son’s first diaper of the day.</li>
<li><span class="math inline">\(\underline{\hspace{1in}}\)</span> The number of Manzanita bushes per 100 meters of trail.</li>
</ol></li>
<li>During a road bike race, there is always a chance a crash will occur. Suppose the probability that at least one crash will occur in any race I’m in is <span class="math inline">\(\pi=0.2\)</span> and that races are independent.
<ol style="list-style-type: lower-alpha">
<li>What is the probability that the next two races I’m in will both have crashes?</li>
<li>What is the probability that neither of my next two races will have a crash?</li>
<li>What is the probability that at least one of the next two races have a crash?</li>
</ol></li>
<li>My cats suffer from gastric distress due to eating house plants and the number of vomits per week that I have to clean up follows a Poisson distribution with rate <span class="math inline">\(\lambda=1.2\)</span> pukes per week.
<ol style="list-style-type: lower-alpha">
<li>What is the probability that I don’t have to clean up any vomits this coming week?</li>
<li>What is the probability that I must clean up 1 or more vomits?</li>
<li>If I wanted to measure this process with a rate per day, what rate should I use?</li>
</ol></li>
<li><p>Suppose that the number of runners I see on a morning walk on the trails near my house has the following distribution (Notice I’ve never seen four or more runners on a morning walk):</p>
<table>
<thead>
<tr class="header">
<th align="right">y</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4+</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Probabilty</strong></td>
<td align="center">0.45</td>
<td align="center">0.25</td>
<td align="center">0.20</td>
<td align="center"></td>
<td align="center">0.0</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>What is the probability that I see 3 runners on a morning walk?</li>
<li>What is the expected number of runners that I will encounter?</li>
<li>What is the variance of the number of runners that I will encounter?</li>
</ol></li>
<li>If <span class="math inline">\(Z\sim N\left(\mu=0,\sigma^{2}=1\right)\)</span>, find the following probabilities:
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(P(Z&lt;1.58)=\)</span></li>
<li><span class="math inline">\(P(Z=1.58)=\)</span></li>
<li><span class="math inline">\(P(Z&gt;-.27)=\)</span></li>
<li><span class="math inline">\(P(-1.97&lt;Z&lt;2.46)=\)</span></li>
</ol></li>
<li>Using the Standard Normal Table or the table functions in R, find <span class="math inline">\(z\)</span> that makes the following statements true.
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(P(Z&lt;z)=.75\)</span></li>
<li><span class="math inline">\(P(Z&gt;z)=.4\)</span></li>
</ol></li>
<li>The amount of dry kibble that I feed my cats each morning can be well approximated by a normal distribution with mean <span class="math inline">\(\mu=200\)</span> grams and standard deviation <span class="math inline">\(\sigma=30\)</span> grams.
<ol style="list-style-type: lower-alpha">
<li>What is the probability that I fed my cats more than 250 grams of kibble this morning?</li>
<li>From my cats’ perspective, more food is better. How much would I have to feed them for this morning to be among the top <span class="math inline">\(10\%\)</span> of feedings?</li>
</ol></li>
</ol>
<!--chapter:end:02_Probability.Rmd-->
</div>
</div>
<div id="confidence-intervals-via-bootstrapping" class="section level1">
<h1><span class="header-section-number">3</span> Confidence Intervals via Bootstrapping</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Every chapter, we will load all the librarys we will use at the beginning</span>
<span class="co"># of the chapter.</span>
<span class="kw">library</span>(ggplot2)    <span class="co"># graphing functions</span>
<span class="kw">library</span>(dplyr)      <span class="co"># data summary tools</span>

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<div id="theory-of-bootstrapping" class="section level2">
<h2><span class="header-section-number">3.1</span> Theory of Bootstrapping</h2>
<p>Suppose that we had a population of interest and we wish to estimate the mean of that population (the population mean we’ll denote as <span class="math inline">\(\mu\)</span>). We can’t observe every member of the population (which would be prohibitively expensive) so instead we take a random sample and from that sample calculate a sample mean (which we’ll denote <span class="math inline">\(\bar{x}\)</span>). We believe that <span class="math inline">\(\bar{x}\)</span> will be a good estimator of <span class="math inline">\(\mu\)</span>, but it will vary from sample to sample and won’t be exactly equal to <span class="math inline">\(\mu\)</span>.</p>
<p>Next suppose we wish to ask if a particular value for <span class="math inline">\(\mu\)</span>, say <span class="math inline">\(\mu_{0}\)</span>, is consistent with our observed data? We know that <span class="math inline">\(\bar{x}\)</span> will vary from sample to sample, but we have no idea how much it will vary between samples. However, if we could understand how much <span class="math inline">\(\bar{x}\)</span> varied sample to sample, we could answer the question. For example, suppose that <span class="math inline">\(\bar{x}=5\)</span> and we know that <span class="math inline">\(\bar{x}\)</span> varied about <span class="math inline">\(\pm2\)</span> from sample to sample. Then I’d say that possible values of <span class="math inline">\(\mu_{0}\)</span> in the interval <span class="math inline">\(3\)</span> to <span class="math inline">\(7\)</span> <span class="math inline">\(\left(5\pm2\right)\)</span> are reasonable values for <span class="math inline">\(\mu\)</span> and anything outside that interval is not reasonable.</p>
<p>Therefore, if we could take many, many repeated samples from the population and calculate our test statistic <span class="math inline">\(\bar{x}\)</span> for each sample, we could rule out possible values of <span class="math inline">\(\mu\)</span>. Unfortunately we don’t have the time or money to repeatedly sample from the actual population, but we could sample from our best approximation to what the population is like.</p>
<p>Suppose we were to sample from a population of shapes, and we observed <span class="math inline">\(4/9\)</span> of the sample were squares, <span class="math inline">\(3/9\)</span> were circles, and a triangle and a diamond. Then our best guess of what the population that we sampled from was a population with <span class="math inline">\(4/9\)</span> squares, <span class="math inline">\(3/9\)</span> circles, and <span class="math inline">\(1/9\)</span> of triangles and diamonds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">multiplot</span>(sample.plot, population.plot, <span class="dt">cols=</span><span class="dv">2</span>)</code></pre></div>
<pre><code>## Loading required package: grid</code></pre>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Using this approximated population (which is just many many copies of our sample data), we can repeated sample <span class="math inline">\(\bar{x}^{*}\)</span> values to create an estimate of the sampling distribution of <span class="math inline">\(\bar{x}\)</span>.</p>
<p>Because our approximate population is just an infinite number of copies of our sample data, then sampling from the approximate population is equivalent to sampling with replacement from our sample data. If I take <span class="math inline">\(n\)</span> samples from <span class="math inline">\(n\)</span> distinct objects with replacement, then the process can be thought of as mixing the <span class="math inline">\(n\)</span> objects in a bowl and taking an object at random, noting which it is, replace it into the bowl, and then draw the next sample. Practically, this means some objects will be selected more than once and some will not be chosen at all. To sample our observed data with replacement, we’ll use the <code>resample()</code> function in the <code>mosaic</code> package. We see that some rows will be selected multiple times, and some will not be selected at all.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Testing.Data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">name=</span><span class="kw">c</span>(<span class="st">&#39;Alison&#39;</span>,<span class="st">&#39;Brandon&#39;</span>,<span class="st">&#39;Casey&#39;</span>,<span class="st">&#39;Derek&#39;</span>,<span class="st">&#39;Elise&#39;</span>))
Testing.Data</code></pre></div>
<pre><code>##      name
## 1  Alison
## 2 Brandon
## 3   Casey
## 4   Derek
## 5   Elise</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Sample rows from the Testing Data (with replacement)</span>
mosaic<span class="op">::</span><span class="kw">resample</span>(Testing.Data)</code></pre></div>
<pre><code>##       name orig.id
## 1   Alison       1
## 4    Derek       4
## 3    Casey       3
## 1.1 Alison       1
## 5    Elise       5</code></pre>
<p>Notice Alison has selected twice, while Brandon has not been selected at all.</p>
<p>The sampling from the estimated population via sampling from the observed data is called bootstrapping because we are making no distributional assumptions about where the data came from, and the idiom “Pulling yourself up by your bootstraps” seemed appropriate.</p>
<p><strong>Example</strong>: Mercury Levels in Fish from Florida Lakes</p>
<p>A data set provided by the Lock<span class="math inline">\(^{5}\)</span> introductory statistics textbook looks at the mercury levels in fish harvested from lakes in Florida. There are approximately 7,700 lakes in Florida that are larger than 10 acres. As part of a study to assess the average mercury contamination in these lakes, a random sample of <span class="math inline">\(n=53\)</span> lakes, an unspecified number of fish were harvested and the average mercury level (in ppm) was calculated for fish in each lake. The goal of the study was to assess if the average mercury concentration was greater than the 1969 EPA “legally actionable level” of 0.5 ppm.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read the Lakes data set</span>
Lakes &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;http://www.lock5stat.com/datasets/FloridaLakes.csv&#39;</span>)
<span class="co"># make a nice picture... dot plots are very similar to histograms</span>
<span class="co"># but in this case, my y-axis doen&#39;t make any sense.</span>
<span class="kw">ggplot</span>(Lakes, <span class="kw">aes</span>(<span class="dt">x=</span>AvgMercury)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_dotplot</span>()</code></pre></div>
<pre><code>## `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We can calculate mean average mercury level for the <span class="math inline">\(n=53\)</span> lakes</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Lakes <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>( AvgMercury ))</code></pre></div>
<pre><code>##        xbar
## 1 0.5271698</code></pre>
<p>The sample mean is greater than <span class="math inline">\(0.5\)</span> but not by too much. Is a true population mean concentration <span class="math inline">\(\mu_{Hg}\)</span> that is <span class="math inline">\(0.5\)</span> or less incompatible with our observed data? Is our data sufficient evidence to conclude that the average mercury content is greater than <span class="math inline">\(0.5\)</span>? Perhaps the true average mercury content is less than (or equal to) <span class="math inline">\(0.5\)</span> and we just happened to get a random sample that with a mean greater than <span class="math inline">\(0.5\)</span>?</p>
<p>The first step in answering these questions is to create an estimate of the sampling distribution of <span class="math inline">\(\bar{x}_{Hg}\)</span>. To do this, we will sample from the approximate population of lakes, which is just many many replicated copies of our sample data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create the Estimated Sampling Distribution of xbar</span>
BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>mosaic<span class="op">::</span><span class="kw">resample</span>(Lakes) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(AvgMercury))

<span class="co"># what columns does the data frame &quot;BootDist&quot; have?</span>
<span class="kw">head</span>(BootDist)</code></pre></div>
<pre><code>##        xbar
## 1 0.5111321
## 2 0.5043396
## 3 0.5252830
## 4 0.5362264
## 5 0.4992453
## 6 0.5960377</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># show a histogram of the estimated sampling distribution of xbar</span>
<span class="kw">ggplot</span>(BootDist, <span class="kw">aes</span>(<span class="dt">x=</span>xbar)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Estimated Sampling distribution of xbar&#39;</span> )</code></pre></div>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="quantile-based-confidence-intervals" class="section level2">
<h2><span class="header-section-number">3.2</span> Quantile-based Confidence Intervals</h2>
<p>In many cases we have seen, the sampling distribution of a statistic is centered on the parameter we are interested in estimating and is symmetric about that parameter. There are actually several ways to create a confidence interval from the estimated sampling distribution. The method presented here is called the “percentile” method and works when the sampling distribution is symmetric and the estimator we are using is unbiased. For example, we expect that the sample mean <span class="math inline">\(\bar{x}\)</span> should be a good estimate of the population mean <span class="math inline">\(\mu\)</span> and the sampling distribution of <span class="math inline">\(\bar{x}\)</span> should look something like the following.</p>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>There are two points, (call them <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span>) where for our given sample size and population we are sampling from, where we expect that <span class="math inline">\(95\%\)</span> of the sample means to fall within. That is to say, <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> capture the middle <span class="math inline">\(95\%\)</span> of the sampling distribution of <span class="math inline">\(\bar{x}\)</span>.</p>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>These sample means are randomly distributed about the population mean <span class="math inline">\(\mu\)</span>. Given our sample data and sample mean <span class="math inline">\(\bar{x}\)</span>, we can examine how our simulated values of <span class="math inline">\(\bar{x}^{*}\)</span> vary about <span class="math inline">\(\bar{x}\)</span>. I expect that these simulated sample means <span class="math inline">\(\bar{x}^{*}\)</span> should vary about <span class="math inline">\(\bar{x}\)</span> in the same way that <span class="math inline">\(\bar{x}\)</span> values vary around <span class="math inline">\(\mu\)</span>. Below are three estimated sampling distributions that we might obtain from three different samples and their associated sample means.</p>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>For each possible sample, we could consider creating the estimated sampling distribution of <span class="math inline">\(\bar{X}\)</span> and calculating the <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> values that capture the middle <span class="math inline">\(95\%\)</span> of the estimated sampling distribution. Below are twenty samples, where we’ve calculated this interval for each sample.</p>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Most of these intervals contain the true parameter <span class="math inline">\(\mu\)</span>, that we are trying to estimate. In practice, I will only take one sample and therefore will only calculate one sample mean and one interval, but I want to recognize that the method I used to produce the interval (i.e. take a random sample, calculate the mean and then the interval) will result in intervals where only <span class="math inline">\(95\%\)</span> of those intervals will contain the mean <span class="math inline">\(\mu\)</span>. Therefore, I will refer to the interval as a <span class="math inline">\(95\%\)</span> confidence interval.</p>
<p>After the sample is taken and the interval is calculated, the numbers lower and upper bounds of the confidence interval are fixed. Because <span class="math inline">\(\mu\)</span> is a constant value and the confidence interval is fixed, nothing is changing. To distinguish between a future random event and the fixed (but unknown) outcome of if I ended up with an interval that contains <span class="math inline">\(\mu\)</span> and we use the term confidence interval instead of probability interval.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create the Estimated Sampling Distribution of xbar</span>
BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10</span>) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>mosaic<span class="op">::</span><span class="kw">resample</span>(Lakes) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(AvgMercury))

<span class="co"># show a histogram of the estimated sampling distribution of xbar</span>
<span class="kw">ggplot</span>(BootDist, <span class="kw">aes</span>(<span class="dt">x=</span>xbar, <span class="dt">y=</span>..density..)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Estimated Sampling distribution of xbar&#39;</span>)</code></pre></div>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># calculate the 95% confidence interval using middle 95% of xbars</span>
<span class="kw">quantile</span>( BootDist<span class="op">$</span>xbar, <span class="dt">probs=</span><span class="kw">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>) )</code></pre></div>
<pre><code>##      2.5%     97.5% 
## 0.4803066 0.6067217</code></pre>
<p>There are several ways to interpret this interval.</p>
<ol style="list-style-type: decimal">
<li><p>The process used to calculate this interval (take a random sample, calculate a statistic, repeatedly re-sample, and take the middle <span class="math inline">\(95\%\)</span>) is a process that results in an interval that contains the parameter of interest on <span class="math inline">\(95\%\)</span> of the samples we could have collected, however we don’t know if the particular sample we collected and its resulting interval of <span class="math inline">\(\left(0.44,\,0.62\right)\)</span> is one of the intervals containing <span class="math inline">\(\mu\)</span>.</p></li>
<li><p>We are <span class="math inline">\(95\%\)</span> confident that <span class="math inline">\(\mu\)</span> is in the interval <span class="math inline">\(\left(0.44,\,0.62\right)\)</span>. This is delightfully vague and should be interpreted as a shorter version of the previous interpretation.</p></li>
<li><p>The interval <span class="math inline">\(\left(0.44,\,0.62\right)\)</span> is the set of values of <span class="math inline">\(\mu\)</span> that are consistent with the observed data at the <span class="math inline">\(0.05\)</span> threshold of statistical significance for a two-sided hypothesis test</p></li>
</ol>
<p><strong>Example</strong>: Fuel Economy</p>
<p>Suppose we have data regarding fuel economy of <span class="math inline">\(5\)</span> new vehicles of the same make and model and we wish to test if the observed fuel economy is consistent with the advertised <span class="math inline">\(31\)</span> mpg at highway speeds. We the data are</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CarMPG &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">ID=</span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="dt">mpg =</span> <span class="kw">c</span>(<span class="fl">31.8</span>, <span class="fl">32.1</span>, <span class="fl">32.5</span>, <span class="fl">30.9</span>, <span class="fl">31.3</span>) )
CarMPG <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">xbar=</span><span class="kw">mean</span>(mpg) )</code></pre></div>
<pre><code>##    xbar
## 1 31.72</code></pre>
<p>We will use the sample mean to assess if the sample fuel efficiency is consistent with the advertised number. Because these cars could be considered a random sample of all new cars of this make, we will create the estimated sampling distribution using the bootstrap re-sampling of the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>mosaic<span class="op">::</span><span class="kw">resample</span>(CarMPG) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(mpg))

<span class="co"># show a histogram of the sampling distribution of xbar</span>
<span class="kw">ggplot</span>(BootDist, <span class="kw">aes</span>(<span class="dt">x=</span>xbar)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Estimated Sampling distribution of xbar&#39;</span>)</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># calculate the 95% confidence interval using middle 95% of xbars</span>
<span class="kw">quantile</span>( BootDist<span class="op">$</span>xbar, <span class="dt">probs=</span><span class="kw">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>) )</code></pre></div>
<pre><code>##  2.5% 97.5% 
## 31.22 32.20</code></pre>
<p>We see that the <span class="math inline">\(95\%\)</span> confidence interval is <span class="math inline">\(\left(31.2,\,32.2\right)\)</span> and does not actually contain the advertised <span class="math inline">\(31\)</span> mpg. However, I don’t think we would object to a car manufacturer selling us a car that is better than advertised.</p>
<p><strong>Example</strong>: Pulse Rate of College Students</p>
<p>In the package Lock5Data, the dataset <code>GPAGender</code> contains information taken from undergraduate students in an Introductory Statistics course. This is a convenience sample, but could be considered representative of students at that university. One of the covariates measured was the students pulse rate and we will use this to create a confidence interval for average pulse of students at that university.</p>
<p>First we’ll look at the raw data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(GPAGender, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)     <span class="co"># load the dataset</span>

<span class="co"># Now a nice histogram</span>
<span class="kw">ggplot</span>(GPAGender, <span class="kw">aes</span>(<span class="dt">x=</span>Pulse, <span class="dt">y=</span>..density..)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Sample Data&#39;</span>)</code></pre></div>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>It is worth noting this was supposed to be measuring resting heart rates, but there are two students had extremely high pulse rates and six with extremely low rates. The two high values are approximately what you’d expect from someone currently engaged in moderate exercise and the low values are levels we’d expect from highly trained endurance athletes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Summary Statistics</span>
GPAGender <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(Pulse),
                        <span class="dt">StdDev =</span> <span class="kw">sd</span>(Pulse))</code></pre></div>
<pre><code>##       xbar   StdDev
## 1 69.90379 12.08569</code></pre>
<p>So the sample mean is <span class="math inline">\(\bar{x}=69.9\)</span> but how much should we expect our sample mean to vary from sample to sample when our sample size is <span class="math inline">\(n=343\)</span> people? We’ll estimate the sampling distribution of <span class="math inline">\(\bar{X}\)</span> using the bootstrap.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create the bootstrap replicates</span>
BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>mosaic<span class="op">::</span><span class="kw">resample</span>(GPAGender) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(Pulse))

<span class="kw">ggplot</span>(BootDist, <span class="kw">aes</span>(<span class="dt">x=</span>xbar, <span class="dt">y=</span>..density..)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Sampling Distribution of Mean(Pulse)&#39;</span>)</code></pre></div>
<p><img src="03_Bootstrapping_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Just by sampling variability, we expect the sampling mean <span class="math inline">\(\bar{X}\)</span> to vary from approximately 68 to 72. The appropriate quantiles for a <span class="math inline">\(95\%\)</span> bootstrap confidence interval are actually</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>( BootDist<span class="op">$</span>xbar, <span class="dt">probs=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>) )</code></pre></div>
<pre><code>##     2.5%    97.5% 
## 68.65306 71.20707</code></pre>
</div>
<div id="exercises-2" class="section level2">
<h2><span class="header-section-number">3.3</span> Exercises</h2>
<p>For several of these exercises, we will use data sets from the R package <code>Lock5Data</code>, which greatly contributed to the pedagogical approach of these notes. Install the package from CRAN using the RStudio point-and-click interface <code>Tools -&gt; Install Packages</code>….</p>
<ol style="list-style-type: decimal">
<li><p>Load the dataset <code>BodyTemp50</code> from the Lock5Data package. This is a dataset of 50 healthy adults. Unfortunately the documentation doesn’t give how the data was collected, but for this problem we’ll assume that it is a representative sample of healthy US adults.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>( BodyTemp50, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span> )
?BodyTemp50</code></pre></div>
<pre><code>## No documentation for &#39;BodyTemp50&#39; in specified packages and libraries:
## you could try &#39;??BodyTemp50&#39;</code></pre>
<p>One of the columns of this dataset is the Pulse of the 50 data points, which is the number of heartbeats per minute.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a histogram of the observed pulse values. Comment on the graph and aspects of the graph that might be of scientific interest.</li>
<li>Calculate the sample mean <span class="math inline">\(\bar{x}\)</span> and sample standard deviation <span class="math inline">\(s\)</span> of the pulses.</li>
<li>Create a dataset of 10000 bootstrap replicates of <span class="math inline">\(\bar{x}^{*}\)</span>.</li>
<li>Create a histogram of the bootstrap replicates. Calculate the mean and standard deviation of this distribution. Notice that the standard deviation of the distribution is often called the Standard Error of <span class="math inline">\(\bar{x}\)</span> and we’ll denote it as <span class="math inline">\(\hat{\sigma}_{\bar{x}}\)</span>.</li>
<li>Using the bootstrap replicates, create a 95% confidence interval for <span class="math inline">\(\mu\)</span>, the average adult heart rate.</li>
<li>Calculate the interval <span class="math display">\[\left(\bar{x}-2\cdot\hat{\sigma}_{\bar{x}}\,,\,\;\;\bar{x}+2\cdot\hat{\sigma}_{\bar{x}}\right)\]</span> and comment on its similarity to the interval you calculated in part (e).</li>
</ol></li>
<li>Load the dataset <code>EmployedACS</code> from the <code>Lock5Data</code> package. This is a dataset drawn from American Community Survey results which is conducted monthly by the US Census Bureau and should be representative of US workers. The column <code>HoursWk</code> represents the number of hours worked per week.
<ol style="list-style-type: lower-alpha">
<li>Create a histogram of the observed hours worked. Comment on the graph and aspects of the graph that might be of scientific interest.</li>
<li>Calculate the sample mean <span class="math inline">\(\bar{x}\)</span> and sample standard deviation <span class="math inline">\(s\)</span> of the worked hours per week.</li>
<li>Create a dataset of 10000 bootstrap replicates of <span class="math inline">\(\bar{x}^{*}\)</span>.</li>
<li>Create a histogram of the bootstrap replicates. Calculate the mean and standard deviation of this distribution. Notice that the standard deviation of the distribution is often called the Standard Error of <span class="math inline">\(\bar{x}\)</span> and we’ll denote it as <span class="math inline">\(\sigma_{\bar{x}}\)</span>.</li>
<li>Using the bootstrap replicates, create a 95% confidence interval for <span class="math inline">\(\mu\)</span>, the average worked hours per week.</li>
<li>Calculate the interval <span class="math display">\[\left(\bar{x}-2\cdot\hat{\sigma}_{\bar{x}}\,,\,\;\;\bar{x}+2\cdot\hat{\sigma}_{\bar{x}}\right)\]</span> and comment on its similarity to the interval you calculated in part (e).</li>
</ol></li>
</ol>
<!--chapter:end:03_Bootstrapping.Rmd-->
</div>
</div>
<div id="sampling-distribution-of-barx" class="section level1">
<h1><span class="header-section-number">4</span> Sampling Distribution of <span class="math inline">\(\bar{X}\)</span></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the ggplot2 and dplyr packages... which I use constantly.</span>
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())

<span class="co"># other packages I&#39;ll only use occasionally so instead of loading the</span>
<span class="co"># whole package, I&#39;ll just do packageName::functionName() when I use</span>
<span class="co"># the function.</span></code></pre></div>
<p>In the previous chapter, we using bootstrapping to estimate the sampling distribution of <span class="math inline">\(\bar{X}\)</span>. We then used this bootstrap distribution to calculate a confidence interval for the population mean. We noticed that the sampling distribution of <span class="math inline">\(\bar{X}\)</span> almost always looked like a normal distribution. Prior to the advent of modern computing, statisticians used a theoretical approximation known as the Central Limit Theorem (CLT). Even today, statistical procedures based on the CLT are widely used and often perform as the corresponding re-sampling technique. In this chapter we’ll lay the theoretical foundations for the CLT as well as introduce computation</p>
<div id="enlightening-example" class="section level2">
<h2><span class="header-section-number">4.1</span> Enlightening Example</h2>
<p>Suppose we are sampling from a population that has a mean of <span class="math inline">\(\mu=5\)</span> and is skewed. For this example, I’ll use a Chi-squared distribution with parameter <span class="math inline">\(\nu=5\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Population is a Chi-sq distribution with df=5 </span>
PopDist &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">20</span>,<span class="dt">length=</span><span class="dv">10000</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density=</span><span class="kw">dchisq</span>(x,<span class="dt">df=</span><span class="dv">5</span>))

<span class="kw">ggplot</span>(PopDist, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>density)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill=</span><span class="st">&#39;salmon&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Population Distribution&#39;</span>)</code></pre></div>
<p><img src="04_SamplingDistribution_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We want to estimate the mean <span class="math inline">\(\mu\)</span> and take a random sample of <span class="math inline">\(n=5\)</span>. Lets do this a few times and notice that the sample mean is never exactly 5, but is a bit off from that.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">5</span>  <span class="co"># Our Sample Size!</span>
mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span>{
  Sample.Data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x =</span> <span class="kw">rchisq</span>(n,<span class="dt">df=</span><span class="dv">5</span>) )
  Sample.Data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">xbar =</span> <span class="kw">mean</span>(x) )
}</code></pre></div>
<pre><code>##       xbar
## 1 4.327771
## 2 7.053190
## 3 4.878844</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">5</span>
SampDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>{
  Sample.Data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x =</span> <span class="kw">rchisq</span>(n,<span class="dt">df=</span><span class="dv">5</span>) )
  Sample.Data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">xbar =</span> <span class="kw">mean</span>(x)     ) 
}</code></pre></div>
<p>We will compare the population distribution to the sampling distribution graphically.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span>PopDist, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>density), <span class="dt">fill=</span><span class="st">&#39;salmon&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">data=</span>SampDist, <span class="kw">aes</span>(<span class="dt">x=</span>xbar, <span class="dt">y=</span>..density..),
                  <span class="dt">binwidth=</span>.<span class="dv">1</span>,
                  <span class="dt">alpha=</span>.<span class="dv">6</span>)     <span class="co"># alpha is the opacity of the layer</span></code></pre></div>
<p><img src="04_SamplingDistribution_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>From the histogram of the sample means, we notice three things:</p>
<ul>
<li>The sampling distribution of <span class="math inline">\(\bar{X}\)</span> is centered at the population mean <span class="math inline">\(\mu\)</span>.</li>
<li>The sampling distribution of <span class="math inline">\(\bar{X}\)</span> has less spread than the population distribution.</li>
<li>The sampling distribution of <span class="math inline">\(\bar{X}\)</span> is less skewed than the population distribution.</li>
</ul>
</div>
<div id="mathematical-details" class="section level2">
<h2><span class="header-section-number">4.2</span> Mathematical details</h2>
<div id="probability-rules-for-expectations-and-variances" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Probability Rules for Expectations and Variances</h3>
<p>Claim: For random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and constant <span class="math inline">\(a\)</span> the following statements hold: <span class="math display">\[E\left(aX\right)  =   aE\left(X\right)\]</span> <span class="math display">\[Var\left(aX\right)    =   a^{2}Var\left(X\right)\]</span> <span class="math display">\[E\left(X+Y\right) =   E\left(X\right)+E\left(Y\right)\]</span> <span class="math display">\[E\left(X-Y\right) =   E\left(X\right)-E\left(Y\right)\]</span> <span class="math display">\[Var\left(X\pm Y\right)    =   Var\left(X\right)+Var\left(Y\right)\;\textrm{if X,Y are independent}\]</span></p>
<p>Proving these results is relatively straight forward and is done in almost all introductory probability text books.</p>
</div>
<div id="mean-and-variance-of-the-sample-mean" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Mean and Variance of the Sample Mean</h3>
<p>We have been talking about random variables drawn from a known distribution and being able to derive their expected values and variances. We now turn to the mean of a collection of random variables. Because sample values are random, any function of them is also random. So even though the act of calculating a mean is not a random process, the numbers that are feed into the algorithm are random. Thus the sample mean will change from sample to sample and we are interested in how it varies.</p>
<p>Using the rules we have just confirmed, it is easy to calculate the expectation and variance of the sample mean. Given a sample <span class="math inline">\(X_{1},X_{2},\dots,X_{n}\)</span> of observations where all the observations are independent of each other and all the observations have expectation <span class="math inline">\(E\left[X_{i}\right]=\mu\)</span> and variance <span class="math inline">\(Var\left[X_{i}\right]=\sigma^{2}\)</span> then <span class="math display">\[\begin{aligned}E\left[\bar{X}\right]  
  &amp;=    E\left[\frac{1}{n}\sum_{i=1}^{n}X_{i}\right] \\
    &amp;=  \frac{1}{n}E\left[\sum_{i=1}^{n}X_{i}\right] \\
    &amp;=  \frac{1}{n}\sum_{i=1}^{n}E\left[X_{i}\right] \\
    &amp;=  \frac{1}{n}\sum_{i=1}^{n}\mu                 \\
    &amp;=  \frac{1}{n}\,n\mu                            \\
    &amp;=  \mu\end{aligned}\]</span> and <span class="math display">\[\begin{aligned} Var\left[\bar{X}\right]                 
  &amp;=    Var\left[\frac{1}{n}\sum_{i=1}^{n}X_{i}\right]       \\
    &amp;=  \frac{1}{n^{2}}Var\left[\sum_{i=1}^{n}X_{i}\right]   \\
    &amp;=  \frac{1}{n^{2}}\sum_{i=1}^{n}Var\left[X_{i}\right]   \\
    &amp;=  \frac{1}{n^{2}}\sum_{i=1}^{n}\sigma^{2}              \\
    &amp;=  \frac{1}{n^{2}}\,n\sigma^{2}                         \\
    &amp;=  \frac{\sigma^{2}}{n}
    \end{aligned}\]</span></p>
<p>Notice that the sample mean has the same expectation as the original distribution that the samples were pulled from, but it has a smaller variance! So the sample mean is an unbiased estimator of the population mean <span class="math inline">\(\mu\)</span> and the average distance of the sample mean to the population mean decreases as the sample size becomes larger.</p>
</div>
</div>
<div id="distribution-of-barx" class="section level2">
<h2><span class="header-section-number">4.3</span> Distribution of <span class="math inline">\(\bar{X}\)</span></h2>
<p>If the samples were drawn from a normal distribution</p>
<p>If <span class="math inline">\(X_{i}\stackrel{iid}{\sim}N\left(\mu,\sigma^{2}\right)\)</span> then it is well known (and proven in most undergraduate probability classes) that <span class="math inline">\(\bar{X}\)</span> is also normally distributed with a mean and variance that were already established. That is <span class="math display">\[\bar{X}\sim N\left(\mu_{\bar{X}}=\mu,\;\sigma_{\bar{X}}^{2}=\frac{\sigma^{2}}{n}\right)\]</span></p>
<p>Notation: Because the expectations of <span class="math inline">\(X\)</span> and <span class="math inline">\(\bar{X}\)</span> are the same, I could drop the subscript for the expectation of <span class="math inline">\(\bar{X}\)</span> but it is sometimes helpful to be precise. Because the variances are different we will use <span class="math inline">\(\sigma_{\bar{X}}\)</span> to denote the standard deviation of <span class="math inline">\(\bar{X}\)</span> and <span class="math inline">\(\sigma_{\bar{X}}^{2}\)</span> to denote variance of <span class="math inline">\(\bar{X}\)</span>. If there is no subscript, we are referring to the population parameter of the distribution from which we taking the sample from.</p>
<p>Exercise: A researcher measures the wingspan of a captured Mountain Plover three times. Assume that each of these <span class="math inline">\(X_{i}\)</span> measurements comes from a <span class="math inline">\(N\left(\mu=6\textrm{ inches},\,\sigma^{2}=1^{2}\textrm{ inch}\right)\)</span> distribution.</p>
<ol style="list-style-type: decimal">
<li><p>What is the probability that the first observation is greater than 7? <span class="math display">\[\begin{aligned}P\left(X\ge7\right)    
  &amp;=    P\left(\frac{X-\mu}{\sigma}\ge\frac{7-6}{1}\right)  \\
&amp;=  P\left(Z\ge1\right)                                 \\
&amp;=  0.1587
  \end{aligned}\]</span></p></li>
<li><p>What is the distribution of the sample mean? <span class="math display">\[\bar{X}\sim N\left(\mu_{\bar{X}}=6,\,\;\sigma_{\bar{X}}^{2}=\frac{1^{2}}{3}\right)\]</span></p></li>
<li><p>What is the probability that the sample mean is greater than 7? <span class="math display">\[\begin{aligned}P\left(\bar{X}\ge7\right)                                                     
  &amp;=    P\left(\frac{\bar{X}-\mu_{\bar{X}}}{\sigma_{\bar{X}}}\ge\frac{7-6}{\sqrt{\frac{1}{3}}}\right)  \\
&amp;=  P\left(Z\ge\sqrt{3}\right)    \\
&amp;=  P\left(Z\ge1.73\right) \\
&amp;=  0.0418
\end{aligned}\]</span></p></li>
</ol>
<p>Example: Suppose that the weight of an adult black bear is normally distributed with standard deviation <span class="math inline">\(\sigma=50\)</span> pounds. How large a sample do I need to take to be <span class="math inline">\(95\%\)</span> certain that my sample mean is within <span class="math inline">\(10\)</span> pounds of the true mean <span class="math inline">\(\mu\)</span>?</p>
<p>So we want <span class="math display">\[\left|\bar{X}-\mu\right| \le 10\]</span> which we rewrite as <span class="math display">\[-10    \le\bar{X}-\mu_{\bar{X}}\le 10\]</span></p>
<p><span class="math display">\[\frac{-10}{\left(\frac{50}{\sqrt{n}}\right)}  \le\frac{\bar{X}-\mu_{\bar{X}}}{\sigma_{\bar{X}}}\le    \frac{10}{\left(\frac{50}{\sqrt{n}}\right)}\]</span></p>
<p><span class="math display">\[\frac{-10}{\left(\frac{50}{\sqrt{n}}\right)}  \le Z\le    \frac{10}{\left(\frac{50}{\sqrt{n}}\right)}\]</span></p>
<p>Next we look in our standard normal table to find a <span class="math inline">\(z\)</span>-value such that <span class="math inline">\(P\left(-z\le Z\le z\right)=0.95\)</span> and that value is <span class="math inline">\(z=1.96\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">z=</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">length=</span><span class="dv">1000</span>) ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">y =</span> <span class="kw">dnorm</span>(z) )
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>z, <span class="dt">y=</span>y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>( <span class="dt">data =</span> data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">abs</span>(z) <span class="op">&lt;=</span><span class="st"> </span><span class="fl">1.96</span>), <span class="dt">fill=</span><span class="st">&#39;grey&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">7</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>( <span class="dt">x=</span><span class="dv">0</span>, <span class="dt">y=</span>.<span class="dv">2</span>, <span class="dt">label=</span><span class="st">&#39;95%&#39;</span>)</code></pre></div>
<p><img src="04_SamplingDistribution_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>So all we need to do is solve the following equation for <span class="math inline">\(n\)</span> <span class="math display">\[1.96  =   \frac{10}{ \left( \frac{50}{\sqrt{n}} \right) }\]</span> <span class="math display">\[\frac{1.96}{10}\left(50\right)    =   \sqrt{n}\]</span> <span class="math display">\[96    \approx n\]</span></p>
</div>
<div id="central-limit-theorem" class="section level2">
<h2><span class="header-section-number">4.4</span> Central Limit Theorem</h2>
<blockquote>
<p>I know of scarcely anything so apt to impress the imagination as the wonderful form of cosmic order expressed by the “Law of Frequency of Error”. The law would have been personified by the Greeks and deified, if they had known of it. It reigns with serenity and in complete self-effacement, amidst the wildest confusion. The huger the mob, and the greater the apparent anarchy, the more perfect is its sway. It is the supreme law of Unreason. Whenever a large sample of chaotic elements are taken in hand and marshaled in the order of their magnitude, an unsuspected and most beautiful form of regularity proves to have been latent all along. - Sir Francis Galton (1822-1911)</p>
</blockquote>
<p>It was not surprising that the average of a number of normal random variables is also a normal random variable. Because the average of a number of binomial random variables cannot be binomial since the average could be something besides a <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> and the average of Poisson random variables does not have to be an integer. The question arises, what can we say the distribution of the sample mean if the data comes from a non-normal distribution? The answer is quite a lot! Provided the distribution sample from has a non-infinite variance and we have a sufficient sample size.</p>
<p><strong>Central Limit Theorem</strong></p>
<p>Let <span class="math inline">\(X_{1},\dots X_{n}\)</span> be independent observations collected from a distribution with expectation <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>. Then the distribution of <span class="math inline">\(\bar{X}\)</span> converges to a normal distribution with expectation <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}/n\)</span> as <span class="math inline">\(n\rightarrow\infty\)</span>.</p>
<p>In practice this means that if <span class="math inline">\(n\)</span> is large (usually <span class="math inline">\(n&gt;30\)</span> is sufficient), then <span class="math display">\[\bar{X}\stackrel{\cdot}{\sim}N\left(\mu_{\bar{X}}=\mu,\,\,\,\sigma_{\bar{X}}^{2}=\frac{\sigma^{2}}{n}\right)\]</span></p>
<p>So what does this mean?</p>
<ol style="list-style-type: decimal">
<li><p>Variables that are the sum or average of a bunch of other random variables will be close to normal. Example: human height is determined by genetics, prenatal nutrition, food abundance during adolescence, etc. Similar reasoning explains why the normal distribution shows up surprisingly often in natural science.</p></li>
<li><p>With sufficient data, the sample mean will have a known distribution and we can proceed as if the sample mean came from a normal distribution.</p></li>
</ol>
<p>Example: Suppose the waiting time from order to delivery at a fast-food restaurant is a exponential random variable with rate <span class="math inline">\(\lambda=1/2\)</span> minutes and so the expected wait time is <span class="math inline">\(2\)</span> minutes and the variance is <span class="math inline">\(4\)</span> minutes. What is the approximate probability that we observe a sample of size <span class="math inline">\(n=40\)</span> with a mean time greater than <span class="math inline">\(2.5\)</span> minutes?</p>
<p><span class="math display">\[\begin{aligned}P\left(\bar{X}\ge2.5\right)
  &amp;=    P\left(\frac{\bar{X}-\mu_{\bar{X}}}{\sigma_{\bar{X}}}\ge\frac{2.5-\mu_{\bar{X}}}{\sigma_{\bar{X}}}\right) \\
    &amp;\approx    P\left(Z\ge\frac{2.5-2}{\frac{2}{\sqrt{40}}}\right) \\
    &amp;=  P\left(Z\ge1.58\right) \\
    &amp;=  0.0571 \end{aligned}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Answer obtained via simulation</span>
SampDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span>{                     <span class="co"># make 10,000</span>
  Sample &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x=</span> <span class="kw">rexp</span>(<span class="dt">n=</span><span class="dv">40</span>, <span class="dt">rate=</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> ) )   <span class="co"># simulated xbar </span>
  Sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">xbar =</span> <span class="kw">mean</span>( x )         )   <span class="co"># values</span>
}
SampDist <span class="op">%&gt;%</span><span class="st">                                         </span><span class="co"># What proportion of those</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Greater =</span> <span class="kw">ifelse</span>(xbar <span class="op">&gt;=</span><span class="st"> </span><span class="fl">2.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># xbar values are</span>
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">ProportionGreater =</span> <span class="kw">mean</span>(Greater) )     <span class="co"># greater than 2.5?</span></code></pre></div>
<pre><code>##   ProportionGreater
## 1            0.0621</code></pre>
<p><strong>Summary</strong></p>
<p>Often we have sampled <span class="math inline">\(n\)</span> elements from some population <span class="math inline">\(Y_{1},Y_{2},\dots,Y_{n}\)</span> independently and <span class="math inline">\(E\left(Y_{i}\right)=\mu\)</span> and <span class="math inline">\(Var\left(Y_{i}\right)=\sigma^{2}\)</span> and we want to understand the distribution of the sample mean, that is we want to understand how the sample mean varies from sample to sample.</p>
<p><span class="math inline">\(E\left(\bar{Y}\right)=\mu\)</span>. That states that the distribution of the sample mean will centered at <span class="math inline">\(\mu\)</span>. We expect to sometimes take samples where the sample mean is higher than <span class="math inline">\(\mu\)</span> and sometimes less than <span class="math inline">\(\mu\)</span>, but the average underestimate is the same magnitude as the average overestimate.</p>
<p><span class="math inline">\(Var\left(\bar{Y}\right)=\frac{\sigma^{2}}{n}\)</span>. This states that as our sample size increases, we trust the sample mean to be close to <span class="math inline">\(\mu\)</span>. The larger the sample size, the greater our expectation that the <span class="math inline">\(\bar{Y}\)</span> will be close to <span class="math inline">\(\mu\)</span>.</p>
<p>If <span class="math inline">\(Y_{1},Y_{2},\dots,Y_{n}\)</span> were sampled from a <span class="math inline">\(N\left(\mu,\sigma^{2}\right)\)</span> distribution then <span class="math inline">\(\bar{Y}\)</span> is normally distributed. <span class="math display">\[\bar{Y} \sim    N\left(\mu_{\bar{Y}}=\mu,\;\;\sigma_{\bar{Y}}^{2}=\frac{\sigma^{2}}{n}\right)\]</span></p>
<p>If <span class="math inline">\(Y_{1},Y_{2},\dots,Y_{n}\)</span> were sampled from a distribution that is <em>not</em> normal but has mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>, and our sample size is large, then <span class="math inline">\(\bar{Y}\)</span> is <em>approximately</em> normally distributed. <span class="math display">\[\bar{Y}   \stackrel{\cdot}{\sim}  N\left(\mu_{\bar{Y}}=\mu,\;\;\sigma_{\bar{Y}}^{2}=\frac{\sigma^{2}}{n}\right)\]</span></p>
</div>
<div id="exercises-3" class="section level2">
<h2><span class="header-section-number">4.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Suppose that the amount of fluid in a small can of soda can be well approximated by a Normal distribution. Let <span class="math inline">\(X\)</span> be the amount of soda (in milliliters) in a single can and <span class="math inline">\(X\sim N\left(\mu=222,\;\sigma=5\right)\)</span>.
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(P\left(X&gt;230\right)=\)</span></li>
<li>Suppose we take a random sample of 6 cans such that the six cans are independent. What is the expected value of the mean of those six cans? In other words, what is <span class="math inline">\(E\left(\bar{X}\right)\)</span>?</li>
<li>What is <span class="math inline">\(Var\left(\bar{X}\right)\)</span>? (Recall we denote this as <span class="math inline">\(\sigma_{\bar{X}}^{2}\)</span>)</li>
<li>What is the standard deviation of <span class="math inline">\(\bar{X}\)</span>? (Recall we denote this as <span class="math inline">\(\sigma_{\bar{X}}\)</span>)</li>
<li>What is the probability that the sample mean will be greater than 230 ml? That is, find <span class="math inline">\(P\left(\bar{X}&gt;230\right)\)</span>.</li>
</ol></li>
<li>Suppose that the number of minutes that I spend waiting for my order at Big Foot BBQ can be well approximated by a Normal distribution with mean <span class="math inline">\(\mu=10\)</span> minutes and standard deviation <span class="math inline">\(\sigma=1.5\)</span> minutes.
<ol style="list-style-type: lower-alpha">
<li>Tonight I am planning on going to Big Foot BBQ. What is the probability I have to wait less than 9 minutes?</li>
<li>Over the next month, I’ll visit Big Foot BBQ 5 times. What is the probability that the mean waiting time of those 5 visits is less than 9 minutes? (This assumes independence of visits but because I don’t hit the same restaurant the same night each week, this assumption is probably OK.)</li>
</ol></li>
<li>Suppose that we have a population with the following distribution that has mean <span class="math inline">\(\mu=5.2\)</span> and standard deviation <span class="math inline">\(\sigma=3.0\)</span>: <img src="04_SamplingDistribution_files/figure-html/Ch3_HistogramMatching-1.png" width="672" />
<ol style="list-style-type: lower-alpha">
<li>Which of the histograms would most likely represent the distribution of the sample mean <span class="math inline">\(\bar{x}\)</span> of <span class="math inline">\(n=4\)</span> observations?<br />
</li>
<li>Which of the histograms would most likely represent the distribution of the sample mean <span class="math inline">\(\bar{x}\)</span> of <span class="math inline">\(n=30\)</span> observations?</li>
<li>Justify your choices in parts (a) and (b).</li>
</ol></li>
<li>A bottling company uses a machine to fill bottles with a tasty beverage. The bottles are advertised to contain 300 milliliters (ml), but in reality the amount varies according to a normal distribution with mean <span class="math inline">\(\mu=298\)</span> ml and standard deviation <span class="math inline">\(\sigma=3\)</span> ml. (For this problem, we’ll assume <span class="math inline">\(\sigma\)</span> is known and carry out the calculations accordingly).
<ol style="list-style-type: lower-alpha">
<li>What is the probability that a randomly chosen bottle contains less than 296 ml?</li>
<li>Given a simple random sample of size <span class="math inline">\(n=6\)</span> bottles, what is the probability that the sample mean is less than <span class="math inline">\(296\)</span> ml?</li>
<li>What is the probability that a single bottle is filled within <span class="math inline">\(1\)</span> ml of the true mean <span class="math inline">\(\mu=298\)</span> ml? <em>Hint: Draw the distribution and shade in what probability you want… then convert that to a question about standard normals. To find the answer using a table or R, you need to look up two values and perform a subtraction.</em></li>
<li>What is the probability that the mean of <span class="math inline">\(10\)</span> randomly selected bottles is within <span class="math inline">\(1\)</span> ml of the mean? What about the mean of a sample of <span class="math inline">\(n=100\)</span> bottles?</li>
<li>If a sample of size <span class="math inline">\(n=50\)</span> has a sample mean of <span class="math inline">\(\bar{x}=298\)</span>, should this be evidence that the filling machine is out of calibration? i.e., assuming the machine has a mean fill amount of <span class="math inline">\(\mu=300\)</span> and <span class="math inline">\(\sigma=3\)</span>, what is <span class="math inline">\(P\left(\bar{X}\le298\right)\)</span>?</li>
</ol></li>
</ol>
<!--chapter:end:04_SamplingDistribution.Rmd-->
</div>
</div>
<div id="confidence-intervals-for-mu" class="section level1">
<h1><span class="header-section-number">5</span> Confidence Intervals for <span class="math inline">\(\mu\)</span></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<div id="asymptotic-result-sigma-known" class="section level2">
<h2><span class="header-section-number">5.1</span> Asymptotic result (<span class="math inline">\(\sigma\)</span> known)</h2>
<p>We know that our sample mean <span class="math inline">\(\bar{x}\)</span>, should be close to the population mean <span class="math inline">\(\mu\)</span>. So when giving a region of values for <span class="math inline">\(\mu\)</span> that are consistent with the observed data, we would expect our CI formula to be something like <span class="math inline">\(\left(\bar{x}-d,\;\bar{x}+d\right)\)</span> for some value <span class="math inline">\(d\)</span>. That value of <span class="math inline">\(d\)</span> should be small if our sample size is big, representing our faith that a large amount of data should result in a statistic that is very close to the true value of <span class="math inline">\(\mu\)</span>. Recall that if our data <span class="math inline">\(X_{i}\sim N\left(\mu,\,\sigma^{2}\right)\)</span> or our sample size was large enough, then we know</p>
<p><span class="math display">\[\bar{X}\sim N\left(\mu,\,\;\sigma_{\bar{X}}^{2}=\frac{\sigma^{2}}{n}\right)\]</span> or is approximately so. Doing a little re-arranging, we see that <span class="math display">\[\frac{\bar{X}-\mu}{\left(\frac{\sigma}{\sqrt{n}}\right)}\sim N\left(0,1\right)\]</span></p>
<p>So if we take the 0.025 and 0.975 quantiles of the normal distribution, which are <span class="math inline">\(z_{0.025}=-1.96\)</span> and <span class="math inline">\(z_{0.975}=1.96\)</span>, we could write <span class="math display">\[\begin{aligned}0.95   
    &amp;=  P\left[ -1.96\le\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\le1.96 \right] \\
      &amp;=    P\left[ -1.96\left(\frac{\sigma}{\sqrt{n}}\right)\le\bar{X}-\mu\le1.96\left(\frac{\sigma}{\sqrt{n}}\right) \right] \\
    &amp;=  P\left[ \bar{X}-1.96\left(\frac{\sigma}{\sqrt{n}}\right)\le\mu\le\bar{X}+1.96\left(\frac{\sigma}{\sqrt{n}}\right) \right]
    \end{aligned}\]</span> Which suggests that a reasonable 95% Confidence Interval for <span class="math inline">\(\mu\)</span> is <span class="math display">\[\bar{x}\pm1.96\left(\frac{\sigma}{\sqrt{n}}\right)\]</span> In general for a <span class="math inline">\(\left(1-\alpha\right)\cdot100\%\)</span> confidence interval, we would use the formula <span class="math inline">\(\bar{x}\pm z_{1-\alpha/2}\left(\frac{\sigma}{\sqrt{n}}\right)\)</span>. Notice that I could write the formula using <span class="math inline">\(z_{\alpha/2}\)</span> instead of <span class="math inline">\(z_{1-\alpha/2}\)</span> because the normal distribution is symmetric about 0 and we are subtracting and adding the same quantity to <span class="math inline">\(\bar{x}\)</span>.</p>
<p>The interpretation of a confidence interval is that over repeated sampling, <span class="math inline">\(100(1-\alpha)\%\)</span> of the resulting intervals will contain the population mean <span class="math inline">\(\mu\)</span> but we don’t know if the interval we have actually observed is one of the good intervals that contains the mean <span class="math inline">\(\mu\)</span> or not. Because this is quite the mouthful, we will say “we are <span class="math inline">\(100\left(1-\alpha\right)\%\)</span> confident that the observed interval contains the mean <span class="math inline">\(\mu\)</span>.”</p>
<p>Example: Suppose a bottling facility has a machine that supposedly fills bottles to 300 milliliters (ml) and is known to have a standard deviation of <span class="math inline">\(\sigma=3\)</span> ml. However, the machine occasionally gets out of calibration and might be consistently overfilling or under-filling bottles. To discover if the machine is calibrated correctly, we take a random sample of <span class="math inline">\(n=40\)</span> bottles and observe the mean amount filled was <span class="math inline">\(\bar{x}=299\)</span> ml. We calculate a <span class="math inline">\(95\%\)</span> confidence interval (CI) to be <span class="math display">\[\begin{aligned} \bar{x}   &amp;\pm    z_{1-\alpha/2}\left(\frac{\sigma}{\sqrt{n}}\right)\\
                   299    &amp;\pm  1.96\left(\frac{3}{\sqrt{40}}\right) \\
                   299    &amp;\pm  0.93 \end{aligned}\]</span> and conclude that we are <span class="math inline">\(95\%\)</span> confident that the that the true mean fill amount is in <span class="math inline">\(\left[298.07,299.93\right]\)</span> and that the machine has likely drifted off calibration.</p>
</div>
<div id="asymptotoic-result-sigma-unknown" class="section level2">
<h2><span class="header-section-number">5.2</span> Asymptotoic result (<span class="math inline">\(\sigma\)</span> unknown)</h2>
<p>It is unrealistic to expect that we know the population variance <span class="math inline">\(\sigma^{2}\)</span> but do not know the population mean <span class="math inline">\(\mu\)</span>. So in calculations that involve <span class="math inline">\(\sigma\)</span>, we want to use the sample standard deviation <span class="math inline">\(s\)</span> instead.</p>
<p>Our previous results about confidence intervals assumed that <span class="math inline">\(\bar{X}\sim N\left(\mu,\frac{\sigma^{2}}{n}\right)\)</span> (or is approximately so) and therefore <span class="math display">\[\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}\sim N\left(0,1\right)\]</span> I want to just replace <span class="math inline">\(\sigma^{2}\)</span> with <span class="math inline">\(S^{2}\)</span> but the sample variance <span class="math inline">\(S^{2}\)</span> is also a random variable and incorporating it into the standardization function might affect the distribution. <span class="math display">\[\frac{\bar{X}-\mu}{\sqrt{\frac{S^{2}}{n}}}\sim\;???\]</span> Unfortunately this substitution of <span class="math inline">\(S^{2}\)</span> for <span class="math inline">\(\sigma^{2}\)</span> comes with a cost and this quantity is not normally distributed. Instead it has a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. However as the sample size increases and <span class="math inline">\(S^{2}\)</span> becomes a more reliable estimator of <span class="math inline">\(\sigma^{2}\)</span>, this penalty should become smaller.</p>
<p><img src="05_ConfidenceIntervals_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The <span class="math inline">\(t\)</span>-distribution is often call “Student’s t-distribution” is named after <a href="http://en.wikipedia.org/wiki/William_Sealy_Gosset">William Gosset</a> who worked at Guinness Brewing and did work with small sample sizes in both the brewery and at the farms that supplied the barley. Because Guinness prevented its employees from publishing any of their work, he published under the pseudonym “Student”.</p>
<p>Notice that as the sample size increases, the t-distribution gets closer and closer to the normal distribution. From here on out, we will use the following standardization formula: <span class="math display">\[\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}}\sim\;t_{n-1}\]</span> and emphasize that this formula is valid if the sample observations came from a population with a normal distribution or if the sample size is large enough for the Central Limit Theorem to imply that <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed.</p>
<p>Substituting the sample standard deviation into the confidence interval formula, we also substitute a t-quantile for the standard normal quantile. We will denote <span class="math inline">\(t_{n-1}^{1-\alpha/2}\)</span> as the <span class="math inline">\(1-\alpha/2\)</span> quantile of a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. Therefore we will use the following formula for the calculation of <span class="math inline">\(100\left(1-\alpha\right)\%\)</span> confidence intervals for the mean <span class="math inline">\(\mu\)</span>: <span class="math display">\[\bar{x}\pm t_{n-1}^{1-\alpha/2}\left(\frac{s}{\sqrt{n}}\right)\]</span></p>
<p>Notation: We will be calculating confidence intervals for the rest of the course and it is useful to recognize the skeleton of a confidence interval formula. The basic form is always the same <span class="math display">\[Estimate\;\pm\,t_{df}^{1-\alpha/2}\,\,Standard\,Error\left(\,Estimate\,\right)\]</span> In our current problem, <span class="math inline">\(\bar{x}\)</span> is our estimate of <span class="math inline">\(\mu\)</span> and the estimated standard deviation (which is commonly called the standard error) is <span class="math inline">\(s/\sqrt{n}\)</span> and the appropriate degrees of freedom are <span class="math inline">\(df=n-1\)</span>.</p>
<p>Example: Suppose we are interested in calculating a <span class="math inline">\(95\%\)</span> confidence interval for the mean weight of adult black bears. We collect a random sample of <span class="math inline">\(40\)</span> individuals (large enough for the CLT to kick in) and observe the following data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bears &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">weight =</span> 
   <span class="kw">c</span>(<span class="dv">306</span>, <span class="dv">446</span>, <span class="dv">276</span>, <span class="dv">235</span>, <span class="dv">295</span>, <span class="dv">302</span>, <span class="dv">374</span>, <span class="dv">339</span>, <span class="dv">624</span>, <span class="dv">266</span>,
     <span class="dv">497</span>, <span class="dv">384</span>,  <span class="dv">429</span>, <span class="dv">497</span>, <span class="dv">224</span>, <span class="dv">157</span>, <span class="dv">248</span>, <span class="dv">349</span>, <span class="dv">388</span>, <span class="dv">391</span>,
     <span class="dv">266</span>, <span class="dv">230</span>, <span class="dv">621</span>, <span class="dv">314</span>, <span class="dv">344</span>,  <span class="dv">413</span>, <span class="dv">267</span>, <span class="dv">380</span>, <span class="dv">225</span>, <span class="dv">418</span>,
     <span class="dv">257</span>, <span class="dv">466</span>, <span class="dv">230</span>, <span class="dv">548</span>, <span class="dv">277</span>, <span class="dv">354</span>, <span class="dv">271</span>, <span class="dv">369</span>,  <span class="dv">275</span>, <span class="dv">272</span>))
xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(bears<span class="op">$</span>weight)
s    &lt;-<span class="st"> </span><span class="kw">sd</span>(  bears<span class="op">$</span>weight)
<span class="kw">cbind</span>(xbar, s)</code></pre></div>
<pre><code>##       xbar        s
## [1,] 345.6 108.8527</code></pre>
<p>Notice that the data do not appear to come from a normal distribution, but a slightly heavier right tail. We’ll plot the histogram of data along with a normal distribution with the same mean and standard deviation as our data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">normal.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">weight=</span><span class="kw">seq</span>(<span class="dv">100</span>,<span class="dv">700</span>,<span class="dt">length=</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">y =</span> <span class="kw">dnorm</span>(weight, <span class="dt">mean=</span>xbar, <span class="dt">sd=</span>s))
<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&#39;density&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>( <span class="dt">data=</span>normal.data, <span class="kw">aes</span>(<span class="dt">x=</span>weight, <span class="dt">y=</span>y), <span class="dt">fill=</span><span class="st">&#39;light blue&#39;</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">data=</span>bears, <span class="kw">aes</span>(<span class="dt">x=</span>weight, <span class="dt">y=</span>..density..),
                 <span class="dt">binwidth=</span><span class="dv">30</span>, <span class="dt">alpha=</span>.<span class="dv">6</span>)  </code></pre></div>
<p><img src="05_ConfidenceIntervals_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The observed sample mean is <span class="math inline">\(\bar{x}=345.6\)</span> pounds and a sample standard deviation <span class="math inline">\(s=108.8527\)</span> pounds. Because we want a <span class="math inline">\(95\%\)</span> $confidence interval <span class="math inline">\(\alpha=0.05\)</span>. Using t-tables or the following R code</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(.<span class="dv">975</span>, <span class="dt">df=</span><span class="dv">39</span>)</code></pre></div>
<pre><code>## [1] 2.022691</code></pre>
<p>we find that <span class="math inline">\(t_{n-1}^{1-\alpha/2}=2.022691\)</span>. Therefore the <span class="math inline">\(95\%\)</span> confidence interval is <span class="math display">\[\bar{x}   \pm t_{n-1}^{1-\alpha/2}\left(\frac{s}{\sqrt{n}}\right)\]</span> <span class="math display">\[345.6 \pm 2.022691\left(\frac{108.8527}{\sqrt{40}}\right)\]</span> <span class="math display">\[345.6 \pm 34.8\]</span> or <span class="math inline">\(\left(310.8, \, 380.4\right)\)</span> which is interpreted as “We are 95% confident that the true mean <span class="math inline">\(\mu\)</span> is in this interval” which is shorthand for “The process that resulted in this interval (taking a random sample, and then calculating an interval using the algorithm presented) will result in intervals such that 95% of them contain the mean <span class="math inline">\(\mu\)</span>, but we cannot know of this particular interval is one of the good ones or not.”</p>
<p>We can wonder how well this interval matches up with the interval we would have gotten if we had used the bootstrap method to create a confidence interval for <span class="math inline">\(\mu\)</span>. In this case, where the sample size <span class="math inline">\(n\)</span> is relatively large, the Central Limit Theorem is certainly working and the distribution of the sample mean certainly looks fairly normal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SampDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>{
  mosaic<span class="op">::</span><span class="kw">resample</span>(bears) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(weight)) 
}
<span class="kw">ggplot</span>(SampDist, <span class="kw">aes</span>(<span class="dt">x=</span>xbar, <span class="dt">y=</span>..density..)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>()</code></pre></div>
<p><img src="05_ConfidenceIntervals_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Grabbing the appropriate quantiles from the bootstrap estimate of the sampling distribution, we see that the bootstrap <span class="math inline">\(95\%\)</span> confidence interval matches up will with the confidence interval we obtained from asymptotic theory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>( SampDist<span class="op">$</span>xbar, <span class="dt">probs=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>) )</code></pre></div>
<pre><code>##     2.5%    97.5% 
## 312.6000 380.5256</code></pre>
<p>Example: Assume that the percent of alcohol in casks of whiskey is normally distributed. From the last batch of casks produced, the brewer samples <span class="math inline">\(n=5\)</span> casks and wants to calculate a <span class="math inline">\(90\%\)</span> confidence interval for the mean percent alcohol in the latest batch produced. The sample mean was <span class="math inline">\(\bar{x}=55\)</span> percent and the sample standard deviation was <span class="math inline">\(s=4\)</span> percent.</p>
<p><span class="math display">\[\bar{x}   \pm t_{n-1}^{1-\alpha/2}\left(\frac{s}{\sqrt{n}}\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>.<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">df=</span><span class="dv">4</span>)  <span class="co"># 1-(.1)/2 = 1-.05 = .95</span></code></pre></div>
<pre><code>## [1] 2.131847</code></pre>
<p><span class="math display">\[55    \pm 2.13\left(\frac{4}{\sqrt{5}}\right)\]</span> <span class="math display">\[55    \pm 3.8\]</span></p>
<p>Question: If we wanted a <span class="math inline">\(95\%\)</span> confidence interval, would it have been wider or narrower?</p>
<p>Question: If this interval is too wide to be useful, what could we do to make it smaller?</p>
</div>
<div id="sample-size-selection" class="section level2">
<h2><span class="header-section-number">5.3</span> Sample Size Selection</h2>
<p>Often a researcher is in the position of asking how many sample observations are necessary to achieve a specific width of confidence interval. Let the margin of error, which we denote <span class="math inline">\(ME\)</span>, be the half-width desired (so the confidence interval would be <span class="math inline">\(\bar{x}\pm ME\)</span>). So given the desired confidence level, and if we know <span class="math inline">\(\sigma\)</span>, then we can calculate the necessary number of samples to achieve a particular <span class="math inline">\(ME\)</span>. To do this calculation, we must also have some estimate of the population standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p><span class="math display">\[ME=z_{1-\alpha/2}\left(\frac{\sigma}{\sqrt{n}}\right)\]</span> and therefore <span class="math display">\[n\approx\left[z_{1-\alpha/2}\left(\frac{\sigma}{ME}\right)\right]^{2}\]</span></p>
<p>Notice that because <span class="math display">\[n\propto\left[\frac{1}{ME}\right]^{2}\]</span> then if we want a margin of error that is twice as precise (i.e. the CI is half as wide) then we need to quadruple our sample size! Second, this result requires having some knowledge of <span class="math inline">\(\sigma\)</span>. We could acquire an estimate through: 1. a literature search 2. a pilot study 3. expert opinion.</p>
<p>A researcher is interested in estimating the mean weight of an adult elk in Yellowstone’s northern herd after the winter and wants to obtain a <span class="math inline">\(90\%\)</span> confidence interval with a half-width <span class="math inline">\(ME=10\)</span> pounds. Using prior collection data from the fall harvest (road side checks by game wardens), the researcher believes that <span class="math inline">\(\sigma=60\)</span> lbs is a reasonable standard deviation number to use. <span class="math display">\[\begin{aligned}
  n &amp;\approx    \left[ z_{0.95} \left(\frac{\sigma}{ME}\right)\right]^{2} \\
      &amp;=    \left[1.645\left(\frac{60}{10}\right)\right]^{2}              \\
      &amp;=    97.41  \end{aligned}\]</span></p>
<p>Notice that I don’t bother using the <span class="math inline">\(t\)</span>-distribution in this calculations because because I am assuming that <span class="math inline">\(\sigma\)</span> is known. While this is a horrible assumption, the difference between using a <span class="math inline">\(t\)</span> quantile instead of <span class="math inline">\(z\)</span> quantile is small and what really matters is how good the estimate of <span class="math inline">\(\sigma\)</span> is. As with many things, the quality of the input values is reflected in the quality of the output. Typically this sort of calculation is done with only a rough estimate of <span class="math inline">\(\sigma\)</span> and therefore I would subsequently regard the resulting sample size <span class="math inline">\(n\)</span> as an equally rough estimate.</p>
<p>We could be a bit more precise and use the <span class="math inline">\(t\)</span>-quantile, but because the degrees of freedom depend on <span class="math inline">\(n\)</span> as well, then we would have <span class="math inline">\(n\)</span> on both sides of the equation and there is no convenient algebraic solution to solving for <span class="math inline">\(n\)</span>. Later on we’ll use an R function that accounts for this, but for now we will use the rough approximation.</p>
</div>
<div id="exercises-4" class="section level2">
<h2><span class="header-section-number">5.4</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>An experiment is conducted to examine the susceptibility of root stocks of a variety of lemon trees to a specific larva. Forty of the plants are subjected to the larvae and examined after a fixed period of time. The response of interest is the logarithm of the number of larvae per gram of of root stock. For these 40 plants, the sample mean is <span class="math inline">\(\bar{x}=11.2\)</span> and the sample standard deviation is <span class="math inline">\(s=1.3\)</span>. Use these data to construct a <span class="math inline">\(90\%\)</span> confidence interval for <span class="math inline">\(\mu\)</span>, the mean susceptibility of lemon tree root stocks from which the sample was taken.</p></li>
<li><p>A social worker is interested in estimating the average length of time spent outside of prison for first offenders who later commit a second crime and are sent to prison again. A random sample of <span class="math inline">\(n=100\)</span> prison records in the count courthouse indicates that the average length of prison-free life between first and second offenses is <span class="math inline">\(4.2\)</span> years, with a standard deviation of <span class="math inline">\(1.1\)</span> years. Use this information to construct a <span class="math inline">\(95\%\)</span> confidence interval for <span class="math inline">\(\mu\)</span>, the average time between first and second offenses for all prisoners on record in the county courthouse.</p></li>
<li><p>A biologist wishes to estimate the effect of an antibiotic on the growth of a particular bacterium by examining the number of colony forming units (CFUs) per plate of culture when a fixed amount of antibiotic is applied. Previous experimentation with the antibiotic on this type of bacteria indicates that the standard deviation of CFUs is approximately <span class="math inline">\(4\)</span>. Using this information, determine the number of observations (i.e. cultures developed) necessary to calculate a <span class="math inline">\(99\%\)</span> confidence interval with a half-width of <span class="math inline">\(1\)</span>.</p></li>
<li>In the R package <code>Lock5Data</code>, the dataset <code>FloridaLakes</code> contains information about the mercury content of fish in 53 Florida lakes. For this question, we’ll be concerned with the average ppm of mercury in fish from those lakes which is encoded in the column <code>AvgMercury</code>.
<ol style="list-style-type: lower-alpha">
<li>Using the bootstrapping method, calculate a 95% confidence interval for <span class="math inline">\(\mu\)</span>, the average ppm of mercury in fish in all Florida lakes.</li>
<li>Using the asymptotic approximations discussed in this chapter, calculate a 95% confidence interval for <span class="math inline">\(\mu\)</span>, the average ppm of mercury in fish in all Florida lakes.</li>
<li>Comment on the similarity of these two intervals.</li>
</ol></li>
<li>In the R package <code>Lock5Data</code>, the dataset Cereal contains nutrition information about a random sample of 30 cereals taken from an on-line nutrition information website (see the help file for the dataset to get the link). For this problem, we’ll consider the column Sugars which records the grams of sugar per cup.
<ol style="list-style-type: lower-alpha">
<li>Using the bootstrapping method, calculate a 90% confidence interval for <span class="math inline">\(\mu\)</span>, the average grams of sugar per cup of all cereals listed on the website.</li>
<li>Using the asymptotic approximations discussed in this chapter, calculate a 90% confidence interval for <span class="math inline">\(\mu\)</span>, the average grams of sugar per cup of all cereals listed on this website.</li>
<li>Comment on the similarity of these two intervals.</li>
<li>We could easily write a little program (or pay an undergrad) to obtain the nutritional information about all the cereals on the website so the random sampling of 30 cereals is unnecessary. However, a bigger concern is that the website cereals aren’t representative of cereals Americans eat. Why? For example, consider what would happen if we added 30 new cereals that were very nutritious but were never sold.</li>
</ol></li>
</ol>
<!--chapter:end:05_ConfidenceIntervals.Rmd-->
</div>
</div>
<div id="hypothesis-tests-for-the-mean-of-a-population" class="section level1">
<h1><span class="header-section-number">6</span> Hypothesis Tests for the mean of a population</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tidyr)
<span class="kw">library</span>(ggplot2)

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<p>Science is done by observing how the world works, making a conjecture (or hypothesis) about the mechanism and then performing experiments to see if real data agrees or disagrees with the proposed hypothesis.</p>
<p><strong>Example</strong>. Suppose a rancher in Texas (my brother-in-law Bryan) wants to buy some calves from another rancher. This rancher claims that the average weight of his calves is 500 pounds. My brother-in-law likes them and buys 10. A few days later he starts looking at the cows and begins to wonder if the average really is 500 pounds. He weighs his 10 cows and the sample mean is <span class="math inline">\(\bar{x}=475\)</span> and the sample standard deviation is <span class="math inline">\(s=50\)</span>. Below are the data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cows &lt;-<span class="st"> </span><span class="kw">data.frame</span>(    
  <span class="dt">weight =</span> <span class="kw">c</span>(<span class="dv">553</span>, <span class="dv">466</span>, <span class="dv">451</span>, <span class="dv">421</span>, <span class="dv">523</span>, <span class="dv">517</span>, <span class="dv">451</span>, <span class="dv">510</span>, <span class="dv">392</span>, <span class="dv">466</span>) )
cows <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>( <span class="dt">xbar=</span><span class="kw">mean</span>(weight), <span class="dt">s=</span><span class="kw">sd</span>(weight) )</code></pre></div>
<pre><code>##   xbar        s
## 1  475 49.99556</code></pre>
<p>There are two possibilities. Either Bryan was just unlucky the random selection of his 10 cows from the heard, or the true average weight within the herd is less than 500.</p>
<p><span class="math display">\[H_{0}:\;\mu   =   500\]</span> <span class="math display">\[H_{a}:\;\mu   &lt;   500\]</span></p>
<p>For this calculation we’ll assume the weight of a steer is normally distributed <span class="math inline">\(N\left(\mu,\sigma\right)\)</span>, and therefore <span class="math inline">\(\bar{X}\)</span> is normally distributed <span class="math inline">\(N\left(\mu,\frac{\sigma}{\sqrt{n}}\right)\)</span>. If true mean is 500, how likely is it to get a sample mean of 475 (or less)? One way to think about this is that we want a measure of how extreme the event is that we observed, and one way to do that is to calculate how much probability there is for events that are even more extreme.</p>
<p>To calculate how far into the tail our observed sample mean <span class="math inline">\(\bar{x}=475\)</span> is by measuring the area of the distribution that is farther into the tail than the observed value.</p>
<p><span class="math display">\[\begin{aligned}P\left(\bar{X}\le475\right)    
    &amp;= P\left(\frac{\bar{X}-\mu}{\left(\frac{s}{\sqrt{n}}\right)}\le\frac{475-500}{\left(\frac{50}{\sqrt{10}}\right)}\right) \\
      &amp;= P\left(T_{9}\le-1.58\right) \\
      &amp;=    0.074 \end{aligned}\]</span></p>
<p>We see that the observed <span class="math inline">\(\bar{X}\)</span> is in the tail of the distribution and tends to not support <span class="math inline">\(H_{0}\)</span>.</p>
<p>P-value is the probability of seeing the observed data or something more extreme given the null hypothesis is true. By “something more extreme”, we mean samples that would be more evidence for the alternative hypothesis.</p>
<p><span class="math display">\[\mbox{p-value}=P(T_{9}&lt;-1.58)=0.074\]</span></p>
<p>The above value is the actual value calculated using R</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#        pt(-1.58, df=9)           # No Graph</span>
mosaic<span class="op">::</span><span class="kw">xpt</span>(<span class="op">-</span><span class="fl">1.58</span>, <span class="dt">df=</span><span class="dv">9</span>, <span class="dt">ncp=</span><span class="dv">0</span>)    <span class="co"># With a graph; Non-Centrality Parameter = 0</span></code></pre></div>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre><code>## [1] 0.07428219</code></pre>
<p>but using tables typically found in intro statistics books, the most precise thing you would be able to say is <span class="math inline">\(0.05 \le \mbox{p-value} \le 0.10\)</span> So there is a small chance that my brother-in-law just got unlucky with his ten cows. While the data isn’t entirely supportive of <span class="math inline">\(H_{0}\)</span>, we don’t have strong enough data to out right reject <span class="math inline">\(H_{0}\)</span>. So we will say that we fail to reject <span class="math inline">\(H_{0}\)</span>. Notice that we aren’t saying that we accept the null hypothesis, only that there is insufficient evidence to call-out the neighbor as a liar.</p>
<div id="writing-hypotheses" class="section level2">
<h2><span class="header-section-number">6.1</span> Writing Hypotheses</h2>
<div id="null-and-alternative-hypotheses" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Null and alternative hypotheses</h3>
<p>In elementary school most students are taught the scientific method follows the following steps:</p>
<ol style="list-style-type: decimal">
<li>Ask a question of interest.</li>
<li>Construct a hypothesis.</li>
<li>Design and conduct an experiment that challenges the hypothesis.</li>
<li>Depending on how consistent the data is with the hypothesis:
<ol style="list-style-type: lower-alpha">
<li>If the observed data is inconsistent with the hypothesis, then we have proven it wrong and we should consider competing hypotheses.</li>
<li>If the observed data is consistent with the hypothesis, design a more rigorous experiment to continue testing the hypothesis.</li>
</ol></li>
</ol>
<p>Through the iterative process of testing ideas and refining them under the ever growing body of evidence, we continually improve our understanding of how our universe works. The heart of the scientific method is the falsification of hypothesis and statistics is the tool we’ll use to assess the consistency of our data with a hypothesis.</p>
<p>Science is done by examining competing ideas for how the world works and throwing evidence at them. Each time a hypothesis is removed, the remaining hypotheses appear to be more credible. This doesn’t mean the remaining hypotheses are correct, only that they are consistent with the available data.</p>
<ol style="list-style-type: decimal">
<li><p>In approximately 300 BC, <a href="http://en.wikipedia.org/wiki/Eratosthenes">Eratosthenes</a> showed that the world was not flat. (Carl Sagan has an excellent episode of Cosmos on this <a href="https://www.youtube.com/watch?v=G8cbIWMv0rI">topic</a>. He did this by measuring the different lengths of shadows of identical sticks in two cities that were 580 miles apart but lay on the same meridian (Alexandria is directly north of Aswan). His proposed alternative was that the Earth was a sphere. While his alternative is not technically true (it is actually an oblate spheroid that bulges at the equator), it was substantially better than the flat world hypothesis.</p></li>
<li><p>At one point it was believed that plants “ate” the soil and turned it into plant mass. A experiment to test this hypothesis was performed by Johannes Baptista van Helmont in 1648 in which he put exactly 200 pounds of soil in a pot and then grew a willow tree out of it for five years. At the end of the experiment, the pot contained 199.875 pounds of soil and 168 pounds of willow tree. He correctly concluded that the plant matter was not substantially taken from the soil but incorrectly jumped to the conclusion that the mass must of have come from the water that was used to irrigate the willow.</p></li>
</ol>
<p>It is helpful to our understanding to label the different hypothesis, both the ones being tested and the different alternatives. We’ll label the hypothesis being tested as <span class="math inline">\(H_{0}\)</span> which we often refer to as the “null hypothesis.” The alternative hypothesis, which we’ll denote <span class="math inline">\(H_{a}\)</span>, should be the opposite of the null hypothesis. Had Eratosthenes known about modern scientific methods, he would have correctly considered <span class="math inline">\(H_{0}\)</span>: the world is flat verses <span class="math inline">\(H_{a}\)</span>: the world is not flat and not incorrectly concluded that the world is a sphere. Amusingly Eratosthenes’ data wasn’t inconsistent with the hypothesis that the world was shaped like a doughnut, but he thought the sphere to be more likely. Likewise Helmont should have considered the hypotheses <span class="math inline">\(H_{0}\)</span>: plants only consume soil versus the alternative <span class="math inline">\(H_{a}\)</span>: plants consume something besides soil.</p>
<p>In both of cases, the observed data was compared to what would have been expected if the null hypothesis was true. If the null was true Eratosthenes would have seen the same length shadow in both cities and Helmont would have seen 168 pounds of willow tree and <span class="math inline">\(200-168=32\)</span> pounds of soil remaining.</p>
</div>
<div id="error" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Error</h3>
<p>Unfortunately the world is not a simple place and experiments rarely can isolate exactly the hypothesis being tested. We can repeat an experiment and get slightly different results each time due to variation in weather, temperature, or diligence of the researcher. If we are testing the effectiveness of a new drug to treat a particular disease, we don’t trust the results of a single patient, instead we wish to examine many patients (some that receive the new drug and some the receive the old) to average out the noise between the patients. The questions about how many patients do we need to have and how large of a difference between the treatments is large enough to conclude the new drug is better are the heart of modern statistics.</p>
<p>Suppose we consider the population of all US men aged 40-60 with high blood pressure (there might be about 20 million people in this population). We want to know if exercise and ACE inhibitors lower systolic blood pressure better than exercise alone for these people. We’ll consider the null hypothesis that exercise is equivalent to exercise and ACE inhibitors versus exercise is different than exercise and ACE inhibitors. If we could take every single member of the population and expose them to exercise or exercise with ACE inhibitors, we would know for certain how the population reacts to the different treatments. Unfortunately this is too expensive and ethically dubious.</p>
<p>Instead of testing the entire population we’ll take a sample of <span class="math inline">\(n\)</span> men from the population and treat half of them with exercise alone and half of them with exercise and ACE inhibitors. What might our data look like if there is a difference between the two treatments at different samples sizes compared to if there is no difference? At small sample sizes it is difficult to distinguish the effect of the treatment when it is masked by individual variation. At high sample sizes, the individual variation is smoothed out and the difference between the treatments can be readily seen.</p>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Comparing possible data assuming there is a difference between treatments versus no difference. In the top row of graphs, there is a difference between the Exercise and the Exercise + Inhibitor treatments. However, at small sample sizes, we can’t tell if the observed difference is due to the difference in treatment or just random variation in the data. In the second row, there is no difference between the treatments.</p>
<p>When the sample size is large it is easy to see if the treatments differ in their effect on systolic blood pressure, but at medium or small sample sizes, the question is much harder. It is important to recognize that the core of the problem is still “is the observed data consistent with the null hypothesis?” but we now have to consider an addition variability term that is unrelated to the research hypothesis of interest. In the above example, the small sample data is consistent with the null hypothesis even when the null hypothesis is false!</p>
<p>Perhaps the hardest part about conducting a hypothesis test is figuring out what the null and alternative hypothesis should be. The null hypothesis is a statement about a population parameter. <span class="math display">\[H_{0}:\mbox{ population parameter = hypothesized value}\]</span> and the alternative will be one of <span class="math display">\[\begin{aligned} 
  H_{a}:    \textrm{population parameter }  &amp;&lt;   \textrm{ hypothesized value} \\    
  H_{a}:    \textrm{population parameter }  &amp;&gt;   \textrm{ hypothesized value} \\    
  H_{a}:    \textrm{population parameter }  &amp;\ne \textrm{ hypothesized value}
\end{aligned}\]</span> The hard part is figuring which of the possible alternatives we should examine. The alternative hypothesis is what the researcher believes is true. By showing that the complement of <span class="math inline">\(H_{a}\)</span> (that is <span class="math inline">\(H_{0}\)</span>) can not be true, we support the alternative which we believe to be true.</p>
<p><span class="math inline">\(H_{0}\)</span> is often a statement of no effect, or no difference between the claimed and observed.</p>
<p><em>Example</em> A light bulb company advertises that their bulbs last for 1000 hours. Consumers will be unhappy if the bulbs last less time, but will not mind if the bulbs last longer. Therefore Consumer Reports might perform a test and would consider the hypotheses <span class="math display">\[H_{0}:\;\mu   =   1000\]</span> <span class="math display">\[H_{a}:\;\mu   &lt;   1000\]</span></p>
<p>Suppose we perform an experiment with <span class="math inline">\(n=20\)</span> light bulbs and observe <span class="math inline">\(\bar{x}=980\)</span> and <span class="math inline">\(s=64\)</span> hours and therefore our test statistic is <span class="math display">\[ t_{19}   =   \frac{\bar{x}-\mu}{s/\sqrt{n}} =    \frac{980-1000}{64/\sqrt{20}} = -1.40\]</span> Then the p-value would be</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#        pt(-1.4, df=19)           # No Graph</span>
mosaic<span class="op">::</span><span class="kw">xpt</span>(<span class="op">-</span><span class="fl">1.4</span>, <span class="dt">df=</span><span class="dv">19</span>, <span class="dt">ncp=</span><span class="dv">0</span> )   <span class="co"># With a Graph</span></code></pre></div>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre><code>## [1] 0.08881538</code></pre>
<p>and we calculate p-value <span class="math inline">\(=P\left(T_{19}&lt;-1.4\right)=0.0888\)</span></p>
<p><strong>Example</strong> A computer company is buying resistors from another company. The resistors are supposed to have a resistance of <span class="math inline">\(2\)</span> Ohms and too much or too little resistance is bad. Here we would be testing <span class="math display">\[\begin{aligned} 
  H_{0}:\mbox{ }\mu &amp;=    2 \\    
  H_{a}:\mbox{ }\mu &amp;\ne    2 
  \end{aligned}\]</span></p>
<p>Suppose we perform a test of a random sample of resistors and obtain a test statistics of <span class="math inline">\(t_{9}=1.8\)</span>. Because the p-value is “the probability of your data or something more extreme” and in this case more extreme implies extreme values in both tails then</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mosaic<span class="op">::</span><span class="kw">xpt</span>( <span class="kw">c</span>(<span class="op">-</span><span class="fl">1.8</span>, <span class="fl">1.8</span>), <span class="dt">df=</span><span class="dv">9</span>, <span class="dt">ncp=</span><span class="dv">0</span>)</code></pre></div>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre><code>## [1] 0.05269534 0.94730466</code></pre>
<p>and we calculate <span class="math display">\[\textrm{p-value} = P\left(\left|T_{9}\right|&gt;1.8\right)=2P\left(T_{9}&lt;-1.8\right)=2\left(0.0527\right)=0.105\]</span></p>
<p>using the R commands</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="op">-</span><span class="fl">1.8</span>, <span class="dt">df=</span><span class="dv">9</span>)</code></pre></div>
<pre><code>## [1] 0.1053907</code></pre>
</div>
<div id="why-should-hypotheses-use-mu-and-not-barx" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Why should hypotheses use <span class="math inline">\(\mu\)</span> and not <span class="math inline">\(\bar{x}\)</span>?</h3>
<p>There is no need to make a statistical test of the form <span class="math display">\[\begin{aligned} 
  H_{0}:\;\bar{x}   &amp;=    3  \\
  H_{a}:\;\bar{x}   &amp;\ne    3 
\end{aligned}\]</span></p>
<p>because we know the value of <span class="math inline">\(\bar{x}\)</span>; we calculated the value there is no uncertainty to what it is. However I want to use the sample mean <span class="math inline">\(\bar{x}\)</span> as an estimate of the population mean <span class="math inline">\(\mu\)</span> and because I don’t know what <span class="math inline">\(\mu\)</span> is but know that it should be somewhere near <span class="math inline">\(\bar{x}\)</span>, my hypothesis test is a question about <span class="math inline">\(\mu\)</span> and if it is near the value stated in the null hypothesis.</p>
<p>Hypotheses are always statements about population parameters such as <span class="math inline">\(\mu\)</span> or <span class="math inline">\(\sigma\)</span> and never about sample statistic values such as <span class="math inline">\(\bar{x}\)</span> or <span class="math inline">\(s\)</span>.</p>
<p><em>Examples</em></p>
<ol style="list-style-type: decimal">
<li>A potato chip manufacturer advertises that it sells 16 ounces of chips per bag. A consumer advocacy group wants to test this claim. They take a sample of <span class="math inline">\(n=18\)</span> bags and carefully weights the contents of each bag and calculate a sample mean <span class="math inline">\(\bar{x}=15.8\)</span> oz and a sample standard deviation of <span class="math inline">\(s=0.2\)</span>.
<ol style="list-style-type: lower-alpha">
<li>State an appropriate null and alternative hypothesis. <span class="math display">\[\begin{aligned} H_{0}:\mu  &amp;= 16\mbox{ oz } \\
              H_{a}:\mu  &amp;&lt; 16\mbox{ oz }
\end{aligned}\]</span></li>
<li>Calculate an appropriate test statistic given the sample data. <span class="math display">\[t=\frac{\bar{x}-\mu_{0}}{\frac{s}{\sqrt{n}}}=\frac{15.8-16}{\frac{.2}{\sqrt{18}}}=-4.24\]</span></li>
<li>Calculate the p-value. <span class="math display">\[\mbox{p-value }=P(T_{17}&lt;-4.24)=0.000276\]</span></li>
<li>Do you reject or fail to reject the null hypothesis at the <span class="math inline">\(\alpha=0.05\)</span> level? <em>Because the p-value is less than <span class="math inline">\(\alpha=0.05\)</span> we will reject the null hypothesis.</em></li>
<li>State your conclusion in terms of the problem. <em>There is statistically significant evidence to conclude that the mean weight of chips is less than 16 oz.</em></li>
</ol></li>
<li>A pharmaceutical company has developed an improved pain reliever and believes that it acts faster than the leading brand. It is well known that the leading brand takes <span class="math inline">\(25\)</span> minutes to act. They perform an experiment on <span class="math inline">\(16\)</span> people with pain and record the time until the patient notices pain relief. The sample mean is <span class="math inline">\(\bar{x}=23\)</span> minutes, and the sample standard deviation was <span class="math inline">\(s=10\)</span> minutes.
<ol style="list-style-type: lower-alpha">
<li>State an appropriate null and alternative hypothesis. <span class="math display">\[\begin{aligned} H_{0}:\mu  &amp;= 25\mbox{ minutes } \\
              H_{a}:\mu  &amp;&lt; 25\mbox{ minutes }
\end{aligned}\]</span></li>
<li>Calculate an appropriate test statistic given the sample data. <span class="math display">\[t_{15}=\frac{\bar{x}-\mu_{0}}{\frac{s}{\sqrt{n}}}=\frac{23-25}{\frac{10}{\sqrt{16}}}=-0.8\]</span></li>
<li>Calculate the p-value. <span class="math display">\[\mbox{p-value }=P(T_{15}&lt;-0.8)=0.218\]</span></li>
<li>Do you reject or fail to reject the null hypothesis at the <span class="math inline">\(\alpha=.10\)</span> level?<br />
<em>Since the p-value is larger than my <span class="math inline">\(\alpha\)</span>-level, I will fail to reject the null hypothesis.</em></li>
<li>State your conclusion in terms of the problem. <em>These data do not provide statistically significant evidence to conclude that this new pain reliever acts faster than the leading brand.</em></li>
</ol></li>
<li>Consider the case of SAT test preparation course. They claim that their students perform better than the national average of 1019. We wish to perform a test to discover whether or not that is true. <span class="math display">\[\begin{aligned} H_{0}:\,\mu    &amp;= 1019  \\
              H_{a}:\,\mu    &amp;&gt; 1019
\end{aligned}\]</span> They take a sample of size <span class="math inline">\(n=10\)</span> and the sample mean is <span class="math inline">\(\bar{x}=1020\)</span>, with a sample standard deviation <span class="math inline">\(s=50\)</span>. The test statistic is <span class="math display">\[t_{9}=\frac{\bar{x}-\mu_{0}}{\frac{s}{\sqrt{n}}}=\frac{1}{\frac{50}{\sqrt{10}}}=.06\]</span> So the p-value is <span class="math inline">\(\mbox{p-value }=P(T_{9}&gt;.06)\approx0.5\)</span> and we fail to reject the null hypothesis. However, what if they had performed this experiment with <span class="math inline">\(n=20000\)</span> students and gotten the same results? <span class="math display">\[t_{19999}=\frac{\bar{x}-\mu_{0}}{\frac{s}{\sqrt{n}}}=\frac{1}{\frac{50}{\sqrt{20000}}}=2.83\]</span> and thus <span class="math inline">\(\mbox{p-value }=P(T_{19999}&gt;2.83)=0.0023\)</span> At <span class="math inline">\(\alpha=.05\)</span>, we will reject the null hypothesis and conclude that there is statistically significant evidence that the students who take the course perform better than the national average.</li>
</ol>
<p>So what just happened and what does “statistically significant” mean? It appears that there is very slight difference between the students who take the course versus those that don’t. With a small sample size we can not detect that difference, but by taking a large sample size, I can detect the difference of even 1 SAT point. So here I would say that there is a statistical difference between the students who take the course versus those that don’t because given such a large sample, we are very unlikely to see a sample mean of <span class="math inline">\(\bar{x}=1020\)</span> if the true mean is <span class="math inline">\(\mu=1019\)</span>. So statistically significant really means “unlikely to occur by random chance”.</p>
<p>But is there a practical difference in 1 SAT point? Not really. Since SAT scores are measured in multiple of 5 (you can score 1015, or 1020, but not 1019), there isn’t any practical value of raising a students score by 1 point. By taking a sample so large, I have been able to detect a completely worthless difference.</p>
<p>Thus we have an example of a statistically significant difference, but it is not a practical difference.</p>
</div>
<div id="calculating-p-values" class="section level3">
<h3><span class="header-section-number">6.1.4</span> Calculating p-values</h3>
<p>Students often get confused by looking up probabilities in tables and don’t know which tail of the distribution supports the alternative hypothesis. This is further exacerbated by tables sometimes giving area to the left, sometimes area to the right, and R only giving area to the left. In general, your best approach to calculating p-values correctly is to draw the picture of the distribution of the test statistic (usually a t-distribution) and decide which tail(s) supports the alternative and figuring out the area farther out in the tail(s) than your test statistic. However, since some students need a more algorithmic set of instructions, the following will work:</p>
<ol style="list-style-type: decimal">
<li>If your alternative has a <span class="math inline">\(\ne\)</span> sign
<ol style="list-style-type: lower-alpha">
<li>Look up the value of your test statistic in whatever table you are going to use and get some probability… which I’ll call <span class="math inline">\(p^{*}\)</span>.</li>
<li>Is <span class="math inline">\(p^{*} &gt; 0.5\)</span>? If so, you just looked up the area in the wrong tail. To fix your error, subtract from one… that is <span class="math inline">\(p^{*} \leftarrow 1-p^{*}\)</span></li>
<li>Because this is a two sided test, multiply <span class="math inline">\(p^{*}\)</span> by two and that is your p-value. <span class="math inline">\(\textrm{p-value}=2\left(p^{*}\right)\)</span></li>
<li>A p-value is a probability and therefore must be in the range <span class="math inline">\([0,1]\)</span>. If what you’ve calculated is outside that range, you’ve made a mistake.</li>
</ol></li>
<li>If your alternative is <span class="math inline">\(&lt;\)</span> (or <span class="math inline">\(&gt;\)</span>) then the p-value is the area to the left (to the right for the greater than case) of your test statistic.
<ol style="list-style-type: lower-alpha">
<li>Look up the value of your test statistic in whatever table you are using and get the probability… which again I’ll call <span class="math inline">\(p^{*}\)</span></li>
<li>If <span class="math inline">\(p^{*} &gt; 0.5\)</span>, you have most likely screwed up and looked up the area for the wrong tail. Be careful here, because if your alternative is “greater than” and your test statistic is negative, then the p-value <em>really is</em> greater than <span class="math inline">\(0.5\)</span>. This situation is rare and 9 times out of 10, the student has just used the table incorrectly. Most of the time you’ll subtract from one <span class="math inline">\(p^{*}=1-p^{*}\)</span>.</li>
<li>After possibly adjusting for looking up the wrong tail, your p-value is <span class="math inline">\(p^{*}\)</span> with no multiplication necessary.</li>
</ol></li>
</ol>
</div>
<div id="calculating-p-values-vs-cutoff-values" class="section level3">
<h3><span class="header-section-number">6.1.5</span> Calculating p-values vs cutoff values</h3>
<p>We have been calculating p-values and then comparing those values to the desired alpha level. It is possible, however, to use the alpha level to back-calculate a cutoff level for the test statistic, or even original sample mean. Often these cutoff values are referred to as critical values. Neither approach is wrong, but is generally a matter of preference, although knowing both techniques can be useful.</p>
<p><strong>Example</strong>. We return to the pharmaceutical company that has developed a new pain reliever. Recall null and alternative hypothesis was <span class="math display">\[\begin{aligned} H_{0}:\mu  &amp;= 25\mbox{ minutes } \\
                  H_{a}:\mu  &amp;&lt; 25\mbox{ minutes } \end{aligned}\]</span> and we had observed a test statistic <span class="math display">\[t=\frac{\bar{x}-\mu_{0}}{\frac{s}{\sqrt{n}}}=\frac{23-25}{\frac{10}{\sqrt{16}}}=-0.8\]</span> with <span class="math inline">\(15\)</span> degrees of freedom. Using an <span class="math inline">\(\alpha=0.10\)</span> level of significance, if this test statistic is smaller than the <span class="math inline">\(0.10\)</span>th quantile of a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(15\)</span> degrees of freedom, then we will reject the null hypothesis. This cutoff value is <span class="math inline">\(t_{crit}=-1.341\)</span> and can be using either R or the t-table. Because the observed test statistic is less extreme than the cutoff value, we failed to reject the null hypothesis.</p>
<p>We can push this idea even farther and calculate a critical value on the original scale of <span class="math inline">\(\bar{x}\)</span> by solving <span class="math display">\[\begin{aligned}
t_{crit}    &amp;=  \frac{\bar{x}_{crit}-\mu_{0}}{\left( \frac{s}{\sqrt{n}} \right)} \\
\\
-1.341    &amp;=    \frac{\bar{x}_{crit}-25}{\left( \frac{10}{\sqrt{16}} \right) }    \\
-1.341\left(\frac{10}{\sqrt{16}}\right)+25  &amp;=  \bar{x}_{crit}  \\
21.65   &amp;=  \bar{x}_{crit}
\end{aligned}\]</span> So if we observe a sample mean <span class="math inline">\(\bar{x}&lt;21.65\)</span> then we would reject the null hypothesis. Here we actually observed <span class="math inline">\(\bar{x}=23\)</span> so this comparison still fails to reject the null hypothesis and concludes there is insufficient evidence to reject that the new pain reliever has the same time till relief as the old medicine.</p>
<p>In general, I prefer to calculate and report p-values because they already account for any ambiguity in if we are dealing with a 1 sided or 2 sided test and how many degrees of freedom there are.</p>
</div>
<div id="t-tests-in-r" class="section level3">
<h3><span class="header-section-number">6.1.6</span> t-tests in R</h3>
<p>While it is possible to do t-tests by hand, most people will use a software package to perform these calculations. Here we will use the R function <code>t.test()</code>. This function expects a vector of data (so that it can calculate <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(s\)</span>) and a hypothesized value of <span class="math inline">\(\mu\)</span>.</p>
<p><em>Example</em>. Suppose we have data regarding fuel economy of <span class="math inline">\(5\)</span> vehicles of the same make and model and we wish to test if the observed fuel economy is consistent with the advertised <span class="math inline">\(31\)</span> mpg at highway speeds. Assuming the fuel economy varies normally among cars of the same make and model, we test <span class="math display">\[\begin{aligned} H_{0}:\,\mu    &amp;= 31 \\
                  H_{a}:\,\mu    &amp;\ne   31 \end{aligned}\]</span> and calculate</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cars &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">mpg =</span> <span class="kw">c</span>(<span class="fl">31.8</span>, <span class="fl">32.1</span>, <span class="fl">32.5</span>, <span class="fl">30.9</span>, <span class="fl">31.3</span>))
cars <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="kw">mean</span>(mpg), <span class="kw">sd</span>(mpg))</code></pre></div>
<pre><code>##   mean(mpg)   sd(mpg)
## 1     31.72 0.6340347</code></pre>
<p>The test statistic is: <span class="math display">\[t=\frac{\bar{x}-\mu_{0}}{s/\sqrt{n}}=\frac{31.72-31}{\left(\frac{0.634}{\sqrt{5}}\right)}=2.54\]</span></p>
<p>The p-value is <span class="math display">\[\textrm{p-value}=2\cdot P\left(T_{4}&gt;2.54\right)=0.064\]</span></p>
<p>and a <span class="math inline">\(95\%\)</span> confidence interval is <span class="math display">\[\begin{aligned} 
\bar{x} &amp;\pm    t_{n-1}^{1-\alpha/2}\left(\frac{s}{\sqrt{n}}\right) \\
31.72     &amp;\pm  2.776445\left(\frac{0.63403}{\sqrt{5}}\right)       \\
31.72     &amp;\pm  0.7872 \\
        [30.93,\; &amp; 32.51]
\end{aligned}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>( cars<span class="op">$</span>mpg, <span class="dt">mu=</span><span class="dv">31</span>, <span class="dt">alternative=</span><span class="st">&#39;two.sided&#39;</span> )</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  cars$mpg
## t = 2.5392, df = 4, p-value = 0.06403
## alternative hypothesis: true mean is not equal to 31
## 95 percent confidence interval:
##  30.93274 32.50726
## sample estimates:
## mean of x 
##     31.72</code></pre>
<p>The <code>t.test()</code> function supports testing one-sided alternatives and more information can be found in the R help system using <code>help(t.test)</code>.</p>
</div>
</div>
<div id="type-i-and-type-ii-errors" class="section level2">
<h2><span class="header-section-number">6.2</span> Type I and Type II Errors</h2>
<p>We can think of the p-value as measuring how much evidence we have for the null hypothesis. If the p-value is small, the evidence for the null hypothesis is small. Conversely if the p-value is large, then the data is supporting the null hypothesis.</p>
<p>There is an important philosophical debate about how much evidence do we need in order to reject the null hypothesis. My brother-in-law would have to have extremely strong evidence before he stated the other rancher was wrong. Likewise, researchers needed solid evidence before concluding that Newton’s Laws of Motion were incorrect.</p>
<p>Since the p-value is a measure of support for the null hypothesis, if the p-value drops below a specified threshold (call it <span class="math inline">\(\alpha\)</span>), I will chose to reject the null hypothesis. Different scientific disciplines have different levels of rigor. Therefore they set commonly used <span class="math inline">\(\alpha\)</span> levels differently. For example physicists demand a high degree of accuracy and consistency, thus might use <span class="math inline">\(\alpha=0.01\)</span>, while ecologists deal with very messy data and might use an <span class="math inline">\(\alpha=0.10\)</span>.</p>
<p>The most commonly used <span class="math inline">\(\alpha\)</span>-level is <span class="math inline">\(\alpha=0.05\)</span>, which is traditional due to an off-hand comment by R.A. Fisher. There is nothing that fundamentally forces us to use <span class="math inline">\(\alpha=0.05\)</span> other than tradition. However, when sociologists do experiments presenting subjects with unlikely events, it is usually when the events have a probability around <span class="math inline">\(0.05\)</span> that the subjects begin to suspect they are being duped.</p>
<p>People who demand rigor might want to set <span class="math inline">\(\alpha\)</span> as low as possible, but there is a trade off. Consider the following possibilities, where the “True State of Nature” is along the top, and the decision is along the side.</p>
<table style="width:72%;">
<colgroup>
<col width="23%" />
<col width="23%" />
<col width="25%" />
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td><p><span class="math inline">\(H_0\)</span> <strong>True</strong></p></td>
<td><p><span class="math inline">\(H_0\)</span> <strong>False</strong></p></td>
</tr>
<tr class="even">
<td><p><strong>Fail to reject</strong> <span class="math inline">\(H_0\)</span></p></td>
<td><p>:)</p></td>
<td><p>Type II Error</p></td>
</tr>
<tr class="odd">
<td><p><strong>Reject</strong> <span class="math inline">\(H_0\)</span></p></td>
<td><p>Type I Error</p></td>
<td><p>:)</p></td>
</tr>
</tbody>
</table>
<p>There are two ways to make a mistake. The type I error is to reject <span class="math inline">\(H_{0}\)</span> when it is true. This error is controlled by <span class="math inline">\(\alpha\)</span>. We can think of <span class="math inline">\(\alpha\)</span> as the probability of rejecting <span class="math inline">\(H_{0}\)</span> when we shouldn’t. However there is a trade off. If <span class="math inline">\(\alpha\)</span> is very small then we will fail to reject <span class="math inline">\(H_{0}\)</span> in cases where <span class="math inline">\(H_{0}\)</span> is not true. This is called a type II error and we will define <span class="math inline">\(\beta\)</span> as the probability of failing to reject <span class="math inline">\(H_{0}\)</span> when it is false.</p>
<p>This trade off between type I and type II errors can be seen by examining our legal system. A person is presumed innocent until proven guilty. So the hypothesis being tested in the court of law are</p>
<p><span class="math display">\[\begin{aligned} H_{0}: &amp;  \textrm{ defendent is innocent}  \\
                  H_{a}: &amp;  \textrm{ defendent is guilty} \end{aligned}\]</span></p>
<p>Our legal system theoretically operates under the rule that it is better to let 10 guilty people go free, than wrongly convict 1 innocent. In other words, it is worse to make a type I mistake (concluding guilty when innocent), than to make a type II mistake (concluding not guilty when guilty). Critically, when a jury finds a person “not guilty” they are not saying that defense team has proven that the defendant is innocent, but rather that the prosecution has not proven the defendant guilty.</p>
<p>This same idea manifests itself in science with the <span class="math inline">\(\alpha\)</span>-level. Typically we decide that it is better to make a type II mistake. An experiment that results in a large p-value does not prove that <span class="math inline">\(H_{0}\)</span> is true, but that there is insufficient evidence to conclude <span class="math inline">\(H_{a}\)</span>.</p>
<p>If we still suspect that <span class="math inline">\(H_{a}\)</span> is true, then we must repeat the experiment with a larger samples size. A larger sample size makes it possible to detect smaller differences.</p>
<div id="power-and-sample-size-selection" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Power and Sample Size Selection</h3>
<p>Just as we calculated the necessary sample size to achieve a confidence interval of a specified width, we are also often interested in calculating the necessary sample size to find a significant difference from the hypothesized mean <span class="math inline">\(\mu_{0}\)</span>. Just as in the confidence interval case where we had to specify the half-width <span class="math inline">\(E\)</span> and some estimate of the population standard deviation <span class="math inline">\(\hat{\sigma}\)</span>, we now must specify a difference we want to be able to detect <span class="math inline">\(\delta\)</span> and an estimate of the population standard deviation <span class="math inline">\(\hat{\sigma}\)</span>.</p>
<p><em>Example</em>. Suppose that I work in Quality Control for a company that manufactures a type of rope. This rope is supposed to have a mean breaking strength of <span class="math inline">\(5000\)</span> pounds and long experience with the process suggests that the standard deviation is approximately <span class="math inline">\(s=50\)</span>. As with many manufacturing processes, sometimes the machines that create the rope get out of calibration. So each morning we take a random sample of <span class="math inline">\(n=7\)</span> pieces of rope and using <span class="math inline">\(\alpha=0.05\)</span>, test the hypothesis <span class="math display">\[\begin{aligned} H_{0}:\;\mu    &amp;= 5000  \\
                  H_{a}:\;\mu    &amp;&lt; 5000  \end{aligned}\]</span> Notice that I will reject the null hypothesis if <span class="math inline">\(\bar{x}\)</span> is less than some cut-off value (which we denote <span class="math inline">\(\bar{x}_{crit}\)</span>), which we calculate by first recognizing that the critical t-value is <span class="math display">\[t_{crit}=t_{n-1}^{\alpha}=-1.943\]</span> and then solving the following equation for <span class="math inline">\(\bar{x}_{crit}\)</span> <span class="math display">\[\begin{aligned}
t_{crit}    &amp;=  \frac{\bar{x}_{crit}-\mu_{0}}{\frac{s}{\sqrt{n}}} \\
t_{crit}\left(\frac{s}{\sqrt{n}}\right)+\mu_{0} &amp;=  \bar{x}_{crit} \\
-1.943\left(\frac{50}{\sqrt{7}}\right)+5000 &amp;=  \bar{x}_{crit} \\
4963    &amp;=  \bar{x}_{crit}
\end{aligned}\]</span></p>
<p>There is a trade off between the Type I and Type II errors. By making a Type I error, I will reject the null hypothesis when the null hypothesis is true. Here I would stop manufacturing for the day while re-calibrating the machine. Clearly a Type I error is not good. The probability of making a Type I error is denoted <span class="math inline">\(\alpha\)</span>.</p>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>A type II error occurs when I fail to reject the null hypothesis when the alternative is true. This would mean that we would be selling ropes that have a breaking point less than the advertised amount. This opens the company up to a lawsuit. We denote the probability of making a Type II error is denoted as <span class="math inline">\(\beta\)</span> and define Power <span class="math inline">\(=1-\beta\)</span>. But consider that I don’t want to be shutting down the plant when the breaking point is just a few pounds from the true mean. The head of engineering tells me that if the average breaking point is more than <span class="math inline">\(50\)</span> pounds less than <span class="math inline">\(5000\)</span>, we have a problem, but less than <span class="math inline">\(50\)</span> pounds is acceptable.</p>
<p>So I want to be able to detect if the true mean is less than <span class="math inline">\(4950\)</span> pounds. Consider the following where we assume <span class="math inline">\(\mu=4950\)</span>.</p>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>The the probability of a type II error is <span class="math display">\[\begin{aligned}
\beta   &amp;=  P\left(\bar{X}&gt;4963.3\;|\,\mu=4950\right) \\
        &amp;=  P\left(\frac{\bar{X}-4950}{50/\sqrt{7}}&gt;\frac{4963.3-4950}{50/\sqrt{7}}\right) \\
        &amp;=  P\left(T_{6}&gt;0.703\right) \\
        &amp;=  0.254 \end{aligned}\]</span></p>
<p>and therefore my power for detecting a mean breaking strength less than or equal to 4950 is <span class="math inline">\(1-\beta=0.7457\)</span> which is very close to what any statistical package will calculate for us.The power calculation should done using a t-distribution with non-centrality parameter instead of just shifting the distribution. The difference is slight, but is enough to cause our calculation to be slightly off. This power is rather low and I would prefer to have the power be near <span class="math inline">\(0.95\)</span>. We can improve our power by using a larger sample size. We’ll repeat these calculations using <span class="math inline">\(n=15\)</span>.</p>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Power calculations are relatively tedious to do by hand, but fortunately there are several very good resources for exploring how power and sample size interact. My favorite is a Java Applet web page maintained by Dr. Russ Lenth at <a href="http://www.stat.uiowa.edu/~rlenth/Power/" class="uri">http://www.stat.uiowa.edu/~rlenth/Power/</a>. It will provide you a list of analysis to do the calculations for and the user is responsible for knowing that we are doing a one-sample t-test with a one-sided alternative.</p>
<p>Alternatively, we can do these calculations in R using the function <code>power.t.test()</code>.</p>
<p>Fundamentally there are five values that can be used and all power calculators will allow a user to input four of them and the calculator will calculate the fifth.</p>
<ol style="list-style-type: decimal">
<li>The difference <span class="math inline">\(\delta\)</span> from the hypothesized mean <span class="math inline">\(\mu_{0}\)</span> that we wish to detect.</li>
<li>The population standard deviation <span class="math inline">\(\sigma\)</span>.</li>
<li>The significance level of the test <span class="math inline">\(\alpha\)</span>.</li>
<li>The power of the test <span class="math inline">\(1-\beta\)</span>.</li>
<li>The sample size <span class="math inline">\(n\)</span>.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">power.t.test</span>(<span class="dt">delta=</span><span class="dv">50</span>, <span class="dt">sd=</span><span class="dv">50</span>, <span class="dt">sig.level=</span><span class="fl">0.05</span>, <span class="dt">n=</span><span class="dv">7</span>, 
             <span class="dt">type=</span><span class="st">&quot;one.sample&quot;</span>, <span class="dt">alternative=</span><span class="st">&quot;one.sided&quot;</span>)</code></pre></div>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 7
##           delta = 50
##              sd = 50
##       sig.level = 0.05
##           power = 0.7543959
##     alternative = one.sided</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">power.t.test</span>(<span class="dt">delta=</span><span class="dv">50</span>, <span class="dt">sd=</span><span class="dv">50</span>, <span class="dt">sig.level=</span><span class="fl">0.05</span>, <span class="dt">power=</span><span class="fl">0.95</span>, 
             <span class="dt">type=</span><span class="st">&quot;one.sample&quot;</span>, <span class="dt">alternative=</span><span class="st">&quot;one.sided&quot;</span>)</code></pre></div>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 12.32052
##           delta = 50
##              sd = 50
##       sig.level = 0.05
##           power = 0.95
##     alternative = one.sided</code></pre>
<p>The general process for selecting a sample size is to</p>
<ol style="list-style-type: decimal">
<li>Pick a <span class="math inline">\(\alpha\)</span>-level. Usually this is easy and people use <span class="math inline">\(\alpha=0.05\)</span>.</li>
<li>Come up with an estimate for the standard deviation <span class="math inline">\(\sigma\)</span>. If you don’t have an estimate, then a pilot study should be undertaken to get a rough idea what the variability is. Often this is the only good data that comes out of the first field season in a dissertation.</li>
<li>Decide how large of an effect is scientifically interesting.</li>
<li>Plug the results of steps 1-3 into a power calculator and see how large a study you need to achieve a power of <span class="math inline">\(90\%\)</span> or <span class="math inline">\(95\%\)</span>.</li>
</ol>
</div>
</div>
<div id="exercises-5" class="section level2">
<h2><span class="header-section-number">6.3</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>One way the amount of sewage and industrial pollutants dumped into a body of water affects the health of the water is by reducing the amount of dissolved oxygen available for aquatic life. Over a 2-month period, 8 samples were taken from a river at a location 1 mile downstream from a sewage treatment plant. The amount of dissolved oxygen in the samples was determined and is reported in the following table.</p>
<table>
<tbody>
<tr class="odd">
<td align="center">5.1</td>
<td align="center">4.9</td>
<td align="center">5.6</td>
<td align="center">4.2</td>
<td align="center">4.8</td>
<td align="center">4.5</td>
<td align="center">5.3</td>
<td align="center">5.2</td>
</tr>
</tbody>
</table>
Current research suggests that the mean dissolved oxygen level must be at least 5.0 parts per million (ppm) for fish to survive. Do the calculations in parts (b) and (e) by hand.
<ol style="list-style-type: lower-alpha">
<li>Use R to calculate the sample mean and standard deviation.</li>
<li>Using the asymptotic results and the quantities you calculated, by hand calculation create a <span class="math inline">\(95\%\)</span> two-sided confidence interval for the mean dissolved oxygen level during the 2-month period. What assumption is being made for this calculation to be valid?</li>
<li>Calculate a 95% two-sided confidence interval using the bootstrap method. Examine the bootstrap distribution of the sample means, does it appear normal? If so, what does that imply about the assumption you made in the calculation in the previous part?</li>
<li>Using the confidence interval calculated in part (b), do the data support the hypothesis that the mean dissolved oxygen level is equal to 5 ppm?</li>
<li>Using the quantities you calculated in part (a), by hand perform a 1-sided hypothesis test that the mean oxygen level is less that 5 ppm with a significance level of <span class="math inline">\(\alpha=0.05\)</span>.</li>
<li>Use the function <code>t.test</code> in R to repeat the calculations you made in parts (b) and (e).</li>
</ol></li>
<li><p>We are interested in investigating how accurate radon detectors sold to homeowners are. We take a randomly selection of <span class="math inline">\(n=12\)</span> detectors and expose them to <span class="math inline">\(105\)</span> pico-curies per liter (pCi/l) of radon. The following values were given by the radon detectors.</p>
<table>
<thead>
<tr class="header">
<th align="center">91.9</th>
<th align="center">97.8</th>
<th align="center">111.4</th>
<th align="center">122.3</th>
<th align="center">105.4</th>
<th align="center">95.0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">103.8</td>
<td align="center">99.6</td>
<td align="center">96.6</td>
<td align="center">119.3</td>
<td align="center">104.8</td>
<td align="center">101.7</td>
</tr>
</tbody>
</table>
<p>Do all of the following calculations by hand (except for the calculations of the mean and standard deviation).</p>
<ol style="list-style-type: lower-alpha">
<li>Calculate a <span class="math inline">\(90\%\)</span> confidence interval using the asymptotic method.</li>
<li>State an appropriate null and alternative hypothesis for a two-sided t-test. Why is a two-sided test appropriate here?</li>
<li>Calculate an appropriate test statistic.</li>
<li>Calculate a p-value.</li>
<li>At an <span class="math inline">\(\alpha=0.10\)</span> level, what is your conclusion. Be sure to state your conclusion in terms of the problem.</li>
<li>Use the function t.test() to redo the the hand calculations you did in parts (a), (c), (d).</li>
</ol></li>
<li><p>Given data such that <span class="math inline">\(X_{i}\sim N\left(\mu,\sigma^{2}=5^{2}\right)\)</span>, the following graph shows the distribution of a sample mean of <span class="math inline">\(n=8\)</span> observations under the null hypothesis <span class="math inline">\(H_{0}:\mu=5\)</span>. We are interested in testing the alternative <span class="math inline">\(H_{a}:\mu&gt;5\)</span> at the <span class="math inline">\(\alpha=0.05\)</span> level and therefore the cut off point for rejecting the null hypothesis is <span class="math inline">\(t_{crit}=1.895\)</span> and <span class="math inline">\(\bar{x}_{crit}=1.895*5+5=8.35\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Add the plot of the distribution of the sample mean if <span class="math inline">\(\mu=11\)</span> and denote which areas represent <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and the power in the figure below. <em>I expect most people will print out the graph and shade/label everything by hand.</em></li>
</ol>
<p><img src="06_HypothesisTests_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Under the same alternative value of <span class="math inline">\(\mu=11\)</span>, find the probability of a Type II error. That is, calculate the value of <span class="math inline">\(\beta=P\left(\bar{X}&lt;8.35\,|\,\mu=11\right)\)</span>.</li>
</ol></li>
<li>A study is to be undertaken to study the effectiveness of connective tissue massage therapy on the range of motion of the hip joint for elderly clients. Practitioners think that a reasonable standard deviation of the differences (post - pre) would be <span class="math inline">\(\sigma=20\)</span> degrees.
<ol style="list-style-type: lower-alpha">
<li>Suppose an increase of 5 degrees in the range would be a clinically significant result. How large of a sample would be necessary if we wanted to control the Type I error rate by <span class="math inline">\(\alpha=0.1\)</span> and the Type II error rate with <span class="math inline">\(\beta=0.1\)</span> (therefore the power is <span class="math inline">\(1-\beta=0.90\)</span>)? Use the use the <code>power.t.test()</code> function available in the package <code>pwr</code> to find the necessary sample size.</li>
<li>Suppose we were thought that only increases greater than 10 degrees were substantive. How large must our minimum sample size be in this case? Comment on how much larger a sample size must be to detect a difference half as small.</li>
</ol></li>
</ol>
<!--chapter:end:06_HypothesisTests.Rmd-->
</div>
</div>
<div id="two-sample-hypothesis-tests-and-confidence-intervals" class="section level1">
<h1><span class="header-section-number">7</span> Two-Sample Hypothesis Tests and Confidence Intervals</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tidyr)

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<p>There are two broad classifications of types of research, observational studies and designed experiments. These two types of research differ in the way that the researcher interacts with the subjects being observed. In an observational study, the researcher doesn’t force a subject into some behavior or treatment, but merely observes the subject (making measurements but not changing behaviors). In contrast, in an experiment, the researcher imposes different treatments onto the subjects and the pairing between the subject and treatment group happens at random.</p>
<p>Example: For many years hormone (Estrogen and Progestin) replacement therapy’s primary use for post-menopausal woman was to reduce the uncomfortable side-effects of menopause but it was thought to also reduced the rate of breast cancer in post-menopausal women. This belief was the result of many observational studies where women who chose to take hormone replacement therapy also had reduced rates of breast cancer. The lurking variable that the observational studies missed was that hormone therapy is relatively expensive and was taken by predominately women of a high socio- economic status. Those women tended to be more health conscious, lived in areas with less pollution, and were generally at a lower risk for developing breast cancer. Even when researchers realized that socio-economic status was confounded with the therapy, they couldn’t be sure which was the cause of the reduced breast cancer rates. Two variables are said to be confounded if the design of a given experiment or study cannot distinguish the effect of one variable from the other. To correctly test this, nearly 17,000 women underwent an experiment in which each women was randomly assigned to take either the treatment (E+P) or a placebo. The Women’s Health Initiative (WHI) Estrogen plus Progestin Study (E+P) was stopped on July 7, 2002 (after an average 5.6 years of follow-up) because of increased risks of cardiovascular disease and breast cancer in women taking active study pills, compared with those on placebo (inactive pills). The study showed that the overall risks exceeded the benefits, with women taking E+P at higher risk for heart disease, blood clots, stroke, and breast cancer, but at lower risk for fracture and colon cancer. Lurking variables such as income levels and education are correlated to overall health behaviors and with an increased use of hormone replacement therapy. By randomly assigning each woman to a treatment, the unidentified lurking variables were evenly spread across treatments and the dangers of hormone replacement therapy were revealed.</p>
<p>In the previous paragraph, we introduced the idea of a lurking variable where a lurking variable is a variable the researcher hasn’t considered but affects the response variable. In observational studies a researcher will try to measure all the variables that might affect the response but will undoubtedly miss something.</p>
<p>There is a fundamental difference between imposing treatments onto subjects versus taking a random sample from a population and observing relationships between variables. In general, designed experiments allow us to determine cause-and-effect relationships while observational studies can only determine if variables are correlated. This difference in how the data is generated will result in different methods for generating a sampling distribution for a statistic of interest. In this chapter we will focus on experimental designs, though the same analyses are appropriate for observational studies.</p>
<div id="difference-in-means-between-two-groups" class="section level2">
<h2><span class="header-section-number">7.1</span> Difference in means between two groups</h2>
<p>Often researchers will obtain a group of subjects and divide them into two groups, provide different treatments to each, and observe some response. The goal is to see if the two groups have different mean values, as this is the most common difference to be interested in.</p>
<p>The first thing to consider is that the group of subjects in our sample should be representative of a population of interest. Because we cannot impose an experiment on an entire population, we often are forced to examine a small sample and we hope that the sample statistics (the sample mean <span class="math inline">\(\bar{x}\)</span>, and sample standard deviation <span class="math inline">\(s\)</span>) are good estimates of the population parameters (the population mean <span class="math inline">\(\mu\)</span>, and population standard deviation <span class="math inline">\(\sigma\)</span>). First recognize that these are a sample and we generally think of them to be representative of some population.</p>
<p><strong>Example</strong>: Finger Tapping and Caffeine</p>
<p>The effects of caffeine on the body have been well studied. In one experiment, a group of male college students were trained in a particular tapping movement and to tap at a rapid rate. They were randomly divided into caffeine and non-caffeine groups and given approximately two cups of coffee (with either 200 mg of caffeine or none). After a 2-hour period, the students tapping rate was measured.</p>
<p>The population that we are trying to learn about is male college-aged students and we the most likely question of interest is if the mean tap rate of the caffeinated group is different than the non-caffeinated group. Notice that we don’t particularly care about these 20 students, but rather the population of male college-aged students so the hypotheses we are interested in are <span class="math display">\[\begin{aligned} 
H_{0}:  \mu_{c} &amp;=   \mu_{nc} \\    
H_{a}:  \mu_{c} &amp;\ne \mu_{nc}
\end{aligned}\]</span></p>
<p>where <span class="math inline">\(\mu_{c}\)</span> is the mean tap rate of the caffeinated group and <span class="math inline">\(\mu_{nc}\)</span> is the mean tap rate of the non-caffeinated group. We could equivalently express these hypotheses via <span class="math display">\[\begin{aligned}
H_{0}:  \mu_{nc}-\mu_{c}  &amp;=  0  \\
H_{a}:  \mu_{nc}-\mu_{c} &amp;\ne 0
\end{aligned}\]</span></p>
<p>Or we could let <span class="math inline">\(\delta=\mu_{nc}-\mu_{c}\)</span> and write the hypotheses as <span class="math display">\[\begin{aligned}
H_{0}:\,\delta  &amp;=    0 \\
H_{a}:\,\delta  &amp;\ne    0
\end{aligned}\]</span></p>
<p>The data are available in many different formats at <a href="http://www.lock5stat.com/datapage.html" class="uri">http://www.lock5stat.com/datapage.html</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(CaffeineTaps, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)   <span class="co"># load the data from the Lock5Data package</span>
<span class="kw">str</span>(CaffeineTaps)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    20 obs. of  2 variables:
##  $ Taps : int  246 248 250 252 248 250 246 248 245 250 ...
##  $ Group: Factor w/ 2 levels &quot;Caffeine&quot;,&quot;NoCaffeine&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>The first thing we should do is, as always, graph the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(CaffeineTaps, <span class="kw">aes</span>(<span class="dt">x=</span>Taps)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_dotplot</span>( <span class="dt">binwidth=</span>.<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>( Group <span class="op">~</span><span class="st"> </span>. )  <span class="co"># two graphs stacked by Group (Caffeine vs non)</span></code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>From this view, it looks like the caffeine group has a higher tapping rate. It will be helpful to summarize the difference between these two groups with a single statistic by calculating the mean for each group and then calculate the difference between the group means.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CaffeineTaps <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># group the summary stats by Treatment group</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(Taps), <span class="dt">s=</span><span class="kw">sd</span>(Taps))</code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   Group       xbar     s
##   &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1 Caffeine    248.  2.21
## 2 NoCaffeine  245.  2.39</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># No Caffeine  -  Caffeine</span>
<span class="fl">244.8</span> <span class="op">-</span><span class="st"> </span><span class="fl">248.3</span></code></pre></div>
<pre><code>## [1] -3.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CaffeineTaps <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(Taps)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">d =</span> <span class="kw">diff</span>(xbar))</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##       d
##   &lt;dbl&gt;
## 1  -3.5</code></pre>
<p>Notationally, lets call this statistic <span class="math inline">\(d=\bar{x}_{nc}-\bar{x}_{c}=-3.5\)</span>. We are interested in testing if this observed difference might be due to just random chance and we just happened to assigned more of the fast tappers to the caffeine group. How could we test the null hypothesis that the mean of the caffeinated group is different than the non-caffeinated?</p>
<div id="inference-via-resampling" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Inference via resampling</h3>
<p>The key idea is “How could the data have turned out if the null hypothesis is true?” If the null hypothesis is true, then the caffeinated/non-caffeinated group treatment had no effect on the tap rate and it was just random chance that the caffeinated group got a larger percentage of fast tappers. That is to say the group variable has no relationship to tap rate. I could have just as easily assigned the fast tappers to the non-caffeinated group purely by random chance. So our simulation technique is <strong>to shuffle the group labels and then calculate a difference between the group means</strong>!</p>
<p>We can perform this shuffling with the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># shuffle(): takes an input column and reorders it randomly</span>
CaffeineTaps <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">ShuffledGroup =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Group))</code></pre></div>
<pre><code>##    Taps      Group ShuffledGroup
## 1   246   Caffeine      Caffeine
## 2   248   Caffeine    NoCaffeine
## 3   250   Caffeine    NoCaffeine
## 4   252   Caffeine      Caffeine
## 5   248   Caffeine    NoCaffeine
## 6   250   Caffeine      Caffeine
## 7   246   Caffeine    NoCaffeine
## 8   248   Caffeine      Caffeine
## 9   245   Caffeine    NoCaffeine
## 10  250   Caffeine      Caffeine
## 11  242 NoCaffeine      Caffeine
## 12  245 NoCaffeine      Caffeine
## 13  244 NoCaffeine    NoCaffeine
## 14  248 NoCaffeine      Caffeine
## 15  247 NoCaffeine    NoCaffeine
## 16  248 NoCaffeine    NoCaffeine
## 17  242 NoCaffeine      Caffeine
## 18  244 NoCaffeine    NoCaffeine
## 19  246 NoCaffeine    NoCaffeine
## 20  242 NoCaffeine      Caffeine</code></pre>
<p>We can then calculate the mean difference but this time using the randomly generated groups, and now the non-caffeinated group just happens to have a slightly higher mean tap rate just by the random sorting into two groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CaffeineTaps <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">ShuffledGroup =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Group) ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>( ShuffledGroup )  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(Taps)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">d.star =</span> <span class="kw">diff</span>(xbar)) </code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   d.star
##    &lt;dbl&gt;
## 1   -0.7</code></pre>
<p>We could repeat this shuffling several times and see the possible values we might have seen if the null hypothesis is correct and the treatment group doesn’t matter at all.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">5</span>) <span class="op">*</span><span class="st"> </span>{
  CaffeineTaps <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">ShuffledGroup =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Group) ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>( ShuffledGroup )  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(Taps)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">d.star =</span> <span class="kw">diff</span>(xbar))  
}</code></pre></div>
<pre><code>##   d.star
## 1   -1.5
## 2   -1.7
## 3   -0.3
## 4    2.3
## 5   -0.3</code></pre>
<p>Of course, five times isn’t sufficient to understand the sampling distribution of the mean difference under the null hypothesis, we should do more.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">PermutationDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>{
  CaffeineTaps <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">ShuffledGroup =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Group) ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>( ShuffledGroup )  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(Taps)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">d.star =</span> <span class="kw">diff</span>(xbar))  
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(PermutationDist, <span class="kw">aes</span>(<span class="dt">x=</span>d.star)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Permutation dist. of d* assuming H0 is true&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;d*&#39;</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We have almost no cases where the randomly assigned groups produced a difference as extreme as the actual observed difference of <span class="math inline">\(d=-3.5\)</span>. We can calculate the percentage of the sampling distribution of the difference in means that is farther from zero</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">PermutationDist <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">MoreExtreme =</span> <span class="kw">ifelse</span>( <span class="kw">abs</span>(d.star) <span class="op">&gt;=</span><span class="st"> </span><span class="fl">3.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">p.value1 =</span> <span class="kw">sum</span>(MoreExtreme)<span class="op">/</span><span class="kw">n</span>(),        <span class="co"># these are all the</span>
             <span class="dt">p.value2 =</span> <span class="kw">mean</span>(MoreExtreme),           <span class="co"># same calculation</span>
             <span class="dt">p.value3 =</span> <span class="kw">mean</span>( <span class="kw">abs</span>(d.star) <span class="op">&gt;=</span><span class="st"> </span><span class="fl">3.5</span> ) ) <span class="co"># but more verbose</span></code></pre></div>
<pre><code>##   p.value1 p.value2 p.value3
## 1   0.0058   0.0058   0.0058</code></pre>
<p>We see that only 58/10,000 simulations of data produced assuming <span class="math inline">\(H_{0}\)</span> is true produced a <span class="math inline">\(d^{*}\)</span> value more extreme than our observed difference in sample means so we can reject the null hypothesis <span class="math inline">\(H_{0}:\mu_{nc}-\mu_{c}=0\)</span> in favor of the alternative <span class="math inline">\(H_{a}:\mu_{nc}-\mu_{c}\ne 0\)</span> at an <span class="math inline">\(\alpha=0.05\)</span> or any other reasonable <span class="math inline">\(\alpha\)</span> level.</p>
<p>Everything we know about the biological effects of ingesting caffeine suggests that we should have expected the caffeinated group to tap faster, so we might want to set up our experiment so only faster tapping represents “extreme” data compared to the null hypothesis. In this case we want an alternative of <span class="math inline">\(H_{a}:\,\mu_{nc}-\mu_{c}&lt;0\)</span>? Therefore the null and alternative hypothesis are <span class="math display">\[\begin{aligned}
H_{0}:\,\mu_{nc}-\mu_{c}    &amp;\ge    0 \\
H_{a}:\,\mu_{nc}-\mu_{c}    &amp;&lt;  0
\end{aligned}\]</span> or using the parameter <span class="math inline">\(\delta=\mu_{nc}-\mu_{c}\)</span> the null and alternative are <span class="math display">\[\begin{aligned} 
H_{0}:\,\delta  &amp;\ge    0 \\
H_{a}:\,\delta  &amp;  &lt;    0 
\end{aligned}\]</span></p>
<p>The creation of the sampling distribution of the mean difference <span class="math inline">\(d^*\)</span> is identical to our previous technique because if our observed difference d is so negative that it is incompatible with the hypothesis that <span class="math inline">\(\delta=0\)</span> then it must also be incompatible with any positive value of <span class="math inline">\(\delta\)</span>, so we evaluate the consistency of our data with the value of <span class="math inline">\(\delta\)</span> that is closest to the observed d while still being true to the null hypothesis. Thus for either the the one-sided (i.e. <span class="math inline">\(\delta&lt;0\)</span>) or the two-sided case (i.e. <span class="math inline">\(\delta \ne 0\)</span>), we generate the sampling distribution of <span class="math inline">\(d^*\)</span> in the same way. The only difference in the analysis is at the end when we calculate the p-value and don’t consider the positive tail. That is, the p-value is the percent of simulations where <span class="math inline">\(d^*&lt;d\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">PermutationDist <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>( <span class="dt">p.value =</span> <span class="kw">mean</span>( d.star <span class="op">&lt;=</span><span class="st"> </span><span class="op">-</span><span class="fl">3.5</span> ))</code></pre></div>
<pre><code>##   p.value
## 1  0.0028</code></pre>
<p>and we see that the p-value is approximately cut in half by ignoring the upper tail, which makes sense considering the observed symmetry in the sampling distribution of <span class="math inline">\(d^*\)</span>.</p>
<p>In general, we prefer to use a two-sided test because if the two-sided test leads us to reject the null hypothesis then so would the appropriate one-sided hypothesis (except in the case where the alternative was chosen before the data was collected and the observed data was in the other tail). Second, by using a two-sample test, it prevents us from from “tricking” ourselves when we don’t know the which group should have a higher mean going into the experiment, but after seeing the data, thinking we should have known and using the less stringent test. Some statisticians go so far as to say that using a 1-sided test is outright fraudulent. Generally, we’ll concentrate on two-sided tests as they are the most widely acceptable.</p>
<p>Notice that the corresponding confidence interval gives a similar inference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{
  CaffeineTaps <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span>
<span class="st">    </span>mosaic<span class="op">::</span><span class="kw">resample</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarise</span>( <span class="dt">xbar=</span><span class="kw">mean</span>(Taps) ) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarise</span>( <span class="dt">d.star =</span> <span class="kw">diff</span>(xbar)  ) }</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(BootDist, <span class="kw">aes</span>(<span class="dt">x=</span>d.star)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Bootstrap distribution of d*&#39;</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CI &lt;-<span class="st"> </span><span class="kw">quantile</span>( BootDist<span class="op">$</span>d.star, <span class="dt">probs=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>) )
CI</code></pre></div>
<pre><code>##      2.5%     97.5% 
## -5.400000 -1.515152</code></pre>
<p>Notice that the null hypothesis value, <span class="math inline">\(\delta=0\)</span>, is not a value supported by the data because 0 is not in the 95% confidence interval. A subtle point in the above bootstrap code is that I re-sampled each group separately. Because the experimental protocol was to have 10 in each group, then we want our simulated data sets should obey the same rule. Had I re-sampled first and then did the grouping, we might end up with 12 caffeinated and 8 decaffeinated subjects, which is data that our experimental design couldn’t have generated.</p>
</div>
<div id="inference-via-asymptotic-results-unequal-variance-assumption" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Inference via asymptotic results (unequal variance assumption)</h3>
<p>Previously we’ve seen that the Central Limit Theorem gives us a way to estimate the distribution of the sample mean. So it should be reasonable to assume that for our two groups (1=NonCaffeine, 2=Caffeine), <span class="math display">\[\bar{X}_{1}\stackrel{\cdot}{\sim}N\left(\mu_{1},\, \frac{\sigma_{1}^{2}}{n_1}\right)\;\;\;\textrm{and}\;\;\;\bar{X}_{2}\stackrel{\cdot}{\sim}N\left(\mu_{2},\; \frac{\sigma_{2}^{2}}{n_2}\right)\]</span></p>
<p>It turns out that because <span class="math inline">\(\bar{X}_{C}\)</span> and <span class="math inline">\(\bar{X}_{NC}\)</span> both have approximately normal distributions, then the difference between them also does. This shouldn’t be too surprising after looking at the permutation and bootstrap distributions of the <span class="math inline">\(d^*\)</span> values.</p>
<p>So our hypothesis tests and confidence interval routine will follow a similar pattern as our one-sample tests, but we now need to figure out the correct standardization formula for the difference in means. The only difficulty will be figuring out what the appropriate standard deviation term <span class="math inline">\(\hat{\sigma}_{D}\)</span> should be.</p>
<p>Recall that if two random variables, A and B, are independent then <span class="math display">\[Var\left(A-B\right)=Var(A)+Var(B)\]</span> and therefore <span class="math display">\[\begin{aligned} Var\left(D\right) 
  &amp;=    Var\left(\bar{X}_{1}-\bar{X}_{2}\right) \\
    &amp;=  Var\left(\bar{X}_{1}\right)+Var\left(\bar{X}_{2}\right) \\
    &amp;=  \frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}
    \end{aligned}\]</span> and finally we have <span class="math display">\[StdErr\left(D\right)=\sqrt{\frac{s_{1}^{2}}{n_{1}}+\frac{s_{2}^{2}}{n_{2}}}\]</span> and therefore my standardized value for the difference will be <span class="math display">\[\begin{aligned} t_{???}   
  &amp;=    \frac{\textrm{estimate}\,\,\,-\,\,\,\textrm{hypothesized value}}{StdErr\left(\,\,\textrm{estimate}\,\,\right)} \\
    &amp;=  \frac{\left(\bar{x}_{1}-\bar{x}_{2}\right)-0}{\sqrt{\frac{s_{1}^{2}}{n_{1}}+\frac{s_{2}^{2}}{n_{2}}}} \\
    &amp;=  \frac{\left(-3.5\right)-0}{\sqrt{\frac{2.39^{2}}{10}+\frac{2.21^{2}}{10}}} \\
    &amp;=  -3.39 
    \end{aligned}\]</span></p>
<p>This is somewhat painful, but reasonable. The last question is what t-distribution should we compare this to? Previously we’ve used <span class="math inline">\(df=n-1\)</span> but now we have two samples. So our degrees of freedom ought to be somewhere between <span class="math inline">\(\min\left(n_{1},n_{2}\right)-2=8\)</span> and <span class="math inline">\(\left(n_{1}+n_{2}\right)-1=19\)</span>.</p>
<p>There is no correct answer, but the best approximation to what it should be is called Satterwaite’s Approximation. <span class="math display">\[df=\frac{\left(V_{1}+V_{2}\right)^{2}}{\frac{V_{1}^{2}}{n_{1}-1}+\frac{V_{2}^{2}}{n_{2}-1}}\]</span> where <span class="math display">\[V_{1}=\frac{s_{1}^{2}}{n_{1}}\;\;\textrm{and }\;\;V_{2}=\frac{s_{2}^{2}}{n_{2}}\]</span></p>
<p>So for our example we have</p>
<p><span class="math display">\[V_{1}=\frac{2.39^{2}}{10}=0.5712\;\;\;\textrm{and}\;\;\;V_{2}=\frac{2.21^{2}}{10}=0.4884\]</span> and <span class="math display">\[df=\frac{\left(0.5712+0.4884\right)^{2}}{\frac{\left(0.5712\right)^{2}}{9}+\frac{\left(0.4884\right)^{2}}{9}}=17.89\]</span></p>
<p>So now we can compute our p-value as</p>
<p><span class="math display">\[\textrm{p.value}=P\left(T_{17.89}&lt;-3.39\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mosaic<span class="op">::</span><span class="kw">xpt</span>(<span class="op">-</span><span class="fl">3.39</span>, <span class="dt">df=</span><span class="fl">17.89</span>, <span class="dt">ncp=</span><span class="dv">0</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre><code>## [1] 0.00164277</code></pre>
<p>In a similar fashion, we can calculate the confidence interval in our usual fashion</p>
<p><span class="math display">\[\begin{aligned}
\textrm{Est}\;\; &amp;\pm\; t_{???}^{1-\alpha/2}\;\textrm{StdErr}\left(\;\textrm{Est}\;\right)  \\  
\left(\bar{x}_{1}-\bar{x}_{2}\right)  &amp;\pm  t_{17.89}^{1-\alpha/2}\sqrt{\frac{s_{1}^{2}}{n_{1}}+\frac{s_{2}^{2}}{n_{2}}} \\
-3.5  &amp;\pm  2.10\sqrt{\frac{2.39^{2}}{10}+\frac{2.21^{2}}{10}} \\
-3.5  &amp;\pm  2.16 
\end{aligned}\]</span></p>
<p><span class="math display">\[\left(-5.66,\;-1.34\right)\]</span></p>
<p>It is probably fair to say that this is an ugly calculation to do by hand. Fortunately it isn’t too hard to make R do these calculations for you. The function <code>t.test()</code> will accept two arguments, a vector of values from the first group and a vector from the second group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##### Using the base function t.test
<span class="co"># Caffeine    &lt;- CaffeineTaps$Taps[ 1:10]  # first 10 are Caffeine</span>
<span class="co"># NonCaffeine &lt;- CaffeineTaps$Taps[11:20]  # last 10 are non-Caffeine</span>
<span class="co"># t.test( NonCaffeine, Caffeine )</span>

<span class="co"># Using the mosaic version that allows me to give it a formula</span>
mosaic<span class="op">::</span><span class="kw">t.test</span>(Taps <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>CaffeineTaps)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Taps by Group
## t = 3.3942, df = 17.89, p-value = 0.003255
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.332616 5.667384
## sample estimates:
##   mean in group Caffeine mean in group NoCaffeine 
##                    248.3                    244.8</code></pre>
</div>
<div id="inference-via-asymptotic-results-equal-variance-assumption" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Inference via asymptotic results (equal variance assumption)</h3>
<p>In the <code>CaffeineTaps</code> example, the standard deviations of each group are quite similar. Instead of thinking of the data as <span class="math display">\[\bar{X}_{1}\stackrel{\cdot}{\sim}N\left(\mu_{1},\,\frac{\sigma_{1}^{2}}{n_1}\right)\;\;\;\textrm{and}\;\;\;\bar{X}_{2}\stackrel{\cdot}{\sim}N\left(\mu_{2},\;\frac{\sigma_{2}^{2}}{n_2}\right)\]</span> we could consider the model where we assume that the variance term is the same for each sample. <span class="math display">\[\bar{X}_{1}\stackrel{\cdot}{\sim}N\left(\mu_{1},\,\frac{\sigma^{2}}{n_1}\right)\;\;\;\textrm{and}\;\;\;\bar{X}_{2}\stackrel{\cdot}{\sim}N\left(\mu_{2},\; \frac{\sigma^{2}}{n_2}\right)\]</span></p>
<p>First, we can estimate <span class="math inline">\(\mu_{1}\)</span> and <span class="math inline">\(\mu_{2}\)</span> with the appropriate sample means <span class="math inline">\(\bar{x}_{1}\)</span> and <span class="math inline">\(\bar{x}_{2}\)</span>. Next we need to calculate an estimate of <span class="math inline">\(\sigma\)</span> using all of the data. First recall the formula for the sample variance for one group was <span class="math display">\[s^{2}=\frac{1}{n-1}\left[\sum_{j=1}^{n}\left(x_{j}-\bar{x}\right)^{2}\right]\]</span></p>
<p>In the case with two samples, we want a similar formula but it should take into account data from both sample groups. Define the notation <span class="math inline">\(x_{1j}\)</span> to be the <span class="math inline">\(j\)</span>th observation of group 1, and <span class="math inline">\(x_{2j}\)</span> to be the <span class="math inline">\(j\)</span>th observation of group 2 and in general <span class="math inline">\(x_{ij}\)</span> as the <span class="math inline">\(j\)</span>th observation from group <span class="math inline">\(i\)</span>. We want to subtract each observation from the its appropriate sample mean and then, because we had to estimate two means, we need to subtract two degrees of freedom from the denominator. <span class="math display">\[\begin{aligned} s_{pooled}^{2}    
  &amp;=    \frac{1}{n_{1}+n_{2}-2}\left[\sum_{j=1}^{n_{1}}\left(x_{1j}-\bar{x}_{1}\right)^{2}+\sum_{j=1}^{n_{2}}\left(x_{2j}-\bar{x}_{2}\right)^{2}\right] \\
    &amp;=  \frac{1}{n_{1}+n_{2}-2}\left[\sum_{j=1}^{n_{1}}e_{1j}^{2}+\sum_{j=1}^{n_{2}}e_{2j}^{2}\right]\\
    &amp;=  \frac{1}{n_{1}+n_{2}-2}\left[\sum_{i=1}^{2}\sum_{j=1}^{n_{i}}e_{ij}^{2}\right]
    \end{aligned}\]</span></p>
<p>where <span class="math inline">\(\bar{x}_{1}\)</span> and <span class="math inline">\(\bar{x}_{2}\)</span> are the sample means and <span class="math inline">\(e_{ij}=x_{ij}-\bar{x}_{i}\)</span> is the residual error of the <span class="math inline">\(i,j\)</span> observation. A computationally convenient formula for this same quantity is <span class="math display">\[s_{pooled}^{2}=\frac{1}{n_{1}+n_{2}-2}\left[\left(n_{1}-1\right)s_{1}^{2}+\left(n_{2}-1\right)s_{2}^{2}\right]\]</span></p>
<p>Finally we notice that this pooled estimate of the variance term <span class="math inline">\(\sigma^{2}\)</span> has <span class="math inline">\(n_{1}+n_{2}-2\)</span> degrees of freedom. One benefit of the pooled procedure is that we don’t have to mess with the Satterthwaite’s approximate degrees of freedom.</p>
<p>Recall our test statistic in the unequal variance case was <span class="math display">\[t_{???} 
  =\frac{\left(\bar{x}_{1}-\bar{x}_{2}\right)-0}{\sqrt{\frac{s_{1}^{2}}{n_{1}}+\frac{s_{2}^{2}}{n_{2}}}}\]</span> but in the equal variance case, we will use the pooled estimate of the variance term <span class="math inline">\(s_{pooled}^{2}\)</span> instead of <span class="math inline">\(s_{1}^{2}\)</span> and <span class="math inline">\(s_{2}^{2}\)</span>. So our test statistic becomes</p>
<p><span class="math display">\[\begin{aligned} t_{df=n_{1}+n_{2}-2}  
  &amp;=    \frac{\left(\bar{x}_{1}-\bar{x}_{2}\right)-0}{\sqrt{\frac{s_{pool}^{2}}{n_{1}}+\frac{s_{pool}^{2}}{n_{2}}}} \\
    &amp;=  \frac{\left(\bar{x}_{1}-\bar{x}_{2}\right)-0}{s_{pool}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}
  \end{aligned}\]</span></p>
<p>where we have <span class="math display">\[StdErr\left(\bar{X}_{1}-\bar{X}_{2}\right)=s_{pooled}\sqrt{\left(1/n_{1}\right)+\left(1/n_{2}\right)}\]</span> For the <code>CaffeineTaps</code> data, this results in the following analysis for <span class="math display">\[\begin{aligned}
H_{0}:  &amp;\mu_{nc}-\mu_{c}  =  0   \\
H_{a}:  &amp;\mu_{nc}-\mu_{c} \ne 0 
\end{aligned}\]</span></p>
<p>First we have to calculate the summary statistics (along with the pooled <span class="math inline">\(\sigma_{pooled}\)</span>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CaffeineTaps <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar.i =</span> <span class="kw">mean</span>(Taps),   <span class="co"># sample mean for each group</span>
            <span class="dt">s2.i   =</span> <span class="kw">var</span>(Taps),    <span class="co"># sample variances for each group</span>
            <span class="dt">s.i    =</span> <span class="kw">sd</span>(Taps),     <span class="co"># sample standard deviations for each group</span>
            <span class="dt">n.i    =</span> <span class="kw">n</span>()      )    <span class="co"># sample sizes for each group</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   Group      xbar.i  s2.i   s.i   n.i
##   &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1 Caffeine     248.  4.90  2.21    10
## 2 NoCaffeine   245.  5.73  2.39    10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">CaffeineTaps <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(  <span class="dt">n.i =</span> <span class="kw">n</span>(),             
             <span class="dt">s2.i =</span> <span class="kw">var</span>(Taps) ) <span class="op">%&gt;%</span><span class="st">     </span>
<span class="st">  </span><span class="kw">summarize</span>( <span class="dt">s2.p =</span> <span class="kw">sum</span>( (n.i<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>s2.i ) <span class="op">/</span><span class="st"> </span>( <span class="kw">sum</span>(n.i)<span class="op">-</span><span class="dv">2</span> ),
             <span class="dt">s.p  =</span> <span class="kw">sqrt</span>(s2.p) ) </code></pre></div>
<pre><code>## # A tibble: 1 x 2
##    s2.p   s.p
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  5.32  2.31</code></pre>
<p>Next we can calculate <span class="math display">\[t_{18}=\frac{\left(244.8-248.3\right)-0}{2.31\sqrt{\frac{1}{10}+\frac{1}{10}}}=-3.39\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p.value &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="op">-</span><span class="fl">3.39</span>, <span class="dt">df=</span><span class="dv">18</span>)   <span class="co"># 2-sided test, so multiply by 2</span>
p.value</code></pre></div>
<pre><code>## [1] 0.003262969</code></pre>
<p>The associated <span class="math inline">\(95\%\)</span> confidence interval is <span class="math display">\[\left(\bar{x}_{1}-\bar{x}_{2}\right)\pm t_{n_{1}+n_{2}-2}^{1-\alpha/2}\;\left(s_{pool}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>( .<span class="dv">975</span>, <span class="dt">df=</span><span class="dv">18</span> ) </code></pre></div>
<pre><code>## [1] 2.100922</code></pre>
<p><span class="math display">\[\begin{aligned}
-3.5 &amp;\pm 2.10\left(\,2.31\sqrt{\frac{1}{10}+\frac{1}{10}}\right) \\
-3.5 &amp;\pm 2.17 
\end{aligned}\]</span> <span class="math display">\[\left(-5.67,\;-1.33\right)\]</span></p>
<p>This p-value and <span class="math inline">\(95\%\)</span> confidence interval are quite similar to the values we got in the case where we assumed unequal variances.</p>
<p>As usual, these calculations are pretty annoying to do by hand and we wish to instead do them using R. Again the function <code>t.test()</code> will do the annoying calculations for us.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Do the t-test</span>
mosaic<span class="op">::</span><span class="kw">t.test</span>( Taps <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>CaffeineTaps, <span class="dt">var.equal=</span><span class="ot">TRUE</span> ) </code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Taps by Group
## t = 3.3942, df = 18, p-value = 0.003233
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.33357 5.66643
## sample estimates:
##   mean in group Caffeine mean in group NoCaffeine 
##                    248.3                    244.8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Do the t-test</span>
mosaic<span class="op">::</span><span class="kw">t.test</span>( Taps <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>CaffeineTaps, <span class="dt">var.equal=</span><span class="ot">TRUE</span>, <span class="dt">conf.level=</span>.<span class="dv">99</span> ) </code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Taps by Group
## t = 3.3942, df = 18, p-value = 0.003233
## alternative hypothesis: true difference in means is not equal to 0
## 99 percent confidence interval:
##  0.5318082 6.4681918
## sample estimates:
##   mean in group Caffeine mean in group NoCaffeine 
##                    248.3                    244.8</code></pre>
<p><strong>Example</strong> - Does drinking beer increase your attractiveness to mosquitoes?</p>
<p>In places in the country substantial mosquito populations, the question of whether drinking beer causes the drinker to be more attractive to the mosquitoes than drinking something else has plagued campers. To answer such a question, researchers conducted a study to determine if drinking beer attracts more mosquitoes than drinking water. Of <span class="math inline">\(n=43\)</span> subjects, <span class="math inline">\(n_{b}=25\)</span> drank a liter beer and <span class="math inline">\(n_{w}=18\)</span> drank a liter of water and mosquitoes were caught in traps as they approached the different subjects. The critical part of this study is that the treatment (beer or water) was randomly assigned to each subject.</p>
<p>For this study, we want to test <span class="math display">\[H_{0}:\:\delta=0\;\;\;\;\;\;\textrm{vs}\;\;\;\;\;\;H_{a}:\,\delta&lt;0\]</span> where we define <span class="math inline">\(\delta=\mu_{w}-\mu_{b}\)</span> and <span class="math inline">\(\mu_{b}\)</span> is the mean number of mosquitoes attracted to a beer drinker and <span class="math inline">\(\mu_{w}\)</span> is the mean number attracted to a water drinker. As usual we begin our analysis by plotting the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># I can&#39;t find this dataset on-line so I&#39;ll just type it in.</span>
Mosquitoes &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Number =</span> <span class="kw">c</span>(<span class="dv">27</span>,<span class="dv">19</span>,<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">23</span>,<span class="dv">17</span>,<span class="dv">21</span>,<span class="dv">24</span>,<span class="dv">31</span>,<span class="dv">26</span>,<span class="dv">28</span>,<span class="dv">20</span>,<span class="dv">27</span>,
             <span class="dv">19</span>,<span class="dv">25</span>,<span class="dv">31</span>,<span class="dv">24</span>,<span class="dv">28</span>,<span class="dv">24</span>,<span class="dv">29</span>,<span class="dv">21</span>,<span class="dv">21</span>,<span class="dv">18</span>,<span class="dv">27</span>,<span class="dv">20</span>,
             <span class="dv">21</span>,<span class="dv">19</span>,<span class="dv">13</span>,<span class="dv">22</span>,<span class="dv">15</span>,<span class="dv">22</span>,<span class="dv">15</span>,<span class="dv">22</span>,<span class="dv">20</span>,
             <span class="dv">12</span>,<span class="dv">24</span>,<span class="dv">24</span>,<span class="dv">21</span>,<span class="dv">19</span>,<span class="dv">18</span>,<span class="dv">16</span>,<span class="dv">23</span>,<span class="dv">20</span>),
  <span class="dt">Treat =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;Beer&#39;</span>, <span class="dv">25</span>), <span class="kw">rep</span>(<span class="st">&#39;Water&#39;</span>,<span class="dv">18</span>) ) )

<span class="co"># Plot the data</span>
<span class="kw">ggplot</span>(Mosquitoes, <span class="kw">aes</span>(<span class="dt">x=</span>Number)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>( Treat <span class="op">~</span><span class="st"> </span>. )</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>For this experiment and the summary statistic that captures the difference we are trying to understand is <span class="math inline">\(d=\bar{x}_{w}-\bar{x}_{b}\)</span> where <span class="math inline">\(\bar{x}_{w}\)</span> is the sample mean number of mosquitoes attracted by the water group and <span class="math inline">\(\bar{x}_{b}\)</span> is the sample mean number of mosquitoes attracted by the beer group. Because of the order we chose for the subtraction, a negative value for d is supportive of the alternative hypothesis that mosquitoes are more attracted to beer drinkers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Mosquitoes <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Treat) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar.i =</span> <span class="kw">mean</span>(Number),
            <span class="dt">s2.i   =</span> <span class="kw">var</span>(Number),
            <span class="dt">s.i    =</span> <span class="kw">sd</span>(Number),
            <span class="dt">n.i    =</span> <span class="kw">n</span>())</code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   Treat xbar.i  s2.i   s.i   n.i
##   &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1 Beer    23.6  17.1  4.13    25
## 2 Water   19.2  13.5  3.67    18</code></pre>
<p>Here we see that our statistic of interest is <span class="math display">\[\begin{aligned} d 
  &amp;=    \bar{x}_{w}-\bar{x}_{b} \\
    &amp;=  19.22-23.6              \\
    &amp;=  -4.37\bar{7}
    \end{aligned}\]</span> The hypothesis test and confidence interval to see if this is statistically significant evidence to conclude that beer increases attractiveness to mosquitoes is as follows. First we perform the hypothesis test by creating the sampling distribution of <span class="math inline">\(d^*\)</span> assuming <span class="math inline">\(H_0\)</span> is true by repeatedly shuffling the group labels and calculating differences.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">PermutationDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span>{
  Mosquitoes <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">ShuffledTreat =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Treat)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>( ShuffledTreat )              <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarise</span>( <span class="dt">xbar.i =</span> <span class="kw">mean</span>(Number) )     <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarise</span>( <span class="dt">d.star =</span> <span class="kw">diff</span>(xbar.i) )
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(PermutationDist, <span class="kw">aes</span>(<span class="dt">x=</span>d.star)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Sampling Dist. of d* assuming H0 is true&#39;</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p.value &lt;-<span class="st"> </span>PermutationDist <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>( <span class="kw">mean</span>( d.star <span class="op">&lt;=</span><span class="st"> </span><span class="op">-</span><span class="fl">4.377</span> ))
p.value</code></pre></div>
<pre><code>##   mean(d.star &lt;= -4.377)
## 1                  2e-04</code></pre>
<p>The associated confidence interval (lets do a <span class="math inline">\(90\%\)</span> confidence level), is created via bootstrapping.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{
  Mosquitoes <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Treat)                     <span class="op">%&gt;%</span>
<span class="st">    </span>mosaic<span class="op">::</span><span class="kw">resample</span>()                  <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarise</span>( <span class="dt">xbar.i =</span> <span class="kw">mean</span>(Number) )  <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarise</span>( <span class="dt">d.star =</span> <span class="kw">diff</span>(xbar.i) )    
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(BootDist, <span class="kw">aes</span>(<span class="dt">x=</span>d.star)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Bootstrap dist. of d*&#39;</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>( BootDist<span class="op">$</span>d.star, <span class="dt">probs=</span><span class="kw">c</span>(.<span class="dv">05</span>, .<span class="dv">95</span>))</code></pre></div>
<pre><code>##        5%       95% 
## -6.336262 -2.449065</code></pre>
<p>The calculated p-value is extremely small and the associated two-sided 90% confidence interval does not contain 0, so we can conclude that the choice of drink does cause a change in attractiveness to mosquitoes.</p>
<p>If we wanted to perform the same analysis using asymptotic methods we could do the calculations by hand, or just use R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mosaic<span class="op">::</span><span class="kw">t.test</span>( Number <span class="op">~</span><span class="st"> </span>Treat, <span class="dt">data=</span>Mosquitoes, 
        <span class="dt">var.equal=</span><span class="ot">TRUE</span>, <span class="dt">conf.level=</span><span class="fl">0.90</span>)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Number by Treat
## t = 3.587, df = 41, p-value = 0.0008831
## alternative hypothesis: true difference in means is not equal to 0
## 90 percent confidence interval:
##  2.323889 6.431666
## sample estimates:
##  mean in group Beer mean in group Water 
##            23.60000            19.22222</code></pre>
<p>Notice that we didn’t specify the order for the subtraction and the <code>mosaic:t.test()</code> function did the subtraction in the opposite order than we did. The p-value is slightly different but doesn’t change the resulting inference.</p>
</div>
</div>
<div id="difference-in-means-between-two-groups-paired-data" class="section level2">
<h2><span class="header-section-number">7.2</span> Difference in means between two groups: Paired Data</h2>
<p>If the context of study is such that we can logically pair an observation from the first population to a particular observation in the second, then we can perform what is called a Paired Test. In a paired test, we will take each set of paired observations, calculate the difference, and then perform a 1-sample regular hypothesis test on the differences.</p>
<p>For example, in the package Lock5Data there is a dataset that examines the age in which men and women get married. The data was obtained by taking a random sample from publicly available marriage licenses in St. Lawrence County, NY.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(MarriageAges, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)
<span class="kw">head</span>(MarriageAges)</code></pre></div>
<pre><code>##   Husband Wife
## 1      53   50
## 2      38   34
## 3      46   44
## 4      30   36
## 5      31   23
## 6      26   31</code></pre>
<p>Unfortunately the format of this dataset is not particularly convenient for making graphs. Instead I want to turn this data into a “long” dataset where I have one row per person, not one row per marriage.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a dataset that is more convenient for graphing.</span>
MarriageAges.Long &lt;-<span class="st"> </span>MarriageAges <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Marriage =</span> <span class="kw">factor</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">n</span>())) <span class="op">%&gt;%</span><span class="st">        </span><span class="co"># Give each row a unique ID </span>
<span class="st">  </span><span class="kw">gather</span>(<span class="st">&#39;Spouse&#39;</span>, <span class="st">&#39;Age&#39;</span>, Husband, Wife) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># pivot from Husband/Wife to Spouse/Age</span>
<span class="st">  </span><span class="kw">arrange</span>(Marriage, <span class="kw">desc</span>(Spouse))             <span class="co"># Sort by Marriage, then (Wife,Husband)</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a graph of ages, by Spouse Type</span>
<span class="kw">ggplot</span>(MarriageAges.Long, <span class="kw">aes</span>(<span class="dt">x=</span>Age)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span><span class="dv">5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(Spouse <span class="op">~</span><span class="st"> </span>.) </code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>Looking at this view of the data, it doesn’t appear that the husbands tend to be older than the wives. A t-test to see if the average age of husbands is greater than the average age of wives gives an insignificant difference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mosaic<span class="op">::</span><span class="kw">t.test</span>( Age <span class="op">~</span><span class="st"> </span>Spouse, <span class="dt">data=</span>MarriageAges.Long )</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Age by Spouse
## t = 1.8055, df = 203.12, p-value = 0.07248
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.2603887  5.9175316
## sample estimates:
## mean in group Husband    mean in group Wife 
##              34.66667              31.83810</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># t.test( MarriageAges$Husband, MarriageAges$Wife )  # Another way to run the t.test</span></code></pre></div>
<p>But critically, we are ignoring that while the average ages might not be different, for a given marriage, the husband tends to be older than the wife. Instead of looking at the difference in the means (i.e <span class="math inline">\(d=\bar{h}-\bar{w}\)</span>) we should actually be looking at the mean of the differences <span class="math inline">\(\bar{d}=\frac{1}{n}\sum d_{i}\)</span> where <span class="math inline">\(d_{i}=h_{i}-w_{i}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MarriageAges &lt;-<span class="st"> </span>MarriageAges  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">d =</span> Husband <span class="op">-</span><span class="st"> </span>Wife )   

<span class="kw">ggplot</span>(MarriageAges, <span class="kw">aes</span>(<span class="dt">x =</span> d)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Given this set of differences, we’d like to know if this data is compatible with the null hypothesis that husbands and wives tend to be the same age versus the alternative that husbands tend to be older. (We could chose the two-sided test as well). <span class="math display">\[\begin{aligned}
H_{0}:\;\delta  &amp;=  0  \\
H_{A}:\;\delta  &amp;&gt;  0
\end{aligned}\]</span></p>
<p>Because we have reduced our problem to a 1-sample test, we can perform the asymptotic t-test easily enough in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>( MarriageAges<span class="op">$</span>d )</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  MarriageAges$d
## t = 5.8025, df = 104, p-value = 7.121e-08
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  1.861895 3.795248
## sample estimates:
## mean of x 
##  2.828571</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#t.test( MarriageAges$Husband, MarriageAges$Wife, paired=TRUE )  # Another way to run the t.test</span></code></pre></div>
<p>The result is highly statistically significant, and we see the mean difference in ages for the husband to be 2.8 years older.</p>
<p>To perform the same analysis using re-sampling methods, we need to be careful to do the re-sampling correctly. To perform the hypothesis test, we want to create data where the null hypothesis is true. To do this, we’ll shuffle the ages within the marriage so that the husband and the wife have equal probability of being the older spouse. For the bootstrap CI, we need to be certain that we are re-sampling marriages, not people.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Permutation t-test of delta == 0</span>
PermDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{ 
  MarriageAges.Long            <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Marriage)         <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Age =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Age)) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># shuffle the ages within each marriage</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.i =</span> <span class="kw">diff</span>(Age))         <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Calc Husband - Wife age difference</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.bar =</span> <span class="kw">mean</span>(d.i))            <span class="co"># calc the mean difference</span>
}
<span class="kw">ggplot</span>(PermDist, <span class="kw">aes</span>(<span class="dt">x=</span>d.bar)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>()</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">PermDist <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>( <span class="dt">p.value =</span> <span class="kw">mean</span>(d.bar <span class="op">&gt;=</span><span class="st"> </span><span class="fl">2.83</span>) )</code></pre></div>
<pre><code>##   p.value
## 1       0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Bootstrap CI for delta</span>
BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{ 
  MarriageAges.Long            <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Marriage)         <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.i =</span> <span class="kw">diff</span>(Age)) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Calc observed Husband - Wife age differences</span>
<span class="st">      </span>mosaic<span class="op">::</span><span class="kw">resample</span>()         <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># resample from the observed differences</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.bar =</span> <span class="kw">mean</span>(d.i))    <span class="co"># calc the mean difference</span>
}
<span class="kw">quantile</span>( BootDist<span class="op">$</span>d.bar, <span class="dt">probs=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>) )</code></pre></div>
<pre><code>##     2.5%    97.5% 
## 1.895238 3.809524</code></pre>
<p>We observe a similar p-value and confidence interval as we did using the asymptotic test as expected. The code for calculating the bootstrap CI is a bit inefficient because I keep recalculating the observed differences with each bootstrap. However, it is nice to have the code “recipe” for the hypothesis test and the associated CI to be fairly similar.</p>
<p><strong>Example</strong> - Traffic Flow</p>
<p>Engineers in Dresden, Germany were looking at ways to improve traffic flow by enabling traffic lights to communicate information about traffic flow with nearby traffic lights and modify their timing sequence appropriately. The engineers wished to compare new flexible timing system with the standard fixed timing sequence by evaluating the delay at a randomly selected <span class="math inline">\(n=24\)</span> intersections in Dresden. The data show results of one experiment where they simulated buses moving along a street and recorded the delay time for both systems. Because each simulation is extremely intensive, they only simulated <span class="math inline">\(n=24\)</span> intersections instead of simulating the whole city.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(TrafficFlow, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)  
<span class="kw">head</span>(TrafficFlow)</code></pre></div>
<pre><code>##   Timed Flexible Difference
## 1    88       45         43
## 2    90       46         44
## 3    91       45         46
## 4    99       51         48
## 5   101       48         53
## 6   101       48         53</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># A data set more convenient for Graphing and Permutation Tests.</span>
TrafficFlow.Long &lt;-<span class="st"> </span>TrafficFlow           <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Light =</span> <span class="kw">factor</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()))           <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Give each row a unique ID </span>
<span class="st">  </span><span class="kw">gather</span>(<span class="st">&#39;Seq&#39;</span>, <span class="st">&#39;Delay&#39;</span>, Flexible, Timed) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># pivot to SequenceType and Delay amount</span>
<span class="st">  </span><span class="kw">arrange</span>(Light, Seq)                         <span class="co"># Sort by Light, then by SequenceType</span>
<span class="kw">head</span>(TrafficFlow.Long)</code></pre></div>
<pre><code>##   Difference Light      Seq Delay
## 1         43     1 Flexible    45
## 2         43     1    Timed    88
## 3         44     2 Flexible    46
## 4         44     2    Timed    90
## 5         46     3 Flexible    45
## 6         46     3    Timed    91</code></pre>
<p>As usual, we’ll first examine the data with a graph.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TrafficFlow.Long, <span class="kw">aes</span>(<span class="dt">x=</span>Delay)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span><span class="dv">2</span>) <span class="op">+</span><span class="st">              </span><span class="co"># histograms of Delay time</span>
<span class="st">  </span><span class="kw">facet_grid</span>(Seq <span class="op">~</span><span class="st"> </span>.)                       <span class="co"># two plots, stacked by SequenceType</span></code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(TrafficFlow, <span class="kw">aes</span>(<span class="dt">x=</span>Difference)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Difference (Standard - Flexible)&#39;</span>)</code></pre></div>
<p><img src="07_Two_Samples_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>All of the differences were positive, so it is almost ridiculous to do a hypothesis test that there is no decrease in delays with the flexible timing system, but we might as well walk through the analysis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>( TrafficFlow<span class="op">$</span>Difference )</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  TrafficFlow$Difference
## t = 19.675, df = 23, p-value = 6.909e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  54.58639 67.41361
## sample estimates:
## mean of x 
##        61</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Permutation t-test of delta == 0</span>
PermDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{ 
  TrafficFlow.Long                         <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Light)                        <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Delay =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(Delay)) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># shuffle the delays within each intersection</span>
<span class="st">    </span><span class="kw">arrange</span>(Light, Seq)                    <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Put into the Flexible, SeqType order</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.i =</span> <span class="kw">diff</span>(Delay))           <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Calc Timed - Flexible delay difference</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.bar =</span> <span class="kw">mean</span>(d.i))                <span class="co"># calc the mean difference</span>
}
PermDist <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>( <span class="dt">p.value =</span> <span class="kw">mean</span>(d.bar <span class="op">&gt;=</span><span class="st"> </span><span class="dv">61</span>) )</code></pre></div>
<pre><code>##   p.value
## 1       0</code></pre>
<p>Our p-value is 0, but because we we actually only did 10,000 permutations, the most we can say is that the p-value is less than 1/ 10,000.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Bootstrap CI for delta</span>
BootDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{ 
  TrafficFlow.Long               <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(Light)              <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.i =</span> <span class="kw">diff</span>(Delay)) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Calc observed Timed-Flexible delay differences</span>
<span class="st">    </span>mosaic<span class="op">::</span><span class="kw">resample</span>()           <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># resample from the observed differences</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">d.bar =</span> <span class="kw">mean</span>(d.i))      <span class="co"># calc the mean difference</span>
}
<span class="kw">quantile</span>( BootDist<span class="op">$</span>d.bar, <span class="dt">probs=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>) )</code></pre></div>
<pre><code>##     2.5%    97.5% 
## 55.54167 67.33333</code></pre>
<p>The confidence interval suggests that these data support that the mean difference between the flexible timing sequence versus the standard fixed timing sequence in Dresden is in the interval <span class="math inline">\(\left(55.5,\,67.3\right)\)</span> seconds.</p>
</div>
<div id="exercises-6" class="section level2">
<h2><span class="header-section-number">7.3</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>In the 2011 article “Methane contamination of drinking water accompanying gas-well drilling and hydraulic fracturing” in the Proceedings of the National Academy of Sciences, <span class="math inline">\(n_{1}=21\)</span> sites in proximity to a fracking well had a mean methane level of <span class="math inline">\(\bar{x}_{1}=19.2\)</span> mg <span class="math inline">\(CH_{4} L^{-1}\)</span> with a sample standard deviation <span class="math inline">\(s_{1}=30.3\)</span>. The <span class="math inline">\(n_{2}=13\)</span> sites in the same region with no fracking wells within 1 kilometer had mean methane levels of <span class="math inline">\(\bar{x}_{2}=1.1\)</span> mg <span class="math inline">\(CH_{4} L^{-1}\)</span> and standard deviation <span class="math inline">\(s_{2}=6.3\)</span>. Perform a one-sided, two-sample t-test with unpooled variance and an <span class="math inline">\(\alpha=0.05\)</span> level to investigate if the presence of fracking wells increases the methane level in drinking-water wells in this region. Notice that because I don’t give you the data, you can only analyze the data using the asymptotic method and plugging in the give quantities into the formulas presented.
<ol style="list-style-type: lower-alpha">
<li>State an appropriate null and alternative hypothesis. (Be sure to use correct notation!)</li>
<li>Calculate an appropriate test statistic (making sure to denote the appropriate degrees of freedom, if necessary).</li>
<li>Calculate an appropriate p-value.</li>
<li>At an significance level of <span class="math inline">\(\alpha=0.05\)</span>, do you reject or fail to reject the null hypothesis?</li>
<li>Restate your conclusion in terms of the problem.</li>
</ol></li>
<li>All persons running for public office must report the amount of money raised and spent during their campaign. Political scientists contend that it is more difficult for female candidates to raise money. Suppose that we randomly sample <span class="math inline">\(30\)</span> male and <span class="math inline">\(30\)</span> female candidates for state legislature and observe the male candidates raised, on average, <span class="math inline">\(\bar{y}=\$350,000\)</span> with a standard deviation of <span class="math inline">\(s_{y}=\$61,900\)</span> and the females raised on average <span class="math inline">\(\bar{x}=\$245,000\)</span> with a standard deviation of <span class="math inline">\(s_{x}=\$52,100\)</span>. Perform a one-sided, two-sample t-test with pooled variance to test if female candidates generally raise less in their campaigns that male candidates. <em>Notice that because I don’t give you the data, you can only analyze the data using the asymptotic method and plugging in the give quantities into the formulas presented.</em>
<ol style="list-style-type: lower-alpha">
<li>State an appropriate null and alternative hypothesis. (Be sure to use correct notation!)</li>
<li>Calculate an appropriate test statistic (making sure to denote the appropriate degrees of freedom, if necessary).</li>
<li>Calculate an appropriate p-value.</li>
<li>At an significance level of <span class="math inline">\(\alpha=0.05\)</span>, do you reject or fail to reject the null hypothesis?</li>
<li>Restate your conclusion in terms of the problem.</li>
</ol></li>
<li>In the Lock5Data package, the dataset <code>Smiles</code> gives data “…from a study examining the effect of a smile on the leniency of disciplinary action for wrongdoers. Participants in the experiment took on the role of members of a college disciplinary panel judging students accused of cheating. For each suspect, along with a description of the offense, a picture was provided with either a smile or neutral facial expression. Note, that for each individual only one picture was submitted. A leniency score was calculated based on the disciplinary decisions made by the participants.”
<ol style="list-style-type: lower-alpha">
<li>Graph the leniency score for the smiling and non-smiling groups. Comment on if you can visually detect any difference in leniency score.</li>
<li>Calculate the mean and standard deviation of the leniencies for each group. Does it seem reasonable that the standard deviation of each group is the same?</li>
<li>Do a two-sided two-sample t-test using pooled variance using the asymptotic method. Report the test statistic, p-value, and a <span class="math inline">\(95\%\)</span> CI.</li>
<li>Do a two-side two-sample t-test using re-sampling methods. Report the p-value and a <span class="math inline">\(95\%\)</span> CI.</li>
<li>What do you conclude at an <span class="math inline">\(\alpha=0.05\)</span> level? Do you feel we should have used a more stringent <span class="math inline">\(\alpha\)</span> level?</li>
</ol></li>
<li><p>In the Lock5Data package, the dataset <code>StorySpoilers</code> is data from an experiment where the researchers are testing if a “spoiler” at the beginning of a short story negatively affects the enjoyment of the story. A set of <span class="math inline">\(n=12\)</span> stories were selected and a spoiler introduction was created. Each version of each story was read by at least <span class="math inline">\(30\)</span> people and rated. Reported are the average ratings for the spoiler and non-spoiler versions of each story. The following code creates the “long” version of the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tidyr)
<span class="kw">data</span>(StorySpoilers, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)
StorySpoilers.Long &lt;-<span class="st"> </span>StorySpoilers <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(<span class="st">&#39;Type&#39;</span>, <span class="st">&#39;Rating&#39;</span>, Spoiler, Original) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">Story =</span> <span class="kw">factor</span>(Story),      <span class="co"># make Story and Type into</span>
          <span class="dt">Type  =</span> <span class="kw">factor</span>(Type) ) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># categorical variables</span>
<span class="st">  </span><span class="kw">arrange</span>(Story)</code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Based on the description, a 1-sided test is appropriate. Explain why.</li>
<li>Graph the ratings for the original stories and the modified spoiler version. Comment on if you detect any difference in ratings between the two.</li>
<li>Graph the difference in ratings for each story. Comment on if the distribution of the differences seems to suggest that a spoiler lowers the rating.</li>
<li>Do a paired one-sided t-test using the asymptotic method. Also calculate a <span class="math inline">\(95\%\)</span> confidence interval.</li>
<li>Do a paired one-sided t-test using the permutation method. Also calculate a <span class="math inline">\(95\%\)</span> confidence interval using the bootstrap.</li>
<li>Based on your results in parts (d) and (e), what do you conclude?</li>
</ol></li>
<li><p>In the Lock5Data package, the dataset <code>Wetsuits</code> describes an experiment with the goal of quantifying the effect of wearing a wetsuit on the speed of swimming. (It is often debated among triathletes whether or not to wear a wetsuit when it is optional.) A set of <span class="math inline">\(n=12\)</span> swimmers and triathletes did a 1500 m swim in both the wetsuit and again in regular swimwear. The order in which they swam (wetsuit first or non-wetsuit first) was randomized for each participant. Reported is the maximum velocity during each swim.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Code for creating the &quot;long&quot; version of the data</span>
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tidyr)
<span class="kw">data</span>(<span class="st">&#39;Wetsuits&#39;</span>, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)
Wetsuits.Long &lt;-<span class="st"> </span>Wetsuits <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Participant =</span> <span class="kw">factor</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>) ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(<span class="st">&#39;Suit&#39;</span>, <span class="st">&#39;MaxVelocity&#39;</span>, Wetsuit,NoWetsuit) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>( Participant, Suit) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Suit =</span> <span class="kw">factor</span>(Suit))</code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Why did the researcher randomize which suit was worn first?</li>
<li>Plot the velocities for the wetsuit and non-wetsuit for each participant. Comment on if you detect any difference in the means of these two distributions.</li>
<li>Ignore the pairing and do a two-sided two-sample t-test using the asymptotic method. What would you conclude doing the t-test this way?</li>
<li>Plot the difference in velocity for each swimmer. Comment on if the observed difference in velocity seems to indicate that which should be preferred (wetsuit or non-wetsuit).</li>
<li>Do a paired two-sided t-test using the asymptotic method. Also calculate the 95% confidence interval. What do you conclude?</li>
<li>Do a paired two-sided t-test using the permutation method. Also calculate the 95% confidence interval using the bootstrap method. What do you conclude?</li>
</ol></li>
</ol>
<!--chapter:end:07_Two_Samples.Rmd-->
</div>
</div>
<div id="testing-model-assumptions" class="section level1">
<h1><span class="header-section-number">8</span> Testing Model Assumptions</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)

<span class="co"># Set default behavior of ggplot2 graphs to be black/white theme</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<p>Performing a t-test requires that the data was drawn from a normal distribution or that the sample size is large enough that the Central Limit Theorem will guarantee that the sample means are approximately normally distributed. However, how do you decide if the data were drawn from a normal distribution, say if your sample size is between 10 and 20? If we are using a model that assumes equal variance between groups, how should we test if that assumption is true?</p>
<div id="testing-normality" class="section level2">
<h2><span class="header-section-number">8.1</span> Testing Normality</h2>
<div id="visual-inspection---qqplots" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Visual Inspection - QQplots</h3>
<p>If we are taking a sample of size <span class="math inline">\(n=10\)</span> from a standard normal distribution, then I should expect that the smallest observation will be negative. Intuitively, you would expect the smallest observation to be near the 10th percentile of the standard normal, and likewise the second smallest should be near the 20th percentile.</p>
<p>This idea needs a little modification because the largest observation cannot be near the 100th percentile (because that is <span class="math inline">\(\infty\)</span>). So we’ll adjust the estimates to still be spaced at (1/n) quantile increments, but starting at the 0.5/n quantile instead of the 1/n quantile. So the smallest observation should be near the 0.05 quantile, the second smallest should be near the 0.15 quantile, and the largest observation should be near the 0.95 quantile. I will refer to these as the theoretical quantiles.</p>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>I can then graph the theoretical quantiles vs my observed values and if they lie on the 1-to-1 line, then my data comes from a standard normal distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">10</span>
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">observed    =</span> <span class="kw">sort</span>( <span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>) ),
                    <span class="dt">theoretical =</span> <span class="kw">qnorm</span>( (<span class="dv">1</span><span class="op">:</span>n <span class="op">-</span>.<span class="dv">5</span>)<span class="op">/</span>n, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span> ) )
<span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(data) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>( <span class="kw">aes</span>(<span class="dt">x=</span>theoretical, <span class="dt">y=</span>observed) ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(  <span class="kw">aes</span>(<span class="dt">x=</span>theoretical, <span class="dt">y=</span>theoretical) ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&#39;Theoretical&#39;</span>, <span class="dt">y=</span><span class="st">&#39;Observed&#39;</span>, <span class="dt">title=</span><span class="st">&#39;Q-Q Plot: Observed vs Normal Distribution&#39;</span>)</code></pre></div>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>If I think my data are normal, but with some mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, we still make the same graph, but the 1-to-1 line will be moved to pass through the 1st and 3rd quartiles. Again, the data points should be near the line. This is common enough that R has built in functions to make this graph:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">10</span>
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">100</span>, <span class="dt">sd=</span><span class="dv">10</span>)
<span class="kw">qqnorm</span>(x)
<span class="kw">qqline</span>(x)</code></pre></div>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We now will examine a sample of <span class="math inline">\(n=40\)</span> from a bunch of different distributions that are not normal and see what the normal QQ plot looks like. In the following graphs, pay particular attention to the tails. Notice the the t-distribution has significantly heavier tails than the normal distribution and that is reflected in the dots being lower than the line on the left and higher on the right. Likewise the logNormal distribution, which is defined by <span class="math inline">\(\log(X)\sim\)</span> Normal has too light of a tail on the left (because logNormal variables must be greater than 0) and too heavy on the right. The uniform distribution, which is cut off at 0 and 1, has too light of tails in both directions.</p>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-7-1.png" width="576" /></p>
</div>
<div id="tests-for-normality" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Tests for Normality</h3>
<p>It seems logical that there should be some sort of statistical test for if a sample is obviously non-normal. Two common ones are the Shapiro-Wilks test and the Anderson-Darling test. The Shapiro-Wilks test is available in the base installation of R with the function shapiro.test(). The Anderson-Darling test is available in the package <code>nortest</code>. Here we will not focus on the theory of these tests, but instead their use. In both tests the null hypothesis is that the data are normally distributed. <span class="math display">\[\begin{aligned}
H_{0} &amp;:\,  \textrm{data are normally distributed} \\   
H_{a} &amp;:\,  \textrm{data are not normally distributed}  
\end{aligned}\]</span> Therefore a small p-value is evidence against normality.</p>
<p>Often we want to know if our data comes from a normal distribution because our sample size is too small to rely on the Central Limit Theorem to guarantee that the sampling distribution of the sample mean is Normal. So how well do these tests detect non-normality in a small sample size case?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">meanlog=</span><span class="dv">2</span>, <span class="dt">sdlog=</span><span class="dv">2</span>)
<span class="kw">shapiro.test</span>(x)</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.39539, p-value = 2.207e-07</code></pre>
<p>So the Shapiro-Wilks test detects the non-normality in the extreme case of a logNormal distribution, but what about something closer to normal like the gamma distribution?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rgamma</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">shape=</span><span class="dv">5</span>, <span class="dt">rate=</span><span class="dv">1</span><span class="op">/</span><span class="dv">5</span>)
<span class="kw">shapiro.test</span>(x)</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.92703, p-value = 0.4193</code></pre>
<p>Here the Shapiro test fails to detect the sample has non-normality due to the small sample size. Unfortunately, the small sample-size case is exactly when we need a good test. So what do we do?</p>
<p>My advise is to look at the histograms of your data, normal QQ plots, and to use the Shapiro-Wilks test to find extreme non-normality, but recognize that in the small sample case, we have very little power and can only detect extreme departures from normality. If I cannot detect non-normality and my sample size is moderate (15-30), I won’t worry too much since the data isn’t too far from normal and the CLT will help normalize the sample means but for smaller sample sizes, I will use non-parametric methods (such as the bootstrap) that do not make distributional assumptions.</p>
</div>
</div>
<div id="testing-equal-variance" class="section level2">
<h2><span class="header-section-number">8.2</span> Testing Equal Variance</h2>
<div id="visual-inspection" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Visual Inspection</h3>
<p>Often a test procedure assumes equal variances among groups or constant variance along a prediction gradient. The most effect way of checking to see if that assumption is met is to visually inspect the data. For the case of t-tests, boxplots are an excellent visual check. If the lengths of the boxes are not substantially different, then the equal variance assumption is acceptable.</p>
<p>Consider an experiment where we measure the speed of reaction to a stimulus. The subjects are told to press a button as soon as they hear a noise. Between 2 and 30 seconds later an extremely loud noise is made. Of primary interest is how inebriation affects the reaction speed. Since we can’t surprise subjects twice, only one measurement per subject is possible and a paired test is not possible. Subjects were randomly assigned to a control or alcohol group</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Alcohol &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">time=</span><span class="kw">c</span>( <span class="fl">0.90</span>, <span class="fl">0.37</span>, <span class="fl">1.63</span>, <span class="fl">0.83</span>, <span class="fl">0.95</span>, <span class="fl">0.78</span>, <span class="fl">0.86</span>, <span class="fl">0.61</span>, <span class="fl">0.38</span>, <span class="fl">1.97</span>,
          <span class="fl">1.46</span>, <span class="fl">1.45</span>, <span class="fl">1.76</span>, <span class="fl">1.44</span>, <span class="fl">1.11</span>, <span class="fl">3.07</span>, <span class="fl">0.98</span>, <span class="fl">1.27</span>, <span class="fl">2.56</span>, <span class="fl">1.32</span> ),
  <span class="dt">trt =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&#39;control&#39;</span>,<span class="st">&#39;alcohol&#39;</span>), <span class="dt">each=</span><span class="dv">10</span>))

<span class="kw">ggplot</span>(Alcohol, <span class="kw">aes</span>(<span class="dt">x=</span>trt, <span class="dt">y=</span>time)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="tests-for-equal-variance" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Tests for Equal Variance</h3>
<p>Consider having samples drawn from normal distributions <span class="math display">\[X_{ij}=\mu_{i}+\epsilon_{ij}\;\;\;\;\;\;\textrm{where}\;\epsilon_{ij}\sim N\left(0,\,\sigma_{i}^{2}\right)\]</span> where the <span class="math inline">\(i\)</span> subscript denotes which population the observation was drawn from and the <span class="math inline">\(j\)</span> subscript denotes the individual observation and from the <span class="math inline">\(i\)</span>th population we observe <span class="math inline">\(n_i\)</span> samples. In general I might be interested in evaluating if <span class="math inline">\(\sigma_i^2=\sigma_j^2\)</span>.</p>
<p>Let’s consider the simplest case of two populations and consider the null and alternative hypotheses: <span class="math display">\[\begin{aligned}
H_{0} &amp;:\,\sigma_{1}^{2}    =   \sigma_{2}^{2} \\
H_{a} &amp;:\,\sigma_{1}^{2}    \ne \sigma_{2}^{2}
\end{aligned}\]</span> If the null hypothesis is true, then the ratio <span class="math inline">\(s_{1}^{2}/s_{2}^{2}\)</span> should be approximately one. It can be shown that under the null hypothesis, <span class="math display">\[f=\frac{s_{1}^{2}}{s_{2}^{2}}\sim F_{df_{1},df_{2}}\]</span> where <span class="math inline">\(df_{1}\)</span> and <span class="math inline">\(df_{2}\)</span> are the associated degrees of freedom for <span class="math inline">\(s_{1}^{2}\)</span> and <span class="math inline">\(s_{2}^{2}\)</span>. The order of these is traditionally given with the degrees of freedom of the top term first and the degrees of freedom of the bottom term second.</p>
<p>Variables that follow a F distribution must be non-negative and two F distributions are shown below. The F distribution is centered at <span class="math inline">\(E\left(F_{df_{1},df_{2}}\right)=\frac{df_{2}}{df_{2}-2}\approx 1\)</span> for large values of <span class="math inline">\(df_{2}\)</span>. The variance of this distribution goes to 0 as <span class="math inline">\(df_{1}\)</span> and <span class="math inline">\(df_{2}\)</span> get large.</p>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>If the value of my test statistic <span class="math inline">\(f=s_{1}^{2}/s_{2}^{2}\)</span> is too large or too small, then we will reject the null hypothesis. If we preform an F-test with an <span class="math inline">\(\alpha=0.05\)</span> level of significance then we’ll reject <span class="math inline">\(H_{0}\)</span> if <span class="math inline">\(f&lt;F_{0.025,n_{1}-1,n_{2}-1}\)</span> or if <span class="math inline">\(f&gt;F_{0.975,n_{1}-1,n_{2}-1}\)</span>.</p>
<p><strong>Example</strong>. Suppose we have two samples drawn from normally distributed populations. The first has <span class="math inline">\(n_{1}=7\)</span> observations and a sample variance of <span class="math inline">\(s_{1}^{2}=25\)</span> and the second sample has <span class="math inline">\(n_{2}=10\)</span> and <span class="math inline">\(s_{2}^{2}=64\)</span>. Then <span class="math inline">\(f_{6,9}=\frac{25}{64}=0.391\)</span> and we notice this value is is in between the lower and upper cut-off values</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qf</span>( <span class="kw">c</span>(<span class="fl">0.025</span>, .<span class="dv">975</span>), <span class="dv">6</span>, <span class="dv">9</span>)</code></pre></div>
<pre><code>## [1] 0.1810477 4.3197218</code></pre>
<p>so we will fail to reject the null hypothesis. Just for good measure, we can calculate the p-value as <span class="math display">\[\begin{aligned}p-value    
  &amp;=    2\cdot P(F_{n_{1}-1,n_{2}-1}&lt;0.391) \\
    &amp;=  2\cdot P\left(F_{6,9}&lt;0.391\right)
\end{aligned}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pf</span>(<span class="fl">0.391</span>, <span class="dv">6</span>, <span class="dv">9</span>)</code></pre></div>
<pre><code>## [1] 0.2654714</code></pre>
<p>We calculate the p-value by finding the area to the left and multiplying by two because my test statistic was less than 1 (the expected value of f if <span class="math inline">\(H_{0}\)</span> is true). If my test statistic was greater than 1, we would have found the area to the right of <span class="math inline">\(f\)</span> and multiplied by two.</p>
</div>
<div id="symmetry-of-the-f-distribution" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Symmetry of the F-distribution</h3>
<p>When testing <span class="math display">\[\begin{aligned}
H_{0} &amp;:        \sigma_{1}^{2}=\sigma_{2}^{2}    \\
H_{a} &amp;:        \sigma_{1}^{2}\ne\sigma_{2}^{2}
\end{aligned}\]</span></p>
<p>The labeling of group <span class="math inline">\(1\)</span> and group <span class="math inline">\(2\)</span> is completely arbitrary and I should view <span class="math inline">\(f=s_{1}^{2}/s_{2}^{2}\)</span> as the same evidence against null as <span class="math inline">\(f^{*}=s_{2}^{2}/s_{1}^{2}\)</span>. Therefore we have <span class="math display">\[
P\left(F_{df_{1},\,df_{2}}&gt;\frac{s_{1}^{2}}{s_{2}^{2}}\right)=P\left(F_{df_{2},\,df_{1}}&lt;\frac{s_{2}^{2}}{s_{1}^{2}}\right)
\]</span> For example, suppose that <span class="math inline">\(n_{1}=5\)</span> and <span class="math inline">\(n_{2}=20\)</span> and <span class="math inline">\(s_{1}^{2}=6\)</span> and <span class="math inline">\(s_{2}^{2}=3\)</span> then <span class="math display">\[P\left(F_{4,\,19}&gt;\frac{6}{3}\right)=P\left(F_{19,\,4}&lt;\frac{3}{6}\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(<span class="dv">6</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">19</span>)</code></pre></div>
<pre><code>## [1] 0.1354182</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="dv">3</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">19</span>, <span class="dv">4</span>)</code></pre></div>
<pre><code>## [1] 0.1354182</code></pre>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
</div>
<div id="power-of-the-f-test" class="section level2">
<h2><span class="header-section-number">8.3</span> Power of the F-test</h2>
<p>We now turn to the question of how well does this test work? To find out we’ll take samples from normal distributions with different variances and apply our F-test to see how sensitive the test is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">535</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigma1 &lt;-<span class="st"> </span><span class="dv">1</span>
sigma2 &lt;-<span class="st"> </span><span class="dv">2</span>
n1 &lt;-<span class="st"> </span><span class="dv">10</span>
n2 &lt;-<span class="st"> </span><span class="dv">10</span>
v1 &lt;-<span class="st"> </span><span class="kw">var</span>(<span class="kw">rnorm</span>(n1, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>sigma1))
v2 &lt;-<span class="st"> </span><span class="kw">var</span>(<span class="kw">rnorm</span>(n2, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>sigma2))
f &lt;-<span class="st"> </span>v1<span class="op">/</span>v2
<span class="cf">if</span>( f <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span> ){
  p.value &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st">      </span><span class="kw">pf</span>( f, <span class="dt">df1 =</span> n1<span class="op">-</span><span class="dv">1</span>, <span class="dt">df2 =</span> n2<span class="op">-</span><span class="dv">1</span> )
}<span class="cf">else</span>{
  p.value &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>( f, <span class="dt">df1 =</span> n1<span class="op">-</span><span class="dv">1</span>, <span class="dt">df2 =</span> n2<span class="op">-</span><span class="dv">1</span>))
}
p.value</code></pre></div>
<pre><code>## [1] 0.1142902</code></pre>
<p>So even though the standard deviation in the second sample was twice as large as the first, we were unable to detect it do to the small sample sizes. What happens when we take a larger sample size?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigma1 &lt;-<span class="st"> </span><span class="dv">1</span>
sigma2 &lt;-<span class="st"> </span><span class="dv">2</span>
n1 &lt;-<span class="st"> </span><span class="dv">30</span>
n2 &lt;-<span class="st"> </span><span class="dv">30</span>
v1 &lt;-<span class="st"> </span><span class="kw">var</span>(<span class="kw">rnorm</span>(n1, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>sigma1))
v2 &lt;-<span class="st"> </span><span class="kw">var</span>(<span class="kw">rnorm</span>(n2, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>sigma2))
f &lt;-<span class="st"> </span>v1<span class="op">/</span>v2
<span class="cf">if</span>( f <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span> ){
  p.value &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st">      </span><span class="kw">pf</span>( f, <span class="dt">df1 =</span> n1<span class="op">-</span><span class="dv">1</span>, <span class="dt">df2 =</span> n2<span class="op">-</span><span class="dv">1</span> )
}<span class="cf">else</span>{
  p.value &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>( f, <span class="dt">df1 =</span> n1<span class="op">-</span><span class="dv">1</span>, <span class="dt">df2 =</span> n2<span class="op">-</span><span class="dv">1</span>))
}
p.value</code></pre></div>
<pre><code>## [1] 4.276443e-06</code></pre>
<p>What this tells us is that just like every other statistical test, <em>sample size effects the power of the test</em>. In small sample situations, you cannot rely on a statistical test to tell you if your samples have unequal variance. Instead you need to think about if the assumption is scientifically valid or if you can use a test that does not rely on the equal variance assumption.</p>
</div>
<div id="theoretical-distribution-vs-bootstrap" class="section level2">
<h2><span class="header-section-number">8.4</span> Theoretical distribution vs bootstrap</h2>
<p>Returning to the research example with the alcohol and control group, an F-test for different variances results in a p-value of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculating everything by hand</span>
F &lt;-<span class="st"> </span>Alcohol <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(trt) <span class="op">%&gt;%</span><span class="st">                </span><span class="co"># for each trt group,</span>
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">s2 =</span> <span class="kw">var</span>(time)) <span class="op">%&gt;%</span><span class="st">   </span><span class="co"># calculate variance.</span>
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">F =</span> s2[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>s2[<span class="dv">2</span>] )   <span class="co"># and then take the ratio</span>
F</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##       F
##   &lt;dbl&gt;
## 1  1.70</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obs.F &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( F )           <span class="co"># Convert 1-by-1 data frame to simple number</span>
pvalue &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pf</span>( obs.F, <span class="dv">9</span>,<span class="dv">9</span> ))
pvalue</code></pre></div>
<pre><code>## [1] 0.4390223</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Using Rs built in function</span>
<span class="kw">var.test</span>( time <span class="op">~</span><span class="st"> </span>trt, <span class="dt">data=</span>Alcohol )</code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  time by trt
## F = 1.7048, num df = 9, denom df = 9, p-value = 0.439
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.4234365 6.8633246
## sample estimates:
## ratio of variances 
##           1.704753</code></pre>
<p>We can wonder how well the theoretical estimate of the sampling distribution (F_{9,9}) compares to the simulation based estimate of the sampling distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Permutation distribution of Observed F-statistic assuming H0 is true. </span>
PermDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span><span class="kw">var.test</span>(time <span class="op">~</span><span class="st"> </span>mosaic<span class="op">::</span><span class="kw">shuffle</span>(trt), <span class="dt">data=</span>Alcohol)<span class="op">$</span>statistic

<span class="co"># Figure which parts of the distribution are more extreme than my observed F </span>
PermDist &lt;-<span class="st"> </span>PermDist <span class="op">%&gt;%</span><span class="st">   </span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">extreme =</span> F <span class="op">&gt;</span><span class="st"> </span>obs.F <span class="op">|</span><span class="st"> </span>F <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>obs.F )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a histogram of the permutation distribution along with the theoretical</span>
<span class="kw">ggplot</span>(PermDist, <span class="kw">aes</span>(<span class="dt">x=</span>F, <span class="dt">y=</span>..density..)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">25</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>( <span class="dt">data=</span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dt">length=</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span>
<span class="st">                             </span><span class="kw">mutate</span>(<span class="dt">y=</span><span class="kw">df</span>(x, <span class="dv">9</span>,<span class="dv">9</span>)),
             <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y), <span class="dt">alpha=</span>.<span class="dv">3</span>, <span class="dt">fill=</span><span class="st">&#39;red&#39;</span>)</code></pre></div>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value... what percent is more extreme than what I observed?</span>
PermDist <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">p.value =</span> <span class="kw">mean</span>(extreme))</code></pre></div>
<pre><code>##   p.value
## 1  0.6141</code></pre>
<p>The theoretical sampling distribution is more concentrated near 1 than the simulation estimate. As a result, the p-value is a bit larger, but in both cases, we cannot reject equal variances.</p>
<p><strong>Example</strong>: Lets consider a case where we have two groups of moderate sample sizes where there is a difference in variance. Suppose we consider the set of times in takes me to bike to work in the morning versus biking home. On the way to work, I get to go down Beaver street, but on the way home there is a lot of elevation gain. Also surprisingly often on the way home I run into other cyclists I know and we stop and chat or we end up riding some place neither of us has to go.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Commute &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">time =</span> <span class="kw">c</span>(<span class="fl">21.0</span>, <span class="fl">22.1</span>, <span class="fl">19.3</span>, <span class="fl">22.4</span>, <span class="fl">19.6</span>, <span class="fl">19.8</span>,
           <span class="fl">19.6</span>, <span class="fl">20.4</span>, <span class="fl">21.1</span>, <span class="fl">19.7</span>, <span class="fl">19.9</span>, <span class="fl">20.0</span>,
           <span class="fl">25.0</span>, <span class="fl">27.8</span>, <span class="fl">25.2</span>, <span class="fl">25.1</span>, <span class="fl">25.4</span>, <span class="fl">25.9</span>,
           <span class="fl">30.3</span>, <span class="fl">29.5</span>, <span class="fl">25.1</span>, <span class="fl">26.4</span>, <span class="fl">24.4</span>, <span class="fl">27.7</span>,
           <span class="fl">25.8</span>, <span class="fl">27.1</span>),
  <span class="dt">type =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;Morning&#39;</span>,<span class="dv">12</span>), <span class="kw">rep</span>(<span class="st">&#39;Evening&#39;</span>,<span class="dv">14</span>)))

<span class="kw">ggplot</span>(Commute, <span class="kw">aes</span>(<span class="dt">x=</span>type, <span class="dt">y=</span>time)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&#39;Commute Times&#39;</span>, <span class="dt">y=</span><span class="st">&#39;Time (minutes)&#39;</span>, <span class="dt">x=</span><span class="st">&#39;Time of Day&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>We now test to see if there is a significant difference between the variances of these two groups. If we feel comfortable with assuming that these data come from normal distributions, then the theoretical method is appropriate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var.test</span>( time <span class="op">~</span><span class="st"> </span>type, <span class="dt">data=</span>Commute )</code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  time by type
## F = 3.039, num df = 13, denom df = 11, p-value = 0.07301
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.8959971 9.7171219
## sample estimates:
## ratio of variances 
##           3.038978</code></pre>
<p>But if we are uncomfortable with the normality assumption (the Shapiro-Wilks test indicates moderate evidence to reject normality for both samples due to the positive skew in both) we could compare our observed F-statistic to the simulation based estimate of the sampling distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># obs.F = 3.04</span>
obs.F &lt;-<span class="st"> </span><span class="kw">var.test</span>(time <span class="op">~</span><span class="st"> </span>type, <span class="dt">data=</span>Commute)<span class="op">$</span>statistic

<span class="co"># create the permutation distribution of F-values </span>
PermDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span><span class="kw">var.test</span>(time <span class="op">~</span><span class="st"> </span>mosaic<span class="op">::</span><span class="kw">shuffle</span>(type), <span class="dt">data=</span>Commute)<span class="op">$</span>statistic

<span class="co"># Figure which parts of the distribution are more extreme than my observed F </span>
PermDist &lt;-<span class="st"> </span>PermDist <span class="op">%&gt;%</span><span class="st">   </span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">extreme =</span> F <span class="op">&gt;</span><span class="st"> </span>obs.F <span class="op">|</span><span class="st"> </span>F <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>obs.F )  <span class="co"># F &gt; 3.04 or F &lt; 1/3.04</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a histogram of the permutation distribution and theoretical</span>
<span class="kw">ggplot</span>(PermDist, <span class="kw">aes</span>(<span class="dt">x=</span>F, <span class="dt">y=</span>..density..)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth=</span>.<span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>( <span class="dt">data=</span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dt">length=</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span>
<span class="st">                             </span><span class="kw">mutate</span>(<span class="dt">y=</span><span class="kw">df</span>(x, <span class="dv">13</span>, <span class="dv">11</span>)),
             <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y), <span class="dt">alpha=</span>.<span class="dv">3</span>, <span class="dt">fill=</span><span class="st">&#39;red&#39;</span>)</code></pre></div>
<p><img src="08_TestingAssumptions_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value... what proportion is more extreme than what I observed?</span>
PermDist <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">p.value =</span> <span class="kw">mean</span>(extreme))</code></pre></div>
<pre><code>##   p.value
## 1  0.0019</code></pre>
<p>We again see that with this small of a data set, our simulation based p-value is different from the theoretical based p-value. This is primarily due to the non-normality of our data along with the small sample sizes. In general as our sample sizes increase the simulation based and theoretical based distributions should give similar inference and p-values.</p>
</div>
<div id="exercises-7" class="section level2">
<h2><span class="header-section-number">8.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>To find the probabilities for the F-distribution, we will use the function <code>pf(f, df1, df2)</code> where the <code>f</code> is the value for which we want to find the probability of finding a value less than. That is <span class="math display">\[P\left(F_{2,10}&lt;4.2\right)=\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="fl">4.2</span>, <span class="dt">df1=</span><span class="dv">2</span>, <span class="dt">df2=</span><span class="dv">10</span>) </code></pre></div>
<pre><code>## [1] 0.9525855</code></pre>
<ol style="list-style-type: lower-alpha">
<li>Using the probability function for the F-distribution in R, find the following probabilities:
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(P\left(F_{5,5}&lt;\frac{1}{2}\right)\)</span></li>
<li><span class="math inline">\(P\left(F_{5,5}&gt;\frac{2}{1}\right)\)</span></li>
<li><span class="math inline">\(P\left(F_{4,10}&gt;\frac{6}{1}\right)\)</span></li>
<li><span class="math inline">\(P\left(F_{10,4}&lt;\frac{1}{6}\right)\)</span></li>
</ol></li>
<li>From what you calculated in part (a), comment on the reciprocal symmetry of the F-distribution.</li>
</ol></li>
<li>In this exercise we will examine the variability of samples from various distributions and how easily departures from normality are detected using qqplots and the Shapiro-Wilks test. Under no circumstances should you turn in page after page of output or graphs. Produce a table that summarizes how often the test rejects the null hypotheses and include at most one figure of QQ-plots. To receive credit, you must comment on the table and graph and describe what you observe and why you observed what you did.
<ol style="list-style-type: lower-alpha">
<li><p>The following code will create a random sample from a normal distribution and draw the qqplot. Also notice the results of the Shapiro-Wilks test. Investigate the behavior of repeated samples (ie run this code at least 10 times). Repeat with increased sample sizes (do this for n=5,25,100,400). Describe your results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)) <span class="co"># 1 row of 2 graphs, side-by-side</span>
n &lt;-<span class="st"> </span><span class="dv">5</span>                       <span class="co"># sample size is 5</span>
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">25</span>, <span class="dt">sd=</span><span class="dv">5</span>) <span class="co"># draw random sample from a normal distribution</span>
<span class="kw">hist</span>(x)                      <span class="co"># histogram</span>
<span class="kw">qqnorm</span>(x)                    <span class="co"># qqplot for normality</span>
<span class="kw">qqline</span>(x)                    <span class="co"># add a line to the above plot</span>
<span class="kw">shapiro.test</span>(x)              <span class="co"># do the test for normality</span></code></pre></div></li>
<li><p>Repeat problem (a) but consider samples drawn from a distribution that is not normal, in this case, the gamma distribution with parameters <code>shape=3</code>, and <code>rate=2</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)) <span class="co"># 1 row of 2 graphs, side-by-side</span>
n &lt;-<span class="st"> </span><span class="dv">5</span>                          <span class="co"># sample size is 5</span>
x &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n, <span class="dt">shape=</span><span class="dv">3</span>, <span class="dt">rate=</span><span class="dv">2</span>) <span class="co"># draw random sample from a gamma distribution</span>
<span class="kw">hist</span>(x)                         <span class="co"># histogram</span>
<span class="kw">qqnorm</span>(x)                       <span class="co"># qqplot for normality</span>
<span class="kw">qqline</span>(x)                       <span class="co"># add a line to the above plot</span>
<span class="kw">shapiro.test</span>(x)                 <span class="co"># do the test for normality</span></code></pre></div></li>
</ol></li>
<li><p>In this exercise, we will examine the variability of samples from a normal distribution. The following code will generate random samples from a normal distribution, create boxplots, and perform an F-test for equal variance. Run the code many times (again 20 or more times) and investigate the effects of changing your sample size and the mean and standard deviation of each group. <em>Under no circumstances should you turn in page after page of output or graphs. For each question produce a table that summarizes how often the test rejects the null hypotheses and include at most one figure of boxplots. To receive credit, you must comment on the table and graph and describe what you observe and why you observed what you did.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co"># 1 row of 1: Just one graph</span>
n &lt;-<span class="st"> </span><span class="dv">5</span> 
sigma &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)   <span class="co"># Standard deviations of each group</span>
my.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">rnorm</span>( n, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>sigma[<span class="dv">1</span>] ),
                            <span class="kw">rnorm</span>( n, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>sigma[<span class="dv">2</span>] )),
                      <span class="dt">group =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;g1&#39;</span>,n), <span class="kw">rep</span>(<span class="st">&#39;g2&#39;</span>,n)  ))
<span class="kw">boxplot</span>(y <span class="op">~</span><span class="st"> </span>group, <span class="dt">data=</span>my.data) 
<span class="kw">var.test</span>(y <span class="op">~</span><span class="st"> </span>group, <span class="dt">data=</span>my.data)</code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>How often does the F-test reject (at <span class="math inline">\(\alpha=0.05\)</span> level) equal variance when the variances of the two groups are equal? (Run the above code 20 or more times.) Does this appear to change as the sample size gets larger?</li>
<li>How often does the F-test reject (at <span class="math inline">\(\alpha=0.05\)</span> level) equal variance when the variances are different, say <span class="math inline">\(\sigma_{1}=2\)</span> and <span class="math inline">\(\sigma_{2}=4\)</span>? <em>(Run your code many times!)</em></li>
<li>Is it surprising to you how much variability there is in the widths of the boxplots when the data are generated having the same standard deviation? With both groups having the same standard deviation, investigate the variability in boxplot widths as <span class="math inline">\(n\)</span> is <span class="math inline">\(5,20\)</span>, and <span class="math inline">\(50\)</span>.</li>
</ol></li>
<li><p>We are interested in testing if the variance is equal among two populations that are known to be normal. A sample of size <span class="math inline">\(n_{1}=15\)</span> from the first population resulted in a sample mean and standard deviation of <span class="math inline">\(\bar{x}_{1}=52\)</span> and <span class="math inline">\(s_{1}=7\)</span> while the sample of size <span class="math inline">\(n_{2}=20\)</span> from the second population had a sample mean and standard deviation of <span class="math inline">\(\bar{x}_{2}=42\)</span> and <span class="math inline">\(s_{2}=4\)</span>. Perform an F-test with <span class="math inline">\(\alpha=0.05\)</span> to test if the variances are different. <em>Because the data is not given, all calculations must be done by-hand, except the usual probability look up.</em></p></li>
<li><p>The life span of an electrical component was studied under two operating voltages (110 and 220). Ten components were randomly assigned to operate at 110 volts and 16 were assigned to 220 volts. The time to failure (in hundreds of hours) for the 26 components were obtained:</p>
<table>
<tbody>
<tr class="odd">
<td align="center"><strong>110</strong></td>
<td align="center"></td>
<td align="center">19.25</td>
<td align="center">19.7</td>
<td align="center">19.75</td>
<td align="center">19.9</td>
<td align="center">19.95</td>
<td align="center">20.05</td>
<td align="center">20.13</td>
<td align="center">20.2</td>
<td align="center">20.4</td>
<td align="center">20.6</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"><strong>220</strong></td>
<td align="center"></td>
<td align="center">9.7</td>
<td align="center">9.75</td>
<td align="center">9.8</td>
<td align="center">9.82</td>
<td align="center">9.85</td>
<td align="center">9.90</td>
<td align="center">9.92</td>
<td align="center">9.96</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"></td>
<td align="center">10.01</td>
<td align="center">10.02</td>
<td align="center">10.10</td>
<td align="center">10.11</td>
<td align="center">10.13</td>
<td align="center">10.19</td>
<td align="center">10.28</td>
<td align="center">10.31</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>Calculate the mean and variance of each sample group</li>
<li>Test the assumption that the data in each group is normally distributed.
<ol style="list-style-type: lower-roman">
<li>Create the QQplots first and comment on their fit.</li>
<li>Perform the Shapiro-Wilks test to assess normality.</li>
</ol></li>
<li>Test the assumption that the variances in each group are equal
<ol style="list-style-type: lower-roman">
<li>By hand, perform a two-side hypothesis test that variances in each group are equal. <em>Here, “by hand” means to calculate the f-statistic by hand and then form the probability statement that defines the p-value. Then use the pf() function to calculate the actual p-value.</em></li>
<li>Using the R function <code>var.test()</code> confirm your calculations in part (ii).</li>
</ol></li>
</ol></li>
</ol>
<!--chapter:end:08_TestingAssumptions.Rmd-->
</div>
</div>
<div id="analysis-of-variance-anova" class="section level1">
<h1><span class="header-section-number">9</span> Analysis of Variance (ANOVA)</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(ggfortify)  <span class="co"># for autoplot( lm ) functions</span></code></pre></div>
<p>We are now moving into a different realm of statistics. We have covered enough probability and the basic ideas of hypothesis tests and p-values to move onto the type of inference that you took this class to learn. The heart of science is comparing and evaluating which hypothesis is better supported by the data.</p>
<p>To evaluate a hypothesis, scientists will write a grant, hire grad students (or under-grads), collect the data, and then analyze the data using some sort of model that reflects the hypothesis under consideration. It could be as simple as “What is the relationship between iris species and petal width?” or as complex as “What is the temporal variation in growing season length in response to elevated CO<span class="math inline">\(_{2}\)</span> in desert ecosystems?”</p>
<p>At the heart of the question is which predictors should be included in my model of the response variable. Given twenty different predictors, I want to pare them down to just the predictors that matter. I want to make my model as simple as possible, but still retain as much explanatory power as I can.</p>
<p>Our attention now turns to building models of our observed data in a fashion that allows us to ask if a predictor is useful in the model or if we can remove it. Our model building procedure will be consistent:</p>
<ol style="list-style-type: decimal">
<li>Write two models, one that is perhaps overly simple and another that is a complication of the simple model.</li>
<li>Verify that the assumptions that are made in both models are satisfied.</li>
<li>Evaluate if the complex model explains significantly more of the variability in the data than the simple model.</li>
</ol>
<p>Our goal here isn’t to find “the right model” because no model is right. Instead our goal is to find a model that is useful and helps me to understand the science.</p>
<p>We will start by developing a test that helps me evaluate if a model that has a categorical predictor variable for a continuous response should have a mean value for each group or just one overall mean.</p>
<div id="model" class="section level2">
<h2><span class="header-section-number">9.1</span> Model</h2>
<p>The two-sample t-test provided a convenient way to compare the means from two different populations and test if they were equal. We wish to generalize this test to more than two different populations. Later when we have more tools in our statistical tool box, it is useful to notice that ANOVA uses a categorical variable (which group) to predict a continuous response.</p>
<p>Suppose that my data can be written as <span class="math display">\[Y_{ij}=\mu_{i}+\epsilon_{ij}\;\;\;\;\;\textrm{where}\;\;\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\,\sigma\right)\]</span> and <span class="math inline">\(\mu_{i}\)</span> is the mean of group <span class="math inline">\(i\)</span> and <span class="math inline">\(\epsilon_{ij}\)</span> are the deviations from the group means. Let the first subscript denote which group the observation is from <span class="math inline">\(i\in\{1,\dots k\}\)</span> and the second subscript is the observation number within that sample. Each group has its own mean <span class="math inline">\(\mu_{i}\)</span> and we might allow the number of observations in each group <span class="math inline">\(n_{i}\)</span> to be of different across the populations.</p>
<p><em>Assumptions</em>: 1. The error terms come from a normal distribution 2. The variance of each group is the same 3. The observations are independent 4. The observations are representative of the population of interest</p>
<p>In general I want to test the hypotheses <span class="math display">\[\begin{aligned}
H_{0} &amp;:        \mu_{1}=\mu_{2}=\dots=\mu_{k} \\
H_{a} &amp;:        \textrm{at least on mean is different than the others}
\end{aligned}\]</span></p>
<p><strong>Example 1</strong>. Suppose that we have three hybrids of a particular plant and we measure the leaf area for each hybrid.</p>
<p>In the following graph, there does not appear to be a difference between the hybrid means:</p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>However, in this case, it looks like there is a difference in the means of each hybrid:</p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>What is the difference between these two?</p>
<ol style="list-style-type: decimal">
<li><p>If the variance between hybrids is small compared the variance within a hybrid variance is huge compared, then I would fail to reject the null hypothesis of equal means (this would be the first case). In this case, the additional model complexity doesn’t result in more accurate model, so Occam’s Razor would lead us to prefer the simpler model where each group has the same mean.</p></li>
<li><p>If there is a large variance between hybrids compared to the variance within a hybrid then I’d conclude there is a difference (this would be the second case). In this case, I prefer the more complicated model with each group having separate means.</p></li>
</ol>
</div>
<div id="theory" class="section level2">
<h2><span class="header-section-number">9.2</span> Theory</h2>
<p>Notation:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(n=n_{1}+n_{2}+\dots+n_{k}\)</span> as the total number of observations</li>
<li><span class="math inline">\(\bar{y}_{i\cdot}=\frac{1}{n_{i}}\sum_{j=1}^{n_{i}}y_{ij}\)</span> as the sample mean from the <span class="math inline">\(i\)</span>th group</li>
<li><span class="math inline">\(\bar{y}_{\cdot\cdot}\)</span> be the mean of all the observations.</li>
</ol>
<p>Regardless of if the null hypothesis is true, the following is an estimate of <span class="math inline">\(\sigma^{2}\)</span>. We could use a pooled variance estimate similar to the estimator in the pooled two-sample t-test. We will denote this first estimator as the within-group estimate because the sums in the numerator are all measuring the variability within a group. <span class="math display">\[\begin{aligned} s_{W}^{2} 
  &amp;=    \frac{\sum_{i=1}^{k}\sum_{j=1}^{n_{k}}\left(y_{ij}-\bar{y}_{i\cdot}\right)^{2}}{n-k} \\
    &amp;=  \frac{\sum_{j=1}^{n_{1}}\left(y_{1j}-\bar{y}_{1\cdot}\right)^{2}+\sum_{j=1}^{n_{2}}\left(y_{2j}-\bar{y}_{2\cdot}\right)^{2}+\dots+\sum_{j=1}^{n_{k}}\left(y_{kj}-\bar{y}_{k\cdot}\right)^{2}}{\left(n_{1}-1\right)+\left(n_{2}-1\right)+\dots+\left(n_{k}-1\right)} \\
    &amp;=  \frac{\left(n_{1}-1\right)s_{1}^{2}+\left(n_{2}-1\right)s_{2}^{2}+\dots+\left(n_{k}-1\right)s_{k}^{2}}{n-k}
    \end{aligned}\]</span></p>
<p>If the null hypothesis is true and <span class="math inline">\(\mu_{1}=\dots=\mu_{k}\)</span>, then a second way that I could estimate the <span class="math inline">\(\sigma^{2}\)</span> term is using the sample means. If <span class="math inline">\(H_{0}\)</span> is true then each sample mean has sampling distribution <span class="math inline">\(\bar{Y}_{i\cdot}\sim N\left(\mu,\frac{\sigma^{2}}{n_{i}}\right)\)</span>. In the simple case where <span class="math inline">\(n_{1}=n_{2}=\dots=n_{k}\)</span> then the sample variance of the <span class="math inline">\(k\)</span> sample means <span class="math inline">\(\bar{y}_{1},\bar{y}_{2},\dots,\bar{y}_{k}\)</span> has expectation <span class="math inline">\(\sigma^{2}/n_{i}\)</span> and could be used to estimate <span class="math inline">\(\sigma^{2}\)</span>. In the case of unequal sample sizes, the formula will be slightly different.</p>
<p><span class="math display">\[s_{B}^{2}=\frac{1}{k-1}\sum_{i=1}^{k}n_{i}\left(\bar{y}_{i\cdot}-\bar{y}_{\cdot\cdot}\right)^{2}\]</span></p>
<p>Under the null hypothesis, these two estimates are both estimating <span class="math inline">\(\sigma^{2}\)</span> and should be similar and the ratio <span class="math inline">\(s_{B}^{2}/s_{W}^{2}\)</span> follows an F-distribution with numerator degrees of freedom <span class="math inline">\(k-1\)</span> and denominator degrees of freedom <span class="math inline">\(n-k\)</span> degrees of freedom. We define our test statistic as <span class="math display">\[f=\frac{s_{B}^{2}}{s_{W}^{2}}\]</span></p>
<p>In the case that the null hypothesis is false (non-equal means <span class="math inline">\(\mu_{1},\mu_{2},\dots,\mu_{k}\)</span>), <span class="math inline">\(s_{B}^{2}\)</span> should be much larger than <span class="math inline">\(s_{W}^{2}\)</span> and our test statistic <span class="math inline">\(f\)</span> will be very large and so we will reject the null hypothesis if <span class="math inline">\(f\)</span> is greater than the <span class="math inline">\(1-\alpha\)</span> quantile from the F-distribution with <span class="math inline">\(k-1\)</span> and <span class="math inline">\(n-k\)</span> degrees of freedom. If <span class="math inline">\(s_{B}^{2}\)</span> is small, then the difference between the group means and the overall means is small and we shouldn’t reject the null hypothesis. So this F-test will always be a one sided test, rejecting only if f is large. <span class="math display">\[\textrm{p-value}=P\left(F_{k-1,\,n_{t}-k}&gt;f\right)\]</span></p>
<div id="anova-table" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Anova Table</h3>
<p>There are several sources of variability that we are dealing with.</p>
<p><strong>SSW</strong>: Sum of Squares Within - This is the variability within sample groups. <span class="math display">\[SSW=\sum_{i=1}^{k}\sum_{j=1}^{n_{i}}\left(y_{ij}-\bar{y}_{i\cdot}\right)^{2}\;\;\;\;\;\;\;\;df_{W}=n-k\]</span></p>
<p><strong>SSB</strong>: Sum of Squares Between - This is the variability between sample groups. <span class="math display">\[SSB=\sum_{i=1}^{k}n_{i}\left(\bar{y}_{i\cdot}-\bar{y}_{\cdot\cdot}\right)^{2} \;\;\;\;\;\;\;\;\;df_{B}=k-1\]</span></p>
<p>SST: Sum of Squares Total - This is the total variability in the data set. It has an associated df=n-1 because under the null hypothesis there is only one mean <span class="math inline">\(\mu\)</span>. <span class="math display">\[SST=\sum_{i=1}^{k}\sum_{j=1}^{n_{j}}\left(y_{ij}-\bar{y}_{\cdot\cdot}\right)^{2} \;\;\;\;\;\;\;\;\;df_{T}=n-1\]</span></p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>An anova table is usually set up the in the following way (although the total row is sometimes removed):</p>
<table>
<thead>
<tr class="header">
<th align="center">Source</th>
<th align="center">df</th>
<th align="center">Sum of Sq.</th>
<th align="center">Mean Sq.</th>
<th align="center">F-Stat</th>
<th align="left">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Between</td>
<td align="center"><span class="math inline">\(k-1\)</span></td>
<td align="center"><span class="math inline">\(SSB\)</span></td>
<td align="center"><span class="math inline">\(s^2_B=SSB/df_B\)</span></td>
<td align="center"><span class="math inline">\(f=s^2_B/s^2_W\)</span></td>
<td align="left"><span class="math inline">\(P(F_{k-1,n-k}\ge f)\)</span></td>
</tr>
<tr class="even">
<td align="center">Within</td>
<td align="center"><span class="math inline">\(n-k\)</span></td>
<td align="center"><span class="math inline">\(SSW\)</span></td>
<td align="center"><span class="math inline">\(s^2_W=SSW/df_W\)</span></td>
<td align="center"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center"><span class="math inline">\(n-1\)</span></td>
<td align="center"><span class="math inline">\(SST\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>It can be shown that <span class="math inline">\(SST=SSB+SSW\)</span> and we can think about what these sums actually mean by returning to our idea about simple vs complex models.</p>
</div>
<div id="anova-using-simple-vs-complex-models." class="section level3">
<h3><span class="header-section-number">9.2.2</span> ANOVA using Simple vs Complex models.</h3>
<p>The problem under consideration can also be considered as a question about how complicated of a model should we fit to the observed data. If a more complicated model doesn’t “fit” the data better, then I am better of keeping a simple model and view of the process at hand.</p>
<p>Upon the second reading of these notes, the student is likely asking why we even bothered introducing the ANOVA table using SST, SSW, SSB. The answer is that these notations are common in the ANOVA literature and that we can’t justify using an F-test without variance estimates. Both interpretations are valid, but the Simple/Complex models are a better paradigm as we move forward.</p>
<p><strong>Simple Model</strong></p>
<p>The simple model is <span class="math display">\[Y_{ij}=\mu+\epsilon_{ij}\;\;\;\textrm{where}\;\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma^{2}\right)\]</span> and has each observation having the same expectation <span class="math inline">\(\mu\)</span>. Thus we use the overall mean of the data <span class="math inline">\(\bar{y}_{\cdot\cdot}\)</span> as the estimate of <span class="math inline">\(\mu\)</span> and therefore our error terms are <span class="math display">\[e_{ij}=y_{ij}-\bar{y}_{\cdot\cdot}\]</span> The sum of squared error associated with the simple model is thus <span class="math display">\[\begin{aligned} SSE_{simple}      
  &amp;= \sum_{i=1}^{k}\sum_{j=1}^{n_{i}}e_{ij}^{2} \\
    &amp;=  \sum_{i=1}^{k}\sum_{j=1}^{n_{i}}\left(y_{ij}-\bar{y}_{\cdot\cdot}\right)^{2} \\
    &amp;=  SST 
    \end{aligned}\]</span></p>
<p><strong>Complex Model</strong></p>
<p>The more complicated model <span class="math display">\[Y_{ij}=\mu_{i}+\epsilon_{ij}\;\;\;\textrm{where}\;\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma^{2}\right)\]</span> has each observation having the expectation of its group mean <span class="math inline">\(\mu_{i}\)</span>. We’ll use the group means <span class="math inline">\(\bar{y}_{i\cdot}\)</span> as estimates for <span class="math inline">\(\mu_{i}\)</span> and thus the error terms are <span class="math display">\[e_{ij}=y_{ij}-\bar{y}_{i\cdot}\]</span> and the sum of squared error associated with the complex model is thus <span class="math display">\[\begin{aligned} SSE_{complex} 
  &amp;=    \sum_{i=1}^{k}\sum_{j=1}^{n_{i}}e_{ij}^{2} \\
    &amp;=  \sum_{i=1}^{k}\sum_{j=1}^{n_{i}}\left(y_{ij}-\bar{y}_{i\cdot}\right)^{2} \\
    &amp;=  SSW 
    \end{aligned}\]</span></p>
<p><strong>Difference</strong></p>
<p>The difference between the simple and complex sums of squared error is denoted <span class="math inline">\(SSE_{diff}\)</span> and we see <span class="math display">\[\begin{aligned} SSE_{diff}    
  &amp;=    SSE_{simple}-SSE_{complex} \\
    &amp;=  SST-SSW \\
    &amp;=  SSB
    \end{aligned}\]</span> Note that <span class="math inline">\(SSE_{diff}\)</span> can be interpreted as the amount of variability that is explained by the more complicated model vs the simple. If this <span class="math inline">\(SSE_{diff}\)</span> is large, then we should use the complex model. Our only question becomes “How large is large?”</p>
<p>First we must account for the number of additional parameters we have added. If we added five parameters, I should expect to account for more variability that if I added one parameter, so first we will divide <span class="math inline">\(SSE_{diff}\)</span> by the number of added parameters to get <span class="math inline">\(MSE_{diff}\)</span> which is the amount of variability explained by each additional parameter. If that amount is large compared to the leftover from the complex model, then we should use the complex model.</p>
<p>These calculations are preformed in the ANOVA table, and the following table is identical to the previous ANOVA table, and we have only changed the names given to the various quantities.</p>
<table>
<colgroup>
<col width="8%" />
<col width="5%" />
<col width="12%" />
<col width="30%" />
<col width="26%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Source</th>
<th align="center">df</th>
<th align="center">Sum of Sq.</th>
<th align="center">Mean Sq.</th>
<th align="center">F-Stat</th>
<th align="left">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Difference</td>
<td align="center"><span class="math inline">\(k-1\)</span></td>
<td align="center"><span class="math inline">\(SSE_{diff}\)</span></td>
<td align="center"><span class="math inline">\(MSE_{diff}=\frac{SSE_{diff}}{k-1}\)</span></td>
<td align="center"><span class="math inline">\(f=\frac{MSE_{diff}}{MSE_{complex}}\)</span></td>
<td align="left"><span class="math inline">\(P(F_{k-1,n-k}\ge f)\)</span></td>
</tr>
<tr class="even">
<td align="center">Complex</td>
<td align="center"><span class="math inline">\(n-k\)</span></td>
<td align="center"><span class="math inline">\(SSE_{complex}\)</span></td>
<td align="center"><span class="math inline">\(MSE_{complex}=\frac{SSE_{complex}}{n-k}\)</span></td>
<td align="center"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="center">Simple</td>
<td align="center"><span class="math inline">\(n-1\)</span></td>
<td align="center"><span class="math inline">\(SSE_{simple}\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
<div id="parameter-estimates-and-confidence-intervals" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Parameter Estimates and Confidence Intervals</h3>
<p>As usual, the group sample means <span class="math inline">\(\bar{y}_{i\cdot}\)</span> is a good estimator for the mean of group <span class="math inline">\(\mu_{i}\)</span>.</p>
<p>But what about <span class="math inline">\(\sigma^{2}\)</span>? If we conclude that we should use the complex model, and because one of our assumptions is that each group has equal variance, then I should use all of the residual terms <span class="math inline">\(e_{ij}=y_{ij}-\bar{y}_{i\cdot}\)</span> in my estimation of <span class="math inline">\(\sigma\)</span>. In this case we will use <span class="math display">\[\hat{\sigma}^{2}=s_{W}^{2}=MSE_{complex}=\frac{1}{n-k}\sum_{i=1}^{k}\sum_{j=1}^{n_{i}}\left(y_{ij}-\bar{y}_{i\cdot}\right)^{2}\]</span> as the estimate of <span class="math inline">\(\sigma^{2}\)</span>. Notice that this is analogous to the pooled estimate of the variance in a two-sample t-test with the assumption of equal variance.</p>
<p>Therefore an appropriate confidence interval for <span class="math inline">\(\mu_{i}\)</span> is <span class="math display">\[\bar{y}_{i\cdot}\pm t_{\,n-k}^{1-\alpha/2}\left(\frac{\hat{\sigma}}{\sqrt{n_{i}}}\right)\]</span></p>
</div>
</div>
<div id="anova-in-r" class="section level2">
<h2><span class="header-section-number">9.3</span> Anova in R</h2>
<p>First we must define a data frame with the appropriate columns. We start with two vectors, one of which has the leaf area data and the other vector denotes the species. Our response variable must be a continuous random variable and the explanatory is a discrete variable. In R discrete variables are called <code>factors</code> and can you can change a numerical variable to be a <code>factor</code> using the function <code>factor()</code>.</p>
<p>The analysis of variance method is an example of a linear model which can be fit in a variety of ways. We can use either <code>lm()</code> or <code>aov()</code> to fit this model, and in these notes we concentrate on using <code>lm()</code>. The first argument to this function is a formula that describes the relationship between the explanatory variables and the response variable. In this case it is extremely simple, that LAI is a function of the categorical variable Species.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">LAI =</span> <span class="kw">c</span>(<span class="fl">2.88</span>, <span class="fl">2.87</span>, <span class="fl">3.23</span>, <span class="fl">3.24</span>, <span class="fl">3.33</span>, 
                           <span class="fl">3.83</span>, <span class="fl">3.86</span>, <span class="fl">4.03</span>, <span class="fl">3.87</span>, <span class="fl">4.16</span>,
                           <span class="fl">4.79</span>, <span class="fl">5.03</span>, <span class="fl">4.99</span>, <span class="fl">4.79</span>, <span class="fl">5.05</span>),
                   <span class="dt">Species =</span> <span class="kw">factor</span>( <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">each=</span><span class="dv">5</span>) ) )
<span class="kw">str</span>(data)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    15 obs. of  2 variables:
##  $ LAI    : num  2.88 2.87 3.23 3.24 3.33 3.83 3.86 4.03 3.87 4.16 ...
##  $ Species: Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 1 2 2 2 2 2 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(LAI <span class="op">~</span><span class="st"> </span>Species, <span class="dt">data=</span>data)</code></pre></div>
<p>As is always good practice, the first thing we should do is graph our data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>Species, <span class="dt">y=</span>LAI)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>It looks like the equal variance question isn’t a worry and it certainly appears that the mean value for each species is not the same. I expect that we will certainly prefer the complex model in this case.</p>
<p>The <code>lm()</code> command is the command that does all the calculations necessary to fit an ANOVA model. This command returns a list object that is useful for subsequent analysis and it is up to the use to know what subsequent functions to call that answer questions of interest.</p>
<p>In the call to <code>lm()</code> we created a formula. Formulas in R always are of the form <code>Y ~ X</code> where <code>Y</code> is the dependent variable and the <code>X</code> variables are the independent variables.</p>
<p>Before we examine the anova table and make any conclusion, we should double check that the anova assumptions have been satisfied. To check the normality assumption, we will look at the qqplot of the residuals <span class="math inline">\(e_{ij}=y_{ij}-\bar{y}_{i\cdot}\)</span>. These residuals are easily accessed in R using the <code>resid</code> function on the model object. To check the variance assumption, we will examine the boxplot of the data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>( model, <span class="dt">which=</span><span class="dv">2</span>)  <span class="co"># The which argument specifies which plot to make</span></code></pre></div>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The qqplot doesn’t look too bad, with only two observations far from the normality line. To get the Analysis of Variance table, we’ll extract it from the model object using the function <code>anova()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(model)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: LAI
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Species    2 8.2973  4.1487  147.81 3.523e-09 ***
## Residuals 12 0.3368  0.0281                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Notice that R does not give you the third line in the ANOVA table. This was a deliberate choice by the Core Development Team of R, but one that is somewhat annoying. Because the third line is just the total of the first two, it isn’t hard to calculate, if necessary.</p>
<p>The row labeled Species corresponds to the difference between the simple and complex models, while the Residuals row corresponds to the complex model. Notice that <span class="math inline">\(SSE_{diff}\)</span> is quite large, but to decide if it is large enough to justify the use of the complex model, we must go through the calculations to get the p-value, which is quite small. Because the p-value is smaller than any reasonable <span class="math inline">\(\alpha\)</span>-level, we can reject the null hypothesis and conclude that at least one of the means is different than the others.</p>
<p>But which mean is different? The first thing to do is to look at the point estimates and confidence intervals for <span class="math inline">\(\mu_{i}\)</span>. These are <span class="math display">\[\hat{\mu}_{i} =   \bar{y}_{i\cdot}\]</span> <span class="math display">\[\hat{y}_{i\cdot}\pm t_{n-k}^{1-\alpha/2}\left(\frac{\hat{\sigma}}{\sqrt{n_{i}}}\right)\]</span> and can be found using the <code>coef()</code> and <code>confint()</code> functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># To get coefficients in the way we have represented the </span>
<span class="co"># complex model (which we will call the cell means model), we </span>
<span class="co"># must add a -1 to the formula passed to lm()</span>
<span class="co"># We&#39;ll explore this later in this chapter.</span>
model.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(LAI <span class="op">~</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>data)
<span class="kw">coef</span>(model.<span class="dv">2</span>)</code></pre></div>
<pre><code>## Species1 Species2 Species3 
##     3.11     3.95     4.93</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># alternatively we could use the emmeans package</span>
<span class="co"># using either model representation </span>
emmeans<span class="op">::</span><span class="kw">emmeans</span>(model, <span class="op">~</span>Species)</code></pre></div>
<pre><code>##  Species emmean     SE df lower.CL upper.CL
##  1         3.11 0.0749 12     2.95     3.27
##  2         3.95 0.0749 12     3.79     4.11
##  3         4.93 0.0749 12     4.77     5.09
## 
## Confidence level used: 0.95</code></pre>
<p>Are the all the species different from each other? In practice I will want to examine each group and compare it to all others and figure out if they are different. How can we efficiently do all possible t-tests and keep the correct <span class="math inline">\(\alpha\)</span> level correct?</p>
</div>
<div id="multiple-comparisons" class="section level2">
<h2><span class="header-section-number">9.4</span> Multiple comparisons</h2>
<p>Recall that for every statistical test there is some probability of making a type I error and we controlled that probability by setting a desired <span class="math inline">\(\alpha\)</span>-level. If I were to do 20 t-tests of samples with identical means, I would expect, on average, that one of them would turn up to be significantly different just by chance. If I am making a large number of tests, each with a type I error rate of <span class="math inline">\(\alpha\)</span>, I am practically guaranteed to make at least one type I error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="op">-</span><span class="dv">1035</span>) <span class="co"># So that I get the same dataset each time I build the book.</span>
k &lt;-<span class="st"> </span><span class="dv">5</span> ; n &lt;-<span class="st"> </span><span class="dv">10</span> 
mydata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">mu=</span><span class="kw">rep</span>(<span class="dv">0</span>,k<span class="op">*</span>n), <span class="dt">Grp=</span><span class="kw">factor</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>k, <span class="dt">each=</span>n))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">Y=</span>mu<span class="op">+</span><span class="kw">rnorm</span>(k<span class="op">*</span>n), <span class="dt">Group=</span>Grp) 
letterdata &lt;-<span class="st"> </span><span class="kw">lm</span>( Y<span class="op">~</span>Grp, <span class="dt">data=</span>mydata ) <span class="op">%&gt;%</span>
<span class="st">  </span>emmeans<span class="op">::</span><span class="kw">emmeans</span>( <span class="op">~</span><span class="st"> </span>Grp) <span class="op">%&gt;%</span>
<span class="st">  </span>multcomp<span class="op">::</span><span class="kw">cld</span>( <span class="dt">Letters=</span>letters, <span class="dt">adjust=</span><span class="st">&#39;none&#39;</span> ) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Force no p-value adjustment</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(Grp, .group) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>( <span class="dt">Y =</span> <span class="dv">3</span> )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Visualize a made up data set: mydata</span>
<span class="kw">ggplot</span>(mydata, <span class="kw">aes</span>(<span class="dt">x=</span>Grp, <span class="dt">y=</span>Y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data=</span>letterdata, <span class="kw">aes</span>(<span class="dt">label=</span>.group)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>( <span class="kw">expression</span>(<span class="kw">paste</span>(X[ij],<span class="st">&#39; ~ N(0,1)   where &#39;</span>, n[i], <span class="st">&#39; = 10&#39;</span>)) ) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Group&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Response&#39;</span>)</code></pre></div>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>With 5 groups, there are 10 different comparisons to be made, and just by random chance, one of those comparisons might come up significant. In this sampled data, performing 10 different two sample t-tests without making any adjustments to our <span class="math inline">\(\alpha\)</span>-level, we find one statistically significant difference even though all of the data came from a standard normal distribution.</p>
<p>I want to be able to control the family-wise error rate so that the probability that I make one or more type I errors in the set of m of tests I’m considering is <span class="math inline">\(\alpha\)</span>. One general way to do this is called the Bonferroni method. In this method each test is performed using a significance level of <span class="math inline">\(\alpha/m\)</span>. (In practice I will multiple each p-value by m and compare each p-value to my desired family-wise <span class="math inline">\(\alpha\)</span>-level). Unfortunately for large <span class="math inline">\(m\)</span>, this results in unacceptably high levels of type II errors. Fortunately there are other methods for addressing the multiple comparisons issue and they are built into R.</p>
<p>John Tukey’s test of “Honestly Significant Differences” is commonly used to address the multiple comparisons issue when examining all possible pairwise contrasts. This method is available in R by the function in several different methods. This test is near optimal when each group has the same number of samples (which is often termed “a balanced design”), but becomes more conservative (fails to detect differences) as the design becomes more unbalanced. In extremely unbalanced cases, it is preferable to use a Bonferroni adjustment.</p>
<p>Using function <code>emmeans::emmeans()</code> function, which by default does Tukey’s adjustment, the adjusted p-value for the difference between groups 1 and 4 is no longer significant.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>Grp, mydata)
t1 &lt;-<span class="st"> </span>emmeans<span class="op">::</span><span class="kw">emmeans</span>(model, pairwise <span class="op">~</span><span class="st"> </span>Grp)
t1</code></pre></div>
<pre><code>## $emmeans
##  Grp emmean    SE df lower.CL upper.CL
##  1    0.441 0.316 45   -0.196   1.0776
##  2   -0.116 0.316 45   -0.753   0.5203
##  3    0.201 0.316 45   -0.436   0.8377
##  4   -0.548 0.316 45   -1.184   0.0891
##  5   -0.184 0.316 45   -0.820   0.4532
## 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast estimate    SE df t.ratio p.value
##  1 - 2       0.557 0.447 45  1.247  0.7244 
##  1 - 3       0.240 0.447 45  0.537  0.9830 
##  1 - 4       0.989 0.447 45  2.211  0.1943 
##  1 - 5       0.624 0.447 45  1.397  0.6330 
##  2 - 3      -0.317 0.447 45 -0.710  0.9532 
##  2 - 4       0.431 0.447 45  0.964  0.8695 
##  2 - 5       0.067 0.447 45  0.150  0.9999 
##  3 - 4       0.749 0.447 45  1.674  0.4597 
##  3 - 5       0.384 0.447 45  0.860  0.9099 
##  4 - 5      -0.364 0.447 45 -0.814  0.9248 
## 
## P value adjustment: tukey method for comparing a family of 5 estimates</code></pre>
<p>It is also straightforward to generate the letter display using the function <code>cld()</code> which stands for <em>compact letter display</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">emmeans<span class="op">::</span><span class="kw">emmeans</span>(model, <span class="op">~</span><span class="st"> </span>Grp) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># don&#39;t have the pairwise here or else</span>
<span class="st">  </span>multcomp<span class="op">::</span><span class="kw">cld</span>( <span class="dt">Letters=</span>letters )     <span class="co"># the cld() function gets confused...</span></code></pre></div>
<pre><code>##  Grp     emmean        SE df   lower.CL   upper.CL .group
##  4   -0.5476682 0.3161521 45 -1.1844312 0.08909484  a    
##  5   -0.1835186 0.3161521 45 -0.8202817 0.45324440  a    
##  2   -0.1164715 0.3161521 45 -0.7532346 0.52029152  a    
##  3    0.2009232 0.3161521 45 -0.4358399 0.83768620  a    
##  1    0.4408853 0.3161521 45 -0.1958777 1.07764834  a    
## 
## Confidence level used: 0.95 
## P value adjustment: tukey method for comparing a family of 5 estimates 
## significance level used: alpha = 0.05</code></pre>
<p>Likewise if we are testing the ANOVA assumption of equal variance, we cannot rely on doing all pairwise F-tests and we must use a method that controls the overall error rate. The multiple comparisons version of <code>var.test()</code> is Levene’s test which is called similarly to <code>lm()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># leveneTest() is a function that is defined in the &quot;car&quot; package.</span>
car<span class="op">::</span><span class="kw">leveneTest</span>(Y<span class="op">~</span>Group, mydata)</code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  4  0.6173 0.6524
##       45</code></pre>
<p><strong>Example 2</strong>. (Example 8.2 from the Ott and Longnecker) A clinical psychologist wished to compare three methods for reducing hostility levels in university students, and used a certain test (HLT) to measure the degree of hostility. A high score on the test indicated great hostility. The psychologist used <span class="math inline">\(24\)</span> students who obtained high and nearly equal scores in the experiment. Eight subjects were selected at random from among the <span class="math inline">\(24\)</span> problem cases and were treated with method 1, seven of the remaining <span class="math inline">\(16\)</span> students were selected at random and treated with method 2 while the remaining nine students were treated with method 3. All treatments were continued for a one-semester period. Each student was given the HLT test at the end of the semester, with the results show in the following table. Use these data to perform an analysis of variance to determine whether there are differences among the mean scores for the three methods using a significance level of <span class="math inline">\(\alpha=0.05\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define the data</span>
Hostility &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">HLT =</span> <span class="kw">c</span>(<span class="dv">96</span>,<span class="dv">79</span>,<span class="dv">91</span>,<span class="dv">85</span>,<span class="dv">83</span>,<span class="dv">91</span>,<span class="dv">82</span>,<span class="dv">87</span>,
          <span class="dv">77</span>,<span class="dv">76</span>,<span class="dv">74</span>,<span class="dv">73</span>,<span class="dv">78</span>,<span class="dv">71</span>,<span class="dv">80</span>,
          <span class="dv">66</span>,<span class="dv">73</span>,<span class="dv">69</span>,<span class="dv">66</span>,<span class="dv">77</span>,<span class="dv">73</span>,<span class="dv">71</span>,<span class="dv">70</span>,<span class="dv">74</span>),
  <span class="dt">Method =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;M1&#39;</span>,<span class="dv">8</span>), <span class="kw">rep</span>(<span class="st">&#39;M2&#39;</span>,<span class="dv">7</span>), <span class="kw">rep</span>(<span class="st">&#39;M3&#39;</span>,<span class="dv">9</span>) ) )</code></pre></div>
<p>The first thing we will do (as we should do in all data analyses) is to graph our data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Hostility, <span class="kw">aes</span>(<span class="dt">x=</span>Method, <span class="dt">y=</span>HLT)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>These box plots make it clear that there is a difference between the three groups (at least group M1 is different from M2 or M3). An ANOVA model assumes equal variance between groups and that the residuals are normally distributed. Based on the box plot, the equal variance assumption might be suspect (although with only <span class="math inline">\(\approx 8\)</span> observations per group, it might not be bad). We’ll examine a QQ-plot of the residuals to consider the normality.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Is there equal variance in residuals across groups?</span>
<span class="co"># Are the residuals approximately normal?</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>( HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility )
<span class="kw">autoplot</span>(model, <span class="dt">which=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</code></pre></div>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>To examine the Normality of the residuals, we’ll use a Shapiro-Wilk’s test and we’ll also use Levene’s test for homogeneity of variances.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test for equal variances between groups</span>
car<span class="op">::</span><span class="kw">leveneTest</span>(HLT<span class="op">~</span>Method, <span class="dt">data=</span>Hostility)</code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  2  1.6817 0.2102
##       21</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test for Normality</span>
<span class="kw">shapiro.test</span>(<span class="kw">resid</span>(model))</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(model)
## W = 0.98358, p-value = 0.9516</code></pre>
<p>The results of the Shapiro-Wilks test agree with the QQ-plot, and Levene’s test fails to detect differences in the variances between the two groups. This is not to say that there might not be a difference, only that we do not detect one.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>( HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility )
<span class="kw">anova</span>(model)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: HLT
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Method     2 1090.62  545.31  29.574 7.806e-07 ***
## Residuals 21  387.21   18.44                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Because the p-value in the ANOVA table is smaller than <span class="math inline">\(\alpha=0.05\)</span>, we can reject the null hypothesis of equal means and conclude that at least one of the means is different from the others. Our estimate of <span class="math inline">\(\sigma^{2}\)</span> is <span class="math inline">\(\hat{\sigma}^2=18.44\)</span> so the estimate of <span class="math inline">\(\sigma\)</span> is <span class="math inline">\(\hat{\sigma}=\sqrt{18.44}=4.294\)</span>.</p>
<p>To find out which means are different we look at the group means and confidence intervals as well as all the pairwise contrasts between the groups. We will control for the multiple comparisons issue by using Tukey’s method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">emmeans<span class="op">::</span><span class="kw">emmeans</span>(model, pairwise<span class="op">~</span>Method)</code></pre></div>
<pre><code>## $emmeans
##  Method emmean   SE df lower.CL upper.CL
##  M1       86.8 1.52 21     83.6     89.9
##  M2       75.6 1.62 21     72.2     78.9
##  M3       71.0 1.43 21     68.0     74.0
## 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast estimate   SE df t.ratio p.value
##  M1 - M2     11.18 2.22 21 5.030   0.0002 
##  M1 - M3     15.75 2.09 21 7.548   &lt;.0001 
##  M2 - M3      4.57 2.16 21 2.112   0.1114 
## 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>If we feel uncomfortable with the equal variance assumption, we can do each pairwise t-test using non-pooled variance and then correct for the multiple comparisons using Bonferroni’s p-value correction. If we have <span class="math inline">\(k=3\)</span> groups, the we have <span class="math inline">\(k(k-1)/2=3\)</span> different comparisons, so I will calculate each p-value and multiply by <span class="math inline">\(3\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairwise.t.test</span>(Hostility<span class="op">$</span>HLT, Hostility<span class="op">$</span>Method, 
                <span class="dt">pool.sd=</span><span class="ot">FALSE</span>, <span class="dt">p.adjust.method=</span><span class="st">&#39;none&#39;</span>)</code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with non-pooled SD 
## 
## data:  Hostility$HLT and Hostility$Method 
## 
##    M1      M2    
## M2 0.0005  -     
## M3 2.2e-05 0.0175
## 
## P value adjustment method: none</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairwise.t.test</span>(Hostility<span class="op">$</span>HLT, Hostility<span class="op">$</span>Method, 
                <span class="dt">pool.sd=</span><span class="ot">FALSE</span>, <span class="dt">p.adjust.method=</span><span class="st">&#39;bonferroni&#39;</span>)</code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with non-pooled SD 
## 
## data:  Hostility$HLT and Hostility$Method 
## 
##    M1      M2    
## M2 0.0015  -     
## M3 6.7e-05 0.0525
## 
## P value adjustment method: bonferroni</code></pre>
<p>Using the Bonferroni adjusted p-values, we continue to detect a statistically significant difference between Method 1 and both Methods 2 &amp; 3, but do not detect a difference between Method 2 and Method 3.</p>
</div>
<div id="different-model-representations" class="section level2">
<h2><span class="header-section-number">9.5</span> Different Model Representations</h2>
<div id="theory-1" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Theory</h3>
<p>We started with what I will call the “cell means model” <span class="math display">\[Y_{ij}=\mu_{i}+\epsilon_{ij}\;\;\;\textrm{where}\;\;\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma^{2}\right)\]</span> so that the <span class="math inline">\(E\left(Y_{ij}\right)=\mu_{i}\)</span> where I interpret <span class="math inline">\(\mu_{i}\)</span> as the mean of each population. Given some data, we the following graph where the red lines and numbers denote the observed mean of the data in each group :</p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>But I am often interested in the difference between one group and another. For example, suppose this data comes from an experiment and group 1 is the control group. Then perhaps what I’m really interested is not that group 2 has a mean of 9, but rather that it is 5 units larger than the control. In this case perhaps what we care about is the differences. I could re-write the group means in terms of these differences from group 1. So looking at the model this way, the values that define the group means are the mean of group 1 (here it is 4), and the offsets from group 1 to group 2 (which is 5), and the offset from group 1 to group 3 (which is 10).</p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>I could write this interpretation of the model as the “offset” model which is <span class="math display">\[Y_{ij}=\mu+\tau_{i}+\epsilon_{ij}\]</span> where <span class="math inline">\(\mu\)</span> is the mean of group 1 and <span class="math inline">\(\tau_{i}\)</span> is each population’s offset from group 1. Because group 1 can’t be offset from itself, this forces <span class="math inline">\(\tau_{1}=0\)</span>.</p>
<p>Notice that this representation of the complex model has 4 parameters (aside from <span class="math inline">\(\sigma\)</span>), but it has an additional constraint so we still only have 3 parameters that can vary (just as the cell means model has 3 means).</p>
<p>The cell means model and the offset model really are the same model, just looked at slightly differently. They have the same number of parameters, and produce the same predicted values for <span class="math inline">\(\hat{y}_{ij}\)</span> and therefore have the same sum of squares, etc. The only difference is that one is might be more convenient depending on the question the investigator is asking. Actually in all the previous work in this chapter, we’ve been using the offset representation but <code>emmeans::emmeans()</code> is smart enough to recognize when we want the cell means model.</p>
<p>Another way to write the cell means model is as <span class="math inline">\(Y_{ij}=\mu+\tau_{i}+\epsilon_{ij}\)</span> but with the constraint that <span class="math inline">\(\mu=0\)</span>. It doesn’t matter which constraint you use so long as you know which is being used because the interpretation of the values changes (group mean versus an offset from the reference group).</p>
</div>
<div id="model-representations-in-r" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Model Representations in R</h3>
<p>To obtain the different representations within R, we will vary the formula to include or exclude the intercept term <span class="math inline">\(\mu\)</span>. By default, R assumes you want the intercept term (offset representation) and you must use the -1 term in the formula for the cell means representation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fake.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(   <span class="dt">y =</span>        <span class="kw">c</span>( <span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,  <span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>, <span class="dv">13</span>,<span class="dv">14</span>,<span class="dv">15</span>),
                         <span class="dt">grp =</span> <span class="kw">factor</span>(<span class="kw">c</span>( <span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,  <span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,   <span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span> )) )
<span class="co"># Offset representation </span>
<span class="co">#   Unless you have a -1, R implicitly  </span>
<span class="co">#   adds a &quot;+1&quot; to the formula, so </span>
<span class="co">#   so the following statements are equivalent</span>
c.model.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st">     </span>grp, <span class="dt">data=</span>fake.data)
c.model.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>grp, <span class="dt">data=</span>fake.data)
<span class="kw">coef</span>(c.model.<span class="dv">1</span>)</code></pre></div>
<pre><code>## (Intercept)        grp2        grp3 
##           4           5          10</code></pre>
<p>In the above case, we see R is giving the mean of group 1 and then the two offsets.</p>
<p>To force R to use the cell means model, we force R to use the constraint that <span class="math inline">\(\mu=0\)</span> by including a -1 in the model formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c.model.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>grp, <span class="dt">data=</span>fake.data)
<span class="kw">coef</span>(c.model.<span class="dv">1</span>)</code></pre></div>
<pre><code>## grp1 grp2 grp3 
##    4    9   14</code></pre>
<p>Returning the hostility example, recall we used the cell means model and we can extract parameter coefficient estimates using the <code>coef</code> function and ask for the appropriate confidence intervals using <code>confint()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility)
<span class="kw">coef</span>(model)</code></pre></div>
<pre><code>## MethodM1 MethodM2 MethodM3 
## 86.75000 75.57143 71.00000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##             2.5 %   97.5 %
## MethodM1 83.59279 89.90721
## MethodM2 72.19623 78.94663
## MethodM3 68.02335 73.97665</code></pre>
<p>We can use the offset model by removing -1 term from the formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility)
<span class="kw">coef</span>(model)</code></pre></div>
<pre><code>## (Intercept)    MethodM2    MethodM3 
##    86.75000   -11.17857   -15.75000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept)  83.59279  89.907212
## MethodM2    -15.80026  -6.556886
## MethodM3    -20.08917 -11.410827</code></pre>
<p>The intercept term in the offset representation corresponds to Method1 and the coefficients and confidence intervals are the same as in the cell means model. However in the offset model, Method2 is the difference between Method1 and Method2. Notice the coefficient is negative, thus telling us that Method2 has a smaller mean value than the reference group Method1. Likewise Method3 has a negative coefficient indicating that the Method3 group is lower than the reference group.</p>
<p>Similarly the confidence intervals for Method2 and Method3 are now confidence intervals for the difference between these methods and the reference group Method1.</p>
<p>Why would we ever want the offset model vs the cell means model? Often we are interested in testing multiple treatments against a control group and we only care about the change from the control. In that case, setting the control group to be the reference makes sense.</p>
<p>Neither representation is more powerful because on a very deep mathematical level, they are exactly the same model. Superficially though, one representation might be more convenient than the other in a given situation.</p>
</div>
<div id="implications-on-the-anova-table" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Implications on the ANOVA table</h3>
<p>We have been talking about the complex and simple models for our data but there is one more possible model, albeit not a very good one. I will refer to this as the bad model because it is almost always a poor fitting model. <span class="math display">\[Y_{ij}=\epsilon_{ij} \;\;\; \textrm{ where }\;\;\; \epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma^{2}\right).\]</span></p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Notice that the complex model has three parameters that define “signal” part of the model (i.e. the three group means). The simple has one parameter that defines the “signal” (the overall mean). The bad model has no parameters that define the model (i.e. the red line is always at zero).</p>
<p>These three models can be denoted in R by:</p>
<ul>
<li>Complex: – offset representation: <code>Y ~ group</code> which R will recognize as <code>Y ~ group + 1</code> – cell means representation: <code>Y ~ group - 1</code></li>
<li>Simple: <code>Y ~ 1</code></li>
<li>Bad: <code>Y ~ -1</code></li>
</ul>
<p>In the analysis of variance table calculated by <code>anova()</code>, R has to decide which simple model to compare the complex model to. If you used the offset representation, then when group is removed from the model, we are left with the model <code>Y ~ 1</code>, which is the simple model. If we wrote the complex model using the cell means representation, then when group is removed, we are left with the model <code>Y ~ -1</code> which is the bad model.</p>
<p>When we produce the ANOVA table compare the complex to the bad model, the difference in number of parameters between the models will be 3 (because I have to add three parameters to go from a signal line of 0, to three estimated group means). The ANOVA table comparing simple model to the complex will have a difference in number of parameters of 2 (because the simple mean has 1 estimated value compared to 3 estimated values).</p>
<p><strong>Example</strong>. Hostility Scores We return to the hostility scores example and we will create the two different model representations in R and see how the ANOVA table produced by R differs between the two.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">offset.representation &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility)
cell.representation   &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span>Method <span class="op">-</span><span class="dv">1</span>, <span class="dt">data=</span> Hostility)

<span class="co"># This is the ANOVA table we want, comparing Complex to Simple</span>
<span class="co"># Notice the df of the difference between the models is 3-1 = 2</span>
<span class="kw">anova</span>(offset.representation)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: HLT
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Method     2 1090.62  545.31  29.574 7.806e-07 ***
## Residuals 21  387.21   18.44                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This is the ANOVA table comparing the Complex to the BAD model</span>
<span class="co"># Noice the df of the difference between the models is 3-0 = 3</span>
<span class="kw">anova</span>(cell.representation)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: HLT
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Method     3 145551   48517  2631.2 &lt; 2.2e-16 ***
## Residuals 21    387      18                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Because the bad model is extremely bad in this case, the F-statistic for comparing the complex to the bad model is extremely large (<span class="math inline">\(F=2631\)</span>). The complex model is also superior to the simple model, but not by as emphatically (<span class="math inline">\(F=29\)</span>).</p>
<p>One way to be certain which models you are comparing is to explicitly choose the two models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">simple &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>Hostility)

<span class="co"># create the ANOVA table comparing the complex model (using the </span>
<span class="co"># cell means representation) to the simple model. </span>
<span class="co"># The output shown in the following contains all the</span>
<span class="co"># necessary information, but is arranged slightly differently.</span>
<span class="kw">anova</span>(simple, cell.representation)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: HLT ~ 1
## Model 2: HLT ~ Method - 1
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     23 1477.83                                  
## 2     21  387.21  2    1090.6 29.574 7.806e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>My recommendation is to always fit the offset model and, if you are interested in all of the mean values, just access the group means and difference between groups using the <code>emmeans::emmeans()</code> function. If you are interested in the just the offsets, then you can access them through the base functions <code>coef()</code> and <code>conf()</code> or pick them out of your <code>emmeans</code> output.</p>
</div>
</div>
<div id="exercises-8" class="section level2">
<h2><span class="header-section-number">9.6</span> Exercises</h2>
<p><em>In previous chapters, the exercises have been quite blunt about asking you to interpret your results when appropriate. In this chapter (and subsequent chapters) the questions don’t explicitly ask your interpretation, but rather it is implied that and the end of a calculation or whenever you produce a graph or table, there should always be some sort of comment about the result (e.g. this result shows that the residuals are not normally distributed). Your job is to interpret the results, not just produce them.</em></p>
<p><em>Eventually, your job will be to figure out what analysis to conduct, what assumptions should be checked, and how to interpret all of your results in the context of the problem. But for now, it will be up to you to know when to interpret your results.</em></p>
<ol style="list-style-type: decimal">
<li><p>For this exercise, we will compare the Sums of Squared Error for the simple <span class="math inline">\(y_{ij}=\mu+\epsilon_{ij}\)</span> and complex <span class="math inline">\(y_{ij}=\mu_{i}+\epsilon_{ij}\)</span> model and clearly, in the data presented below, the complex model fits the data better. The group means <span class="math inline">\(\bar{y}_{i\cdot}\)</span> are 3, 13, 5, and 9, while the overall mean is <span class="math inline">\(\bar{y}_{\cdot\cdot}=7.5\)</span>.<br />
<img src="09_ANOVA_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<ol style="list-style-type: lower-alpha">
<li><p>For the simple model graph, draw a horizontal line at the height of the overall mean, representing predicted value of a new observation. Next, draw the the corresponding residuals <span class="math inline">\(y_{ij}-\bar{y}_{\cdot\cdot}\)</span> as vertical lines from the data points to the overall mean. Similarly draw horizontal lines for the group means in the complex model and represent the residuals for the complex model <span class="math inline">\(y_{ij}-\bar{y}_{i\cdot}\)</span> as vertical lines from the data points to the group means. In this case, does it appear that the average residual is significantly larger in the simple model than the complex? <em>Hint: Don’t try to do this in R, but rather do this using a pencil and paper.</em></p></li>
<li><p>To show that the complex is a significantly better model, fill in the empty boxes in the ANOVA table.</p>
<table>
<thead>
<tr class="header">
<th align="center">Source</th>
<th align="center">df</th>
<th align="center">SS</th>
<th align="center">MS</th>
<th align="center">F</th>
<th align="center">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Difference</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">Complex</td>
<td align="center"></td>
<td align="center">20</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Simple</td>
<td align="center"></td>
<td align="center">256</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Interpret the p-value you have produced.</p></li>
</ol></li>
<li><p>We will essentially repeat the previous exercise, except this time, the simple model will be preferred. Again for each group, we have <span class="math inline">\(n_i=3\)</span> observations.</p>
<p><img src="09_ANOVA_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
For this data, the following group means can be calculated as <span class="math inline">\(\bar{y}_{i\cdot} = (4.42, 5.21, 4.58)\)</span> and the overall mean is <span class="math inline">\(\bar{y}_{\cdot \cdot}=4.73\)</span>.
<ol style="list-style-type: lower-alpha">
<li>For the simple model graph, draw the corresponding residuals <span class="math inline">\(y_{ij}-\bar{y}_{\cdot\cdot}\)</span> as vertical lines from the data point to the overall mean. Similarly draw the residuals for the complex model <span class="math inline">\(y_{ij}-\bar{y}_{i\cdot}\)</span> as vertical lines from the data points to the group means. In this case, does it appear that the average residual is significantly larger in the simple model than the complex? <em>Again, just draw predicted values and residuals by hand.</em></li>
<li><p>To show that the complex not a significantly better model, fill in the empty boxes in the ANOVA table.</p>
<table>
<thead>
<tr class="header">
<th align="center">Source</th>
<th align="center">df</th>
<th align="center">SS</th>
<th align="center">MS</th>
<th align="center">F</th>
<th align="center">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Difference</td>
<td align="center"></td>
<td align="center">1.035</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">Complex</td>
<td align="center"></td>
<td align="center">8.7498</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Simple</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Interpret the p-value you have produced.</p></li>
</ol></li>
<li><p>The following data were collected and we wish to perform an analysis of variance to determine if the group means are statistically different.</p>
<table>
<thead>
<tr class="header">
<th align="center">Group 1</th>
<th align="center">Group 2</th>
<th align="center">Group 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">4,6,6,8</td>
<td align="center">8,8,6,6</td>
<td align="center">12,13,15,16</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>The complex model assumes different means for each group. That is <span class="math inline">\(Y_{ij}=\mu_{i}+\epsilon_{ij}\)</span>. Calculate <span class="math inline">\(SSE_{complex}\)</span> via the following:
<ol style="list-style-type: lower-roman">
<li>Find the estimate of <span class="math inline">\(\mu_{i}\)</span>. That is, calculate <span class="math inline">\(\hat{\mu}_{i}=\bar{y}_{i\cdot}\)</span> which is the mean of each group. Therefore the predicted value for a new observation in group <span class="math inline">\(i\)</span> would be <span class="math inline">\(\hat{y}_{ij}=\hat{\mu}_{i}=\bar{y}_{i\cdot}\)</span> and you can now calculate <span class="math inline">\(SSE_{complex}\)</span>.</li>
<li>Calculate <span class="math display">\[SSE_{complex} = \sum_{i=1}^{3}\sum_{j=1}^{4} e_{ij}^2 =\sum_{i=1}^{3}\sum_{j=1}^{4}\left(y_{ij}-\hat{y}_{ij}\right)^{2}=\sum_{i=1}^{3}\sum_{j=1}^{4}\left(y_{ij}-\bar{y}_{i\cdot}\right)^{2}\]</span></li>
</ol></li>
<li>The simple model assumes the same mean for each group. That is <span class="math inline">\(Y_{ij}=\mu+\epsilon_{ij}\)</span> Calculate <span class="math inline">\(SSE_{simple}\)</span> via the following:
<ol style="list-style-type: lower-roman">
<li>Find the estimate of <span class="math inline">\(\mu\)</span>. That is, calculate <span class="math inline">\(\hat{\mu}=\bar{y}_{\cdot\cdot}\)</span> which is the overall mean of all the data. Therefore the predicted value for a new observation in any group would be <span class="math inline">\(\hat{y}_{ij}=\hat{\mu}=\bar{y}_{\cdot\cdot}\)</span> and we can calculate <span class="math inline">\(SSE_{simple}\)</span></li>
<li>Calculate <span class="math display">\[SSE_{simple}=\sum_{i=1}^{3}\sum_{j=1}^{4} e_{ij}^2=\sum_{i=1}^{3}\sum_{j=1}^{4}\left(y_{ij}-\hat{y}_{ij}\right)^{2}=\sum_{i=1}^{3}\sum_{j=1}^{4}\left(y_{ij}-\bar{y}_{\cdot\cdot}\right)^{2}\]</span></li>
</ol></li>
<li>Create the ANOVA table using your results in part (b).</li>
<li>Create the ANOVA table using R by typing in the data set and fitting the appropriate model using the <code>lm()</code> and <code>anova()</code> commands.</li>
</ol></li>
<li><p>Suppose that for a project I did four separate t-tests and the resulting p-values were</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(p_1\)</span></th>
<th align="center"><span class="math inline">\(p_2\)</span></th>
<th align="center"><span class="math inline">\(p_3\)</span></th>
<th align="center"><span class="math inline">\(p_4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.03</td>
<td align="center">0.14</td>
<td align="center">0.01</td>
<td align="center">0.001</td>
</tr>
</tbody>
</table></li>
</ol>
<p>If I wanted to control my overall type I error rate at an <span class="math inline">\(\alpha=0.05\)</span> and used the Bonferroni multiple comparisons procedure, which tests would be statistically significant? <em>Notice that this problem does not mention any pairwise contrasts as the Bonferroni correction can be done in a variety of situations. So just use the fact that we are making four different tests and we want to control the overall Type I Error rate.</em></p>
<ol start="5" style="list-style-type: decimal">
<li>We will examine the amount of waste produced at five different plants that manufacture Levi Jeans. The Waste amount is the amount of cloth wasted in cutting out designs compared to a computer program, so negative values for Waste indicate that the human engineer did a better job planning the cuts than the computer algorithm. There are two columns, <code>Plant</code> and <code>Waste</code>.
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R using the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Levi &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;https://raw.github.com/dereksonderegger/570/master/data-raw/Levi.csv&#39;</span>)</code></pre></div>
<ol style="list-style-type: lower-roman">
<li>Examine the data frame using the <code>str(Levi)</code> command. Is the Plant column already a factor, or do you need to convert it to a factor?</li>
</ol></li>
<li>Make a boxplot of the data. Do any assumptions necessary for ANOVA appear to be violated?</li>
<li>Test the equal variance assumption using Levene’s test.</li>
<li><p>Fit an ANOVA model to these data and test if the residuals have a normal distribution using the Shapiro-Wilks test.</p></li>
</ol></li>
<li>The dataset <code>iris</code> is available on R and can be loaded by the entering the command <code>data('iris')</code> at your R prompt. This famous data set contains the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for <span class="math inline">\(n_{i}=50\)</span> flowers from each of <span class="math inline">\(3\)</span> species of iris. The species of iris are <em>setosa</em>, <em>versicolor</em>, and <em>virginica</em>. We will be examining the relationship between sepal width and the species of these irises. Denote the mean value of all setosa flowers as <span class="math inline">\(\mu_{setosa}\)</span> and similar notation for the other species.
<ol style="list-style-type: lower-alpha">
<li>Make a boxplot of the data. Do any assumptions necessary for ANOVA appear to be violated?</li>
<li>Test the equal variance assumption of ANOVA using Levene’s test.</li>
<li>Do the ANOVA test and test the normality of the residual terms by making a QQplot and doing the Shapiro-Wilk’s test.</li>
<li>Examine the ANOVA table. What is the p-value for testing the hypotheses <span class="math display">\[\begin{aligned}
H_{0} &amp;:\,      \mu_{setosa}=\mu_{virginica}=\mu_{versicolor} \\
H_{a} &amp;:\,      \textrm{at least on mean is different} 
\end{aligned}\]</span></li>
<li>Now that we know there is a statistically significant difference among the means (and with setosa having a mean Sepal.Width about 30% larger than the other two, I think aesthetically that is a big difference), we can go searching for it. Use Tukey’s “Honestly Significant Differences” method to test all the pairwise comparisons between means. In particular, what is the p-value for testing <span class="math display">\[\begin{aligned}
H_{0} &amp;:\,      \mu_{setosa}=\mu_{virginica} \\
H_{a} &amp;:\:      \mu_{setosa}\ne\mu_{virginica}
\end{aligned}\]</span></li>
<li>What is the estimated value of <span class="math inline">\(\mu_{setosa}\)</span>? What is the estimated value of <span class="math inline">\(\mu_{virginica}\)</span>?</li>
<li>What is the estimated value of <span class="math inline">\(\sigma^{2}\)</span>?</li>
<li>By hand, calculate the appropriate 95% confidence interval for <span class="math inline">\(\mu_{setosa}\)</span>.</li>
<li>Using R, confirm your calculation in part (h).</li>
</ol></li>
</ol>
<!--chapter:end:09_ANOVA.Rmd-->
</div>
</div>
<div id="regression" class="section level1">
<h1><span class="header-section-number">10</span> Regression</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggfortify)  <span class="co"># for diagnostic plots in ggplot2 via autoplot()</span></code></pre></div>
<p>We continue to want to examine the relationship between a predictor variable and a response but now we consider the case that the predictor is continuous and the response is also continuous. In general we are going to be interested in finding the line that best fits the observed data and determining if we should include the predictor variable in the model.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div id="pearsons-correlation-coefficient" class="section level2">
<h2><span class="header-section-number">10.1</span> Pearson’s Correlation Coefficient</h2>
<p>We first consider Pearson’s correlation coefficient, which is a statistics that measures the strength of the linear relationship between the predictor and response. Consider the following Pearson’s correlation statistic <span class="math display">\[r=\frac{\sum_{i=1}^{n}\left(\frac{x_{i}-\bar{x}}{s_{x}}\right)\left(\frac{y_{i}-\bar{y}}{s_{y}}\right)}{n-1}\]</span> where <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(y_{i}\)</span> are the x and y coordinate of the <span class="math inline">\(i\)</span>th observation. Notice that each parenthesis value is the standardized value of each observation. If the x-value is big (greater than <span class="math inline">\(\bar{x}\)</span>) and the y-value is large (greater than <span class="math inline">\(\bar{y}\)</span>), then after multiplication, the result is positive. Likewise if the x-value is small and the y-value is small, both standardized values are negative and therefore after multiplication the result is positive. If a large x-value is paired with a small y-value, then the first value is positive, but the second is negative and so the multiplication result is negative.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The following are true about Pearson’s correlation coefficient:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(r\)</span> is unit-less because we have standardized the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values.</li>
<li><span class="math inline">\(-1\le r\le1\)</span> because of the scaling by <span class="math inline">\(n-1\)</span></li>
<li>A negative <span class="math inline">\(r\)</span> denotes a negative relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, while a positive value of <span class="math inline">\(r\)</span> represents a positive relationship.</li>
<li><span class="math inline">\(r\)</span> measures the strength of the linear relationship between the predictor and response.</li>
</ol>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="model-theory" class="section level2">
<h2><span class="header-section-number">10.2</span> Model Theory</h2>
<p>To scatterplot data that looks linear we often want to fit the model <span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\;\;\;\textrm{where }\epsilon_{i}\stackrel{iid}{\sim}N\left(0,\sigma^{2}\right)\]</span> where</p>
<table>
<colgroup>
<col width="23%" />
<col width="22%" />
<col width="54%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Parameter</th>
<th align="center">Name</th>
<th align="left">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\beta_0\)</span></td>
<td align="center">y-intercept</td>
<td align="left">Height of regression line at <span class="math inline">\(x=0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\beta_1\)</span></td>
<td align="center">slope</td>
<td align="left">How much the line rises for a <span class="math inline">\(1\)</span> unit increase in <span class="math inline">\(x\)</span>.</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\sigma\)</span></td>
<td align="center">Standard Deviation</td>
<td align="left">The “typical” distance from a point to the regression line</td>
</tr>
</tbody>
</table>
<p>The assumptions of this model are:</p>
<ol style="list-style-type: decimal">
<li><em>The relationship between the predictor and response is actually linear.</em></li>
<li><em>The error terms come from a normal distribution.</em></li>
<li><em>The variance of the errors is the same for every value of x (homoscedasticity).</em></li>
<li><em>The error terms are independent.</em></li>
</ol>
<p>Under this model, the expected value of an observation with covariate <span class="math inline">\(X=x\)</span> is <span class="math inline">\(E\left(Y\,|\,X=x\right)=\beta_{0}+\beta_{1}x\)</span> and a new observation has a standard deviation of <span class="math inline">\(\sigma\)</span> about the line.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Given this model, how do we find estimates of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>? In the past we have always relied on using some sort of sample mean, but it is not obvious what we can use here. Instead of a mean, we will use the values of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> that minimize the sum of squared error (SSE) where <span class="math display">\[\begin{aligned}
\hat{y}_{i} &amp;=  \hat{\beta}_{0}+\hat{\beta}_{1}x_{i} \\
e_{i}         &amp;=    y_{i}-\hat{y}_{i} \\
SSE         &amp;=  \sum_{i=1}^{n}e_{i}^{2}
\end{aligned}\]</span></p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Fortunately there are simple closed form solutions for <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> <span class="math display">\[\begin{aligned}
\hat{\beta}_{1} &amp;=  r\,\left(\frac{s_{y}}{s_{x}}\right)\\
\hat{\beta_{0}} &amp;=  \bar{y}-\hat{\beta}_{1}\bar{x} 
\end{aligned}\]</span></p>
<p>and using these estimates several properties can be shown</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> are the intercept and slope values that minimize SSE.</li>
<li>The regression line goes through the center of mass of the data (<span class="math inline">\(\bar{x}\)</span>,<span class="math inline">\(\bar{y}\)</span>).</li>
<li>The sum of the residuals is 0. That is: <span class="math inline">\(\sum e_{i}=0\)</span>.</li>
<li><span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> are unbiased estimators of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>.</li>
</ol>
<p>We are also interested in an estimate of <span class="math inline">\(\sigma^{2}\)</span> and we will use our usual estimation scheme of <span class="math display">\[\begin{aligned} \hat{\sigma}^{2}  
  &amp;= \frac{1}{n-2}\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}  
    =   \frac{\sum_{i=1}^{n}e_{i}^{2}}{n-2} 
    =   \frac{SSE}{n-2} 
    =   MSE 
    \end{aligned}\]</span></p>
<p>where the <span class="math inline">\(-2\)</span> comes from having to estimate <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> before we can estimate <span class="math inline">\(\sigma^{2}\)</span>. As in the ANOVA case, we can interpret <span class="math inline">\(\sigma\)</span> as the typical distance an observation is from its predicted value.</p>
<p>As always we are also interested in knowing the estimated standard deviation (which we will call Standard Error) of the model parameters <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> and it can be shown that <span class="math display">\[StdErr\left(\hat{\beta}_{0}\right)=\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^{2}}{S_{xx}}}\]</span> and <span class="math display">\[StdErr\left(\hat{\beta}_{1}\right)=\hat{\sigma}\sqrt{\frac{1}{S_{xx}}}\]</span> where <span class="math inline">\(S_{xx}=\sum\left(x_{i}-\bar{x}\right)^{2}\)</span>. These intervals can be used to calculate confidence intervals for <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> using the formulas: <span class="math display">\[\hat{\beta}_{i}\pm t_{n-2}^{1-\alpha/2}StdErr\left(\hat{\beta}_{i}\right)\]</span></p>
<p>Again we consider the iris dataset that is available in R. I wish to examine the relationship between sepal length and sepal width in the species <em>setosa</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">setosa &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>( Species <span class="op">==</span><span class="st"> &#39;setosa&#39;</span> )    <span class="co"># Just setosa!</span>
<span class="kw">ggplot</span>(setosa, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Sepal Length&quot;</span>, <span class="dt">y=</span><span class="st">&quot;Sepal Width&quot;</span>, <span class="dt">title=</span><span class="st">&#39;Setosa Irises&#39;</span>) </code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Do all the crazy calculations &quot;By Hand!&quot;</span>
x &lt;-<span class="st"> </span>setosa<span class="op">$</span>Sepal.Length
y &lt;-<span class="st"> </span>setosa<span class="op">$</span>Sepal.Width
n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
r &lt;-<span class="st"> </span><span class="kw">sum</span>( (x<span class="op">-</span><span class="kw">mean</span>(x))<span class="op">/</span><span class="kw">sd</span>(x) <span class="op">*</span><span class="st"> </span>(y<span class="op">-</span><span class="kw">mean</span>(y))<span class="op">/</span><span class="kw">sd</span>(y) ) <span class="op">/</span><span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)
b1 &lt;-<span class="st"> </span>r<span class="op">*</span><span class="kw">sd</span>(y)<span class="op">/</span><span class="kw">sd</span>(x)
b0 &lt;-<span class="st"> </span><span class="kw">mean</span>(y) <span class="op">-</span><span class="st"> </span>b1<span class="op">*</span><span class="kw">mean</span>(x)
<span class="kw">cbind</span>(r, b0, b1)</code></pre></div>
<pre><code>##              r         b0        b1
## [1,] 0.7425467 -0.5694327 0.7985283</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yhat &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x
resid &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>yhat
SSE &lt;-<span class="st"> </span><span class="kw">sum</span>( resid<span class="op">^</span><span class="dv">2</span> )
s2 &lt;-<span class="st"> </span>SSE<span class="op">/</span>(n<span class="op">-</span><span class="dv">2</span>)
s2</code></pre></div>
<pre><code>## [1] 0.06580573</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Sxx &lt;-<span class="st"> </span><span class="kw">sum</span>( (x<span class="op">-</span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span> )
stderr.b0 &lt;-<span class="st"> </span><span class="kw">sqrt</span>(s2) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span>n <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(x)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>Sxx)
stderr.b1 &lt;-<span class="st"> </span><span class="kw">sqrt</span>(s2) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>Sxx )
<span class="kw">cbind</span>(stderr.b0, stderr.b1)</code></pre></div>
<pre><code>##      stderr.b0 stderr.b1
## [1,] 0.5217119 0.1039651</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t.star &lt;-<span class="st"> </span><span class="kw">qt</span>(.<span class="dv">975</span>, <span class="dt">df=</span>n<span class="op">-</span><span class="dv">2</span>)  
<span class="kw">c</span>(b0<span class="op">-</span>t.star<span class="op">*</span>stderr.b0, b0<span class="op">+</span>t.star<span class="op">*</span>stderr.b0)</code></pre></div>
<pre><code>## [1] -1.6184048  0.4795395</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">c</span>(b1<span class="op">-</span>t.star<span class="op">*</span>stderr.b1, b1<span class="op">+</span>t.star<span class="op">*</span>stderr.b1)</code></pre></div>
<pre><code>## [1] 0.5894925 1.0075641</code></pre>
<p>Of course, we don’t want to have to do these calculations by hand. Fortunately statistics packages will do all of the above calculations. In R, we will use <code>lm()</code> to fit a linear regression model and then call various accessor functions to give me the regression output I want.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>( setosa<span class="op">$</span>Sepal.Width,  setosa<span class="op">$</span>Sepal.Length )</code></pre></div>
<pre><code>## [1] 0.7425467</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(Sepal.Width <span class="op">~</span><span class="st"> </span>Sepal.Length, <span class="dt">data=</span>setosa)
<span class="kw">coef</span>(model)</code></pre></div>
<pre><code>##  (Intercept) Sepal.Length 
##   -0.5694327    0.7985283</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##                   2.5 %    97.5 %
## (Intercept)  -1.6184048 0.4795395
## Sepal.Length  0.5894925 1.0075641</code></pre>
<p>In general, most statistics programs will give a table of output summarizing a regression and the table is usually set up as follows:</p>
<table>
<colgroup>
<col width="11%" />
<col width="12%" />
<col width="16%" />
<col width="36%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Coefficient</th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t-stat</th>
<th align="center">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Intercept</td>
<td align="center"><span class="math inline">\(\hat{\beta}_{0}\)</span></td>
<td align="center">StdErr<span class="math inline">\((\hat{\beta}_0)\)</span></td>
<td align="center"><span class="math inline">\(t_{0}=\frac{\hat{\beta}_0}{StdErr(\hat{\beta}_0)}\)</span></td>
<td align="center"><span class="math inline">\(2*P(T_{n-2}&gt;\vert t_0 \vert )\)</span></td>
</tr>
<tr class="even">
<td align="center">Slope</td>
<td align="center"><span class="math inline">\(\hat{\beta}_{1}\)</span></td>
<td align="center">StdErr<span class="math inline">\((\hat{\beta}_1)\)</span></td>
<td align="center"><span class="math inline">\(t_{1}=\frac{\hat{\beta}_1}{StdErr(\hat{\beta}_1)}\)</span></td>
<td align="center"><span class="math inline">\(2*P(T_{n-2}&gt;\vert t_1 \vert )\)</span></td>
</tr>
</tbody>
</table>
<p>This table is printed by R by using the <code>summary()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(Sepal.Width <span class="op">~</span><span class="st"> </span>Sepal.Length, <span class="dt">data=</span>setosa)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Sepal.Width ~ Sepal.Length, data = setosa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.72394 -0.18273 -0.00306  0.15738  0.51709 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -0.5694     0.5217  -1.091    0.281    
## Sepal.Length   0.7985     0.1040   7.681 6.71e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2565 on 48 degrees of freedom
## Multiple R-squared:  0.5514, Adjusted R-squared:  0.542 
## F-statistic: 58.99 on 1 and 48 DF,  p-value: 6.71e-10</code></pre>
<p>The first row is giving information about the y-intercept. In this case the estimate is <span class="math inline">\(-0.5694\)</span> and the standard error of the estimate is <span class="math inline">\(0.5217\)</span>. The t-statistic and associated p-value is testing the hypotheses: <span class="math inline">\(H_{0}:\,\beta_{0}=0\)</span> vs <span class="math inline">\(H_{a}:\,\beta_{0}\ne0\)</span>. This test is not usually of much interest. However because the equivalent test in the slope row testing <span class="math inline">\(\beta_{1}=0\)</span> vs <span class="math inline">\(\beta_{1}\ne0\)</span>, the p-value of the slope row is <em>very</em> interesting because it tells me if I should include the slope variable in the model. If <span class="math inline">\(\beta_{1}\)</span> could be zero, then we should drop the predictor from our model and use the simple model <span class="math inline">\(y_{i}=\beta_{0}+\epsilon_{i}\)</span> instead.</p>
<p>There are a bunch of other statistics that are returned by <code>summary()</code>. The Residual standard error is just <span class="math inline">\(\hat{\sigma}=\sqrt{MSE}\)</span> and the degrees of freedom for that error is also given. The rest are involved with the ANOVA interpretation of a linear model.</p>
<div id="anova-interpretation" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Anova Interpretation</h3>
<p>Just as in the ANOVA analysis, we really have a competition between two models. The full model <span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x+\epsilon_{i}\]</span> vs the simple model where x does not help predict <span class="math inline">\(y\)</span> <span class="math display">\[y_{i}=\beta_0+\epsilon_{i}\]</span> Notice this is effectively forcing the regression line to be flay and I could have written the model using <span class="math inline">\(\beta_{0}=\mu\)</span> to try to keep our notation straight. If I were to look at the simple model I would use <span class="math inline">\(\bar{y}=\hat{\beta}_0\)</span> as the predicted value of <span class="math inline">\(y\)</span> for <em>any</em> value of <span class="math inline">\(x\)</span> and my Sum of Squared Error in the simple model will be <span class="math display">\[SSE_{simple}  =   \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}
    =   \sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_0\right)^{2}\]</span> and the appropriate Mean Squared Error is</p>
<p><span class="math display">\[MSE_{simple}=\frac{1}{n-1}\sum\left(y_{i}-\hat{\beta}_0\right)^{2}\]</span></p>
<p>We can go through the same sort of calculations for the full complex model and get <span class="math display">\[SSE_{complex} =   \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}
    =   \sum_{i=1}^{n}\left(y_{i}-\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{i}\right)\right)^{2}\]</span> Notice that <span class="math inline">\(\hat{\beta}_0\)</span> term is in both models, but will not be numerically the same. Next we have <span class="math display">\[MSE_{complex}=\frac{1}{n-2}\sum_{i=1}^{n}\left(y_{i}-\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{i}\right)\right)^{2}\]</span> Just as in the AVOVA analysis, if we often like to look at the difference between <span class="math display">\[SSE_{simple}-SSE_{comples}=SSE_{diff}\]</span> and think of this quantity as the amount of variability that is explained by adding the slope parameter to the model. Just as in the AVOVA case we’ll calculate <span class="math display">\[MSE_{diff}=SSE_{diff}/df_{diff}\]</span> where <span class="math inline">\(df_{diff}\)</span> is the number of parameters that we added to the simple model to create the complex one. In the simple linear regression case, <span class="math inline">\(df_{diff}=1\)</span>.</p>
<p>Just as in the ANOVA case, we will calculate an f-statistic to test the null hypothesis that the simple model suffices vs the alternative that the complex model is necessary. The calculation is <span class="math display">\[f=\frac{MSE_{diff}}{MSE_{complex}}\]</span> and the associated p-value is <span class="math inline">\(P\left(F_{1,n-2}&gt;f\right)\)</span>. Notice that this test is exactly testing if <span class="math inline">\(\beta_{1}=0\)</span> and therefore the p-value for the F-test and the t-test for <span class="math inline">\(\beta_{1}\)</span> are the same. It can easily be shown that <span class="math inline">\(t_{1}^{2}=f\)</span>.</p>
<p>The Analysis of Variance table looks the same as what we have seen, but now we recognize that the rows actually represent the complex and simple models and the difference between them.</p>
<table style="width:100%;">
<colgroup>
<col width="9%" />
<col width="6%" />
<col width="12%" />
<col width="26%" />
<col width="29%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Source</th>
<th align="center">df</th>
<th align="center">Sum Sq</th>
<th align="center">MS</th>
<th align="center">F</th>
<th align="center">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Difference</td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(SSE_{diff}\)</span></td>
<td align="center"><span class="math inline">\(MSE_{diff} = SSE_{diff}/1\)</span></td>
<td align="center"><span class="math inline">\(f = \frac{MSE_{diff}}{MSE_{complex}}\)</span></td>
<td align="center"><span class="math inline">\(P(F_{1,n-2} &gt; f)\)</span></td>
</tr>
<tr class="even">
<td align="center">Complex</td>
<td align="center"><span class="math inline">\(n-2\)</span></td>
<td align="center"><span class="math inline">\(SSE_{complex}\)</span></td>
<td align="center"><span class="math inline">\(MSE{complex} = SSE_{complex}/(n-2\)</span></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Simple</td>
<td align="center"><span class="math inline">\(n-1\)</span></td>
<td align="center"><span class="math inline">\(SSE_{simple}\)</span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>As usual, the ANOVA table for the regression is available in R using the <code>anova()</code> command.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(Sepal.Width <span class="op">~</span><span class="st"> </span>Sepal.Length, <span class="dt">data=</span>setosa)
<span class="kw">anova</span>(model)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Sepal.Width
##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Sepal.Length  1 3.8821  3.8821  58.994 6.71e-10 ***
## Residuals    48 3.1587  0.0658                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>But we notice that R chooses not to display the row corresponding to the simple model.</p>
<p>I could consider <span class="math inline">\(SSE_{simple}\)</span> as a baseline measure of the amount of variability in the data. It is interesting to look at how much of that baseline variability has been explained by adding the additional parameter to the model. Therefore we’ll define the ratio <span class="math inline">\(R^{2}\)</span> as: <span class="math display">\[R^{2}=\frac{SSE_{diff}}{SSE_{simple}}=\frac{SSE_{simple}-SSE_{complex}}{SSE_{simple}}=r^{2}\]</span> where <span class="math inline">\(r\)</span> is Pearson’s Correlation Coefficient. <span class="math inline">\(R^{2}\)</span> has the wonderful interpretation of the percent of variability in the response variable that can be explained by the predictor variable <span class="math inline">\(x\)</span>.</p>
</div>
<div id="confidence-intervals-vs-prediction-intervals" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Confidence Intervals vs Prediction Intervals</h3>
<p>There are two different types of questions that we might ask about predicting the value for some x-value <span class="math inline">\(x_{new}\)</span>.</p>
<p>We might be interested in a confidence interval for regression line. For this question we want to know how much would we expect the sample regression line move if we were to collect a new set of data. In particular, for some value of <span class="math inline">\(x\)</span>, say <span class="math inline">\(x_{new}\)</span>, how variable would the regression line be? To answer that we have to ask what is the estimated variance of <span class="math inline">\(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\)</span>? The variance of the regression line will be a function of the variances of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> and thus the standard error looks somewhat reminiscent of the standard errors of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>. Recalling that we defined <span class="math inline">\(S_{xx}=\sum\left(x_{i}-\bar{x}\right)^{2}\)</span>, we have: <span class="math display">\[\hat{Var}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)=\hat{\sigma}^{2}\left(\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}\right)\]</span> and therefore its <span class="math inline">\(StdErr(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new})\)</span> is <span class="math display">\[StdErr\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)=\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}\]</span></p>
<p>We can use this value to produce a confidence interval for the regression line for any value of <span class="math inline">\(x_{new}\)</span>. <span class="math display">\[Estimate  \pm t\;StdErr\left(Estimate\right)\]</span> <span class="math display">\[\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)   \pm t_{n-2}^{1-\alpha/2}\;\;\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}\]</span></p>
<p>the expected value of new observation <span class="math inline">\(\hat{E}\left(Y\,|\,X=x_{new}\right)\)</span>. This expectation is regression line but because the estimated regression line is a function of the data, then the line isn’t the exactly the same as the true regression line. To reflect that, I want to calculate a confidence interval for where the true regression line should be.</p>
<p>I might instead be interested calculating a confidence interval for <span class="math inline">\(y_{new}\)</span>, which I will call a <em>prediction</em> interval in an attempt to keep from being confused with the confidence interval of the regression line. Because we have <span class="math display">\[y_{new}=\beta_{0}+\beta_{1}x_{new}+\epsilon_{new}\]</span></p>
<p>then my prediction interval will still be centered at <span class="math inline">\(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\)</span> but the the uncertainty should be the sum of the uncertainty associated with the estimates of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> and the additional variability associated with <span class="math inline">\(\epsilon_{new}\)</span>. In short, <span class="math display">\[\begin{aligned}
\hat{Var}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}+\epsilon\right)   
    &amp;=  \hat{Var}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)+\hat{Var}\left(\epsilon\right) \\
      &amp;=    \hat{\sigma}^{2}\left(\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}\right)+\hat{\sigma}^{2}
      \end{aligned}\]</span></p>
<p>and the <span class="math inline">\(StdErr\left(\right)\)</span> of a new observation will be</p>
<p><span class="math display">\[StdErr\left(\hat{y}_{new}\right)=\hat{\sigma}\sqrt{1+\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}\]</span></p>
<p>So the prediction interval for a new observation will be: <span class="math display">\[\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)\pm t_{n-2}^{1-\alpha/2}\;\;\hat{\sigma}\sqrt{1+\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}\]</span></p>
<p>To emphasize the difference between confidence regions (capturing where we believe the regression line to lay) versus prediction regions (where new data observations will lay) we note that as the sample size increases, the uncertainty as to where the regression line lays decreases, but the prediction intervals will always contain a minimum width due to the error associated with an individual observation. Below are confidence (red) and prediction (blue) regions for two different sample sizes.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>In general, you will not want to calculate the confidence intervals and prediction intervals by hand. Fortunately R makes it easy to calculate the intervals. The function <code>predict()</code> will calculate the point estimates along with confidence and prediction intervals. The function requires the <code>lm()</code> output along with an optional data frame (if you want to predict values not in the original data).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(setosa, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Sepal Length vs Sepal Width&#39;</span>)</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#fit the regression</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(Sepal.Width <span class="op">~</span><span class="st"> </span>Sepal.Length, <span class="dt">data=</span>setosa)

<span class="co"># display the first few predictions</span>
<span class="kw">head</span>( <span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>) )</code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 3.503062 3.427519 3.578604
## 2 3.343356 3.267122 3.419590
## 3 3.183650 3.086634 3.280666
## 4 3.103798 2.991890 3.215705
## 5 3.423209 3.350256 3.496162
## 6 3.742620 3.632603 3.852637</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict at x = 5.0</span>
<span class="kw">predict</span>(model, 
        <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>,                  <span class="co"># prediction Interval</span>
        <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">Sepal.Length =</span> <span class="fl">5.0</span>)) <span class="co"># at x=5</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 3.423209 2.902294 3.944123</code></pre>
<p>We can create a nice graph of the regression line and associated confidence and prediction regions using the following code in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ask for the confidence and prediction intervals</span>
conf.region &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;confidence&#39;</span>)
pred.region &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;prediction&#39;</span>)

<span class="co"># add them to my original data frame</span>
setosa &lt;-<span class="st"> </span>setosa <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">fit =</span> <span class="kw">fitted</span>(model),
          <span class="dt">conf.lwr =</span> conf.region[,<span class="dv">2</span>],
          <span class="dt">conf.upr =</span> conf.region[,<span class="dv">3</span>],
          <span class="dt">pred.lwr =</span> pred.region[,<span class="dv">2</span>],
          <span class="dt">pred.upr =</span> pred.region[,<span class="dv">3</span>])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make a nice plot</span>
<span class="kw">ggplot</span>(setosa) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(  <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width) ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(   <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>fit), <span class="dt">col=</span><span class="st">&#39;red&#39;</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>( <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">ymin=</span>conf.lwr, <span class="dt">ymax=</span>conf.upr), <span class="dt">fill=</span><span class="st">&#39;red&#39;</span>,  <span class="dt">alpha=</span>.<span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>( <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">ymin=</span>pred.lwr, <span class="dt">ymax=</span>pred.upr), <span class="dt">fill=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>)</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>It is worth noting that these confidence intervals are all point-wise confidence intervals. If I want to calculate confidence or prediction intervals for a large number of <span class="math inline">\(x_{new}\)</span> values, then I have to deal with the multiple comparisons issue. Fortunately this is easy to do in the simple linear regression case. Instead of using the <span class="math inline">\(t_{n-2}^{1-\alpha/2}\)</span> quantile in the interval formulas, we should use <span class="math inline">\(W=\sqrt{2*F_{1-\alpha,\,2,\,n-2}}\)</span>. Many books ignore this issue as does the <code>predict()</code> function in R.</p>
</div>
</div>
<div id="extrapolation" class="section level2">
<h2><span class="header-section-number">10.3</span> Extrapolation</h2>
<p>The data observed will inform a researcher about the relationship between the x and y variables, but only in the range for which you have data! Below are the winning times of the men’s 1500 meter Olympic race.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(men1500m, <span class="dt">package=</span><span class="st">&#39;HSAUR2&#39;</span>)
small &lt;-<span class="st"> </span>men1500m <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>( year <span class="op">!=</span><span class="st"> </span><span class="dv">1896</span> )  <span class="co"># Remove the 1896 Olympics</span>

<span class="co"># fit the model and get the prediction interval</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>( time <span class="op">~</span><span class="st"> </span>year, <span class="dt">data=</span>small )
small &lt;-<span class="st"> </span><span class="kw">cbind</span>(small, <span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;prediction&#39;</span>) )

<span class="kw">ggplot</span>(small, <span class="kw">aes</span>(<span class="dt">x=</span>year, <span class="dt">y=</span>time, <span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>( <span class="kw">aes</span>(<span class="dt">y=</span>fit), <span class="dt">col=</span><span class="st">&#39;red&#39;</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>( <span class="dt">fill=</span><span class="st">&#39;light blue&#39;</span>,  <span class="dt">alpha=</span>.<span class="dv">4</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>( <span class="dt">x=</span><span class="st">&#39;Year&#39;</span>, <span class="dt">y=</span><span class="st">&#39;Time (s)&#39;</span>, <span class="dt">title=</span><span class="st">&#39;Winning times of Mens 1500 m&#39;</span> ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>If we are interested in predicting the results of the 2008 and 2012 Olympic race, what would we predict?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(model, 
        <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">year=</span><span class="kw">c</span>(<span class="dv">2008</span>, <span class="dv">2012</span>)), 
        <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 208.1293 199.3971 216.8614
## 2 206.8451 198.0450 215.6453</code></pre>
<p>We can compare the predicted intervals with the time actually recorded by the winner of the men’s 1500m. In Beijing 2008, Rashid Ramzi from Brunei won the event in 212.94 seconds and in London 2012 Taoufik Makhloufi from Algeria won in 214.08 seconds. Both times are within the corresponding prediction intervals, but clearly the linear relationship must eventually change and therefore our regression could not possibly predict the winning time of the 3112 race.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(model, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">year=</span><span class="kw">c</span>(<span class="dv">3112</span>)), <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</code></pre></div>
<pre><code>##         fit       lwr       upr
## 1 -146.2973 -206.7705 -85.82402</code></pre>
</div>
<div id="checking-model-assumptions" class="section level2">
<h2><span class="header-section-number">10.4</span> Checking Model Assumptions</h2>
<p>As in the ANOVA analysis, we want to be able to check the model assumptions. To do this, we will examine the residuals <span class="math inline">\(e_{i}=y_{i}-\hat{y}_{i}\)</span> for normality using a QQ-plot as we did in ANOVA. To address the constant variance and linearity assumptions we will look at scatterplots of the residuals vs the fitted values <span class="math inline">\(\hat{y}_{i}\)</span>. For the regression to be valid, we want the scatterplot to show no discernible trend. There are two patterns that commonly show up that indicate a violation of the regression assumptions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2233</span>);
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>));
n &lt;-<span class="st"> </span><span class="dv">20</span>;
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">length=</span>n);
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Fitted=</span><span class="kw">c</span>(x,x,x),
  <span class="dt">Residual=</span><span class="kw">c</span>(<span class="kw">rnorm</span>(n,<span class="dv">0</span>,.<span class="dv">25</span>), <span class="kw">rnorm</span>(n,(<span class="dv">2</span><span class="op">*</span>x<span class="op">-</span><span class="dv">1</span>)<span class="op">^</span><span class="dv">2</span><span class="op">-</span>.<span class="dv">375</span>, .<span class="dv">2</span>), <span class="kw">rnorm</span>(n,<span class="dv">0</span>,x<span class="op">*</span>.<span class="dv">45</span>)), 
  <span class="dt">Type=</span><span class="kw">factor</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">each=</span>n), <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&#39;No Trend&#39;</span>, <span class="st">&#39;Non-Linear&#39;</span>, <span class="st">&#39;Non-Constant Variance&#39;</span>) ));
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>){
  index &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>n <span class="op">+</span><span class="st"> </span>n<span class="op">*</span>(i<span class="op">-</span><span class="dv">1</span>);
  <span class="kw">plot</span>(data<span class="op">$</span>Fitted[index], data<span class="op">$</span>Residual[index], 
       <span class="dt">xlab=</span><span class="st">&#39;Fitted&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Residual&#39;</span>, <span class="dt">main=</span>data<span class="op">$</span>Type[index[<span class="dv">1</span>]] );
  <span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>);
}</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>To illustrate this, we’ll consider the cherry tree dataset that comes with R. The goal will be predicting the volume of lumber produced by a cherry tree of a given diameter. The data are given in a dataset pre-loaded in R called <code>trees</code>.</p>
<p>Step one: Graph the data. The first step in a regression analysis is to graph the data and think about if a linear relationship makes sense.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(trees)  <span class="co"># 3 columns Girth, Height, Volume</span></code></pre></div>
<pre><code>##   Girth Height Volume
## 1   8.3     70   10.3
## 2   8.6     65   10.3
## 3   8.8     63   10.2
## 4  10.5     72   16.4
## 5  10.7     81   18.8
## 6  10.8     83   19.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(trees, <span class="kw">aes</span>(<span class="dt">x=</span>Girth, <span class="dt">y=</span>Volume)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Volume vs Girth&#39;</span>)</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Initially, it looks like a line is a pretty good description of this relationship.</p>
<p>Step two: Fit a regression and examine the diagnostic plots.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>( Volume <span class="op">~</span><span class="st"> </span>Girth, <span class="dt">data=</span>trees )
<span class="kw">autoplot</span>(model, <span class="dt">which=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>The normality assumption isn’t too bad, but there is a strong trend in the residual plot. The curvature we see in the residual group is present in the original scatterplot, but it is more obvious. At this point I would think about a slightly more complicated model, e.g. should we include height in the model or perhaps <code>Girth^2</code>? The implications of both of these possibilities will be explored in STA 571 but for now we’ll just continue using the model we have.</p>
<p>Step three: Plot the data and the regression model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trees &lt;-<span class="st"> </span><span class="kw">cbind</span>( trees, <span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;confidence&#39;</span>) )
<span class="kw">head</span>(trees)  <span class="co"># now we have the fit, lwr, upr columns</span></code></pre></div>
<pre><code>##   Girth Height Volume       fit       lwr       upr
## 1   8.3     70   10.3  5.103149  2.152294  8.054004
## 2   8.6     65   10.3  6.622906  3.799685  9.446127
## 3   8.8     63   10.2  7.636077  4.896577 10.375578
## 4  10.5     72   16.4 16.248033 14.156839 18.339228
## 5  10.7     81   18.8 17.261205 15.235884 19.286525
## 6  10.8     83   19.7 17.767790 15.774297 19.761284</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(trees, <span class="kw">aes</span>(<span class="dt">x=</span>Girth)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>( <span class="kw">aes</span>( <span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">alpha=</span>.<span class="dv">4</span>, <span class="dt">fill=</span><span class="st">&#39;pink&#39;</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>( <span class="kw">aes</span>(<span class="dt">y=</span>fit), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Volume)) </code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>In this graph we see that we underestimate the volume for small girths, overestimate for medium values, and underestimate for large girths. So we see the same pattern of the residuals in this graph as we saw in the residual graph. While the model we’ve selected isn’t as good as it could be, this isn’t horribly bad and might suffice for a first pass</p>
<blockquote>
<p>“All models are wrong, but some are useful.” George Box.</p>
</blockquote>
<p>Step four: Evaluate the model coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Volume ~ Girth, data = trees)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.065 -3.107  0.152  3.495  9.587 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -36.9435     3.3651  -10.98 7.62e-12 ***
## Girth         5.0659     0.2474   20.48  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.252 on 29 degrees of freedom
## Multiple R-squared:  0.9353, Adjusted R-squared:  0.9331 
## F-statistic: 419.4 on 1 and 29 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) -43.825953 -30.060965
## Girth         4.559914   5.571799</code></pre>
<p>From the summary output, we can see several things:</p>
<ol style="list-style-type: decimal">
<li><p>The intercept term <span class="math inline">\(\hat{\beta}_{0}\)</span> is significantly different than zero. While we should expect that a tree with zero girth should have zero volume, our model predicts a volume of -36.9, which is obviously ridiculous. I’m not too worried about this because we have no data from trees that small and the intercept is quite the extrapolation from the range of Girth values we actually have. This is primarily being driven by the real relationship having curvature and our model has no curvature in it. So long as we don’t use this model to predict values too far away from our data points, I’m happy.</p></li>
<li><p>The slope is statistically significantly positive. We see an estimate an increase of 5 units of Volume for every 1 unit increase in Girth.</p></li>
<li><p>The estimate <span class="math inline">\(\hat{\sigma}\)</span> is given by the residual standard error and is 4.252 and that is interpreted as the typical distance away from the regression line.</p></li>
<li><p>The R-sq value gives the amount of variability in the data that is explained by the regression line as <span class="math inline">\(93.5\%\)</span>. So the variable Girth explains a huge amount of the variability in volume of lumber a tree produces.</p></li>
<li><p>Finally, the F-test is comparing the complex vs the simple model, which in this case, reduces to just testing if the slope term, <span class="math inline">\(\beta_{1}\)</span>, could be zero. In simple regression, the F-statistic is the square of the t-statistic for testing the slope. That is, F-statistic = <span class="math inline">\(419.4 = 20.48^{2}\)</span>. The p-values are the same for the two tests because they are testing exactly the same hypothesis.</p></li>
</ol>
</div>
<div id="common-problems" class="section level2">
<h2><span class="header-section-number">10.5</span> Common Problems</h2>
<div id="influential-points" class="section level3">
<h3><span class="header-section-number">10.5.1</span> Influential Points</h3>
<p>Sometimes a dataset will contain one observation that has a large effect on the outcome of the model. Consider the following datasets where the red denotes a highly influential point and the red line is the regression line including the point.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>The question of what to do with influential points is not easy to answer. Sometimes these are data points that are a result of lab technician error and should be removed. Sometimes they are the result of an important process that is not well understood by the researcher. It is up to the scientist to figure out which is the case and take appropriate action.</p>
<p>One solution is to run the analysis both with and without the influential point and see how much it affects your inferences.</p>
</div>
<div id="transformations" class="section level3">
<h3><span class="header-section-number">10.5.2</span> Transformations</h3>
<p>When the normality or constant variance assumption is violated, sometimes it is possible to transform the data to make it satisfy the assumption. Often times count data is analyzed as log(count) and weights are analyzed after taking a square root or cube root transform.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>We have the option of either transforming the x-variable or transforming the y-variable or possibly both. One thing to keep in mind, however, is that transforming the x-variable only effects the linearity of the relationship. Transforming the y-variable effects both the linearity and the variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="op">-</span><span class="dv">838</span>)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))
n &lt;-<span class="st"> </span><span class="dv">40</span>
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">30</span>, <span class="dt">length=</span>n);
y &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">30</span><span class="op">*</span><span class="kw">exp</span>((<span class="dv">30</span><span class="op">-</span>x)<span class="op">/</span><span class="dv">10</span>) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">sd=</span><span class="dv">20</span>)
y &lt;-<span class="st"> </span><span class="kw">abs</span>(y)
<span class="kw">plot</span>(x,y); <span class="kw">abline</span>(<span class="kw">coef</span>(<span class="kw">lm</span>(y<span class="op">~</span>x)));
<span class="kw">plot</span>(x, <span class="kw">log</span>(y)); <span class="kw">abline</span>(<span class="kw">coef</span>(<span class="kw">lm</span>(<span class="kw">I</span>(<span class="kw">log</span>(y))<span class="op">~</span>x)));
<span class="kw">plot</span>(x<span class="op">^</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>), y); <span class="kw">abline</span>(<span class="kw">coef</span>(<span class="kw">lm</span>(y<span class="op">~</span><span class="kw">I</span>(x<span class="op">^</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)))));</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)</code></pre></div>
<p>Unfortunately it is not always obvious what transformation is most appropriate. The Box-Cox family of transformations for the y-variable is <span class="math display">\[ f(y\,|\,\lambda) =   \begin{cases}
    y^{\lambda} &amp; \;\;\textrm{if}\,\,\lambda\ne0\\
    \log y &amp; \;\;\textrm{if}\,\,\lambda=0
  \end{cases}\]</span> which includes squaring (<span class="math inline">\(\lambda=2\)</span>), square root (<span class="math inline">\(\lambda=1/2\)</span>) and as <span class="math inline">\(\lambda \to 0\)</span> the transformation converges to <span class="math inline">\(\log y\)</span>. (To do this correctly we should define the transformation in a more complicated fashion, but that level of detail is unnecessary here.) The transformation is selected by looking at the profile log-likelihood value of different values of <span class="math inline">\(\lambda\)</span> and we want to use the <span class="math inline">\(\lambda\)</span> that maximizes the log-likelihood.</p>
<p>Of course, we also want to use a transformation that isn’t completely obscure and is commonly used in the scientific field, so square roots, reciprocals, and logs are preferred.</p>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(mydata)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    40 obs. of  2 variables:
##  $ x: num  0 0.769 1.538 2.308 3.077 ...
##  $ y: num  2 3.08 2.92 4.17 5.44 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MASS<span class="op">::</span><span class="kw">boxcox</span>(y<span class="op">~</span>x, <span class="dt">data=</span>mydata, <span class="dt">plotit=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><img src="10_Regression_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>Here we see the resulting confidence interval for <span class="math inline">\(\lambda\)</span> contains 0, so a <span class="math inline">\(\log\)</span> transformation would be most appropriate.</p>
<p>Unfortunately there isn’t a matching procedure for deciding how to transform the <span class="math inline">\(x\)</span> covariate. Usually we spend a great deal of time trying different transformations and see how they affect the scatterplot and using transformations that are common in whatever field the researcher is working in.</p>
<p>In general, deciding on a transformation to use is often a trade-off between statistical pragmatism and interpretability. In cases that a transformation is not possible, or the interpretation is difficult, it is necessary to build more complicated models that are hopefully interpretable. We will explore these issues in great length in STA 571.</p>
</div>
</div>
<div id="exercises-9" class="section level2">
<h2><span class="header-section-number">10.6</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>Use the following data below to answer the questions below</p>
<table>
<tbody>
<tr class="odd">
<td align="center"><strong>x</strong></td>
<td align="center">3</td>
<td align="center">8</td>
<td align="center">10</td>
<td align="center">18</td>
<td align="center">23</td>
<td align="center">28</td>
</tr>
<tr class="even">
<td align="center"><strong>y</strong></td>
<td align="center">14</td>
<td align="center">28</td>
<td align="center">43</td>
<td align="center">62</td>
<td align="center">79</td>
<td align="center">86</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li><p>Plot the data in a scatter plot. <em>The following code might be useful:</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read in the data</span>
p1.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">x =</span> <span class="kw">c</span>( <span class="dv">3</span>,  <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">23</span>, <span class="dv">28</span>),
  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">14</span>, <span class="dv">28</span>, <span class="dv">43</span>, <span class="dv">62</span>, <span class="dv">79</span>, <span class="dv">86</span>)  )

<span class="co"># make a nice graph</span>
<span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(p1.data, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div></li>
<li><p>We will first calculate the regression coefficients and their estimated standard deviations by hand (mostly).</p>
<ol style="list-style-type: lower-roman">
<li>Use R to confirm that that the following summary statistics are correct:</li>
</ol>
<table>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\bar{x}=15\)</span></td>
<td align="center"><span class="math inline">\(s_x=9.59\)</span></td>
<td align="center"><span class="math inline">\(S_{xx}=460\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\bar{y}=52\)</span></td>
<td align="center"><span class="math inline">\(s_y=28.59\)</span></td>
<td align="center"><span class="math inline">\(r = 0.9898\)</span></td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-roman">
<li><p>Using the above statistics, by hand calculate the estimates <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>.</p></li>
<li><p>For each data point, by hand calculate the predicted value <span class="math inline">\(\hat{y}_{i}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{i}\)</span>.</p></li>
<li><p>For each data point, by hand calculate the estimated error term <span class="math inline">\(\hat{\epsilon}_{i}=y_{i}-\hat{y}_{i}\)</span>.</p></li>
<li><p>Calculate the MSE for the complex model. Using the MSE, what is <span class="math inline">\(\hat{\sigma}\)</span>?</p></li>
<li><p>By hand, calculate the estimated standard deviation (which is often called the standard error) of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>.</p></li>
</ol></li>
<li><p>Use the R function <code>lm()</code> to fit a regression to these data.</p>
<ol style="list-style-type: lower-roman">
<li><p>Using the <code>predict()</code> function, confirm your hand calculation of the <span class="math inline">\(\hat{y}_{i}\)</span> values.</p></li>
<li><p>Using the <code>resid()</code> function, confirm your hand calculation of the <span class="math inline">\(\hat{\epsilon}_{i}\)</span> terms.</p></li>
<li><p>Using the <code>summary()</code> function, confirm your hand calculations of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> and their standard errors.</p></li>
</ol></li>
<li><p>Again using R’s built in functions, give a 95% confidence interval for <span class="math inline">\(\beta_{1}\)</span>.</p></li>
<li><p>Using the appropriate R output, test the hypothesis <span class="math inline">\(H_{0}:\;\beta_{1}=0\)</span> versus the alternative <span class="math inline">\(H_{a}:\;\beta_{1} \ne 0\)</span>.</p></li>
<li><p>Give the R^{2} value for this regression.</p></li>
<li><p>What is the typical distance to the regression line?</p></li>
<li><p>Create a nice graph of the regression line and the confidence interval for the true relationship using the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make a nice graph</span>
<span class="kw">ggplot</span>(p1.data, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&#39;lm&#39;</span>)</code></pre></div>
<p>Often I want to create the confidence region myself (perhaps to use a prediction interval instead of a confidence interval), and we could use the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
model &lt;-<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>p1.data )

p1.data &lt;-<span class="st"> </span>p1.data <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">yhat =</span> <span class="kw">predict</span>(model),
          <span class="dt">lwr  =</span> <span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;confidence&#39;</span>)[,<span class="dv">2</span>],
          <span class="dt">upr  =</span> <span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;confidence&#39;</span>)[,<span class="dv">3</span>]  )

<span class="co"># make a nice graph</span>
<span class="kw">ggplot</span>(p1.data, <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>( <span class="kw">aes</span>(<span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">fill=</span><span class="st">&#39;pink&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">2</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(   <span class="kw">aes</span>(   <span class="dt">y=</span>yhat), <span class="dt">color=</span><span class="st">&#39;green&#39;</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(  <span class="kw">aes</span>(   <span class="dt">y=</span>y   ), <span class="dt">color=</span><span class="st">&#39;black&#39;</span> )</code></pre></div></li>
</ol></li>
<li><p>Olympic track and field records are broken practically every Olympics. The following is output comparing the gold medal winning performance in the men’s long jump (in inches) versus the years 00 to 84. (In this data set, the year 00 represents 1900, and 84 represents 1984. This is a pre Y2K dataset.) There were <span class="math inline">\(n=19\)</span> Olympic games in that period.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Fill in the blanks in the following summary and anova tables:</p>
<p>Summary:</p>
<table>
<thead>
<tr class="header">
<th align="center">Coefficients</th>
<th align="center">Estimate</th>
<th align="center">Std Error</th>
<th align="center">t-value</th>
<th align="center">$Pr(&gt;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">(Intercept)</td>
<td align="center">283.45</td>
<td align="center">4.28</td>
<td align="center"></td>
<td align="center">&lt; 2e-16</td>
</tr>
<tr class="even">
<td align="center">Year</td>
<td align="center">0.613</td>
<td align="center">0.0841</td>
<td align="center">7.289</td>
<td align="center">1.27e-06</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="60%" />
<col width="39%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Residual Standard Error = <span class="math inline">\(\;\;\;\;\;\;\;\;\;\;\)</span></td>
<td align="center">R-sq = <span class="math inline">\(\;\;\;\;\;\;\;\;\;\;\)</span></td>
</tr>
</tbody>
</table>
<p>Analysis of Variance:</p>
<table>
<thead>
<tr class="header">
<th align="center">Source</th>
<th align="center">df</th>
<th align="center">Sum Sq</th>
<th align="center">Mean Sq</th>
<th align="center">F-value</th>
<th align="center">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Year</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">Residuals</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">95.19</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center">18</td>
<td align="center">6673.2</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table></li>
</ol></li>
<li><p>Ott &amp; Longnecker 11.45&amp;47 - In the preliminary studies of a new drug, a pharmaceutical firm needs to obtain information on the relationship between the dose level and potency of the drug. In order to obtain this information, a total of 18 test tubes are inoculated with a virus culture and incubated for an appropriate period of time. Three test tubes are randomly assigned to each of 6 different dose levels. The 18 test tubes are then injected with the randomly assigned dose level of the drug. the measured response is the protective strength of the drug against the virus culture. Due to a problem with a few of the test tubes, only 2 responses were obtained for dose levels 4,8, and 16. The data are:</p>
<table>
<tbody>
<tr class="odd">
<td align="center">Dose</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">4</td>
<td align="center">4</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center">16</td>
<td align="center">16</td>
<td align="center">16</td>
<td align="center">32</td>
<td align="center">32</td>
<td align="center">64</td>
<td align="center">64</td>
<td align="center">64</td>
</tr>
<tr class="even">
<td align="center">Response</td>
<td align="center">5</td>
<td align="center">7</td>
<td align="center">3</td>
<td align="center">10</td>
<td align="center">14</td>
<td align="center">15</td>
<td align="center">17</td>
<td align="center">20</td>
<td align="center">21</td>
<td align="center">19</td>
<td align="center">23</td>
<td align="center">29</td>
<td align="center">28</td>
<td align="center">31</td>
<td align="center">30</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>We will first fit a regression model to the raw data.
<ol style="list-style-type: lower-roman">
<li>Plot the data and comment on the relationship between the covariate and response.</li>
<li>Fit a linear regression model to these data using the lm() function.</li>
<li>Examine the plot of the residuals vs fitted values. Does there appear to be a problem? Explain.</li>
</ol></li>
<li>Often in drug evaluations, a logarithmic transformation of the dose level will yield a linear relationship between the response variable and the independent variable. Let <span class="math inline">\(x_{i}=\log\left(dose_{i}\right)\)</span> (where log is the natural log). Notice that because the constant variance assumption seems to be met, I don’t wish to transform <span class="math inline">\(y\)</span>.
<ol style="list-style-type: lower-roman">
<li>Plot the response of the drug vs the natural log of the dose levels. Does it appear that a linear model is appropriate?</li>
<li>Fit the linear regression model to these data.</li>
<li>From a plot of the residuals vs the fitted values, does the linear model seem appropriate?</li>
<li>Examine the QQplot of the residuals vs the theoretical normal quantiles. Does the normality assumption appear to be violated? Also perform a Shapiro-Wilks test on the residuals to test of a statistically significant difference from normality. Comment on these results.</li>
<li>What is change in the response variable for every one unit change in log(dose)?</li>
<li>Give a <span class="math inline">\(95\%\)</span> confidence interval for the y-intercept and slope parameters. Is the log(dose) level a statistically significant predictor of the response?</li>
</ol></li>
</ol></li>
</ol>
<!--chapter:end:10_Regression.Rmd-->
</div>
</div>
<div id="resampling-linear-models" class="section level1">
<h1><span class="header-section-number">11</span> Resampling Linear Models</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(ggfortify)
<span class="kw">library</span>(car)       <span class="co"># for the Boot function</span>
<span class="kw">library</span>(boot)      <span class="co"># for the boot function</span></code></pre></div>
<p>The last several chapters have introduced a number of parametric models where we assume that the error terms are normally distributed. <span class="math display">\[\begin{aligned}
  \textrm{One-sample t-test:}   &amp; \;\;\; Y_{i}=\mu+\epsilon_{i}                      &amp; \textrm{where} &amp; \;\;\;\epsilon_{i}\stackrel{iid}{\sim}N\left(0,\sigma\right) \\
  \textrm{Two-sample t-test:}   &amp;   \;\;\;Y_{ij}=\mu_{i}+\epsilon_{ij}                &amp; \textrm{where} &amp; \;\;\;\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma\right)\;\;\;i\in\left\{ 1,2\right\} \\
  \textrm{ANOVA:}                 &amp; \;\;\;Y_{ij}=\mu_{i}+\epsilon_{ij}                &amp; \textrm{where} &amp; \;\;\;\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma\right)\;\;\;i\in\left\{ 1,2,\dots,k\right\} \\
  \textrm{Regression:}          &amp; \;\;\;Y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i} &amp; \textrm{where} &amp; \;\;\;\epsilon_{i}\stackrel{iid}{\sim}N\left(0,\sigma\right)
  \end{aligned}\]</span></p>
<p>We developed hypothesis tests and confidence intervals for the model parameters assuming that the error terms were normally distributed and, in the event that they are normally distributed, those tests and confidence intervals are the best we can do. However, if the errors are not normally distributed, what should we do?</p>
<p>Previously we used bootstrapping to estimate the sampling distribution of the sampling statistic when we didn’t know the distribution. We will use the same bootstrapping method, but we’ll simplify all of the above cases to the the same simple linear model <span class="math display">\[Y_{i}=E\left(Y_{i}\right)+\epsilon_{i}\;\;\;\textrm{where}\;\;\epsilon_{i}\stackrel{iid}{\sim}N\left(0,\sigma\right)\]</span> and <span class="math inline">\(E\left(Y_{i}\right)\)</span> takes on some form of the parameters depending on the model specified. It turns out that R can do all of these analyses using the same <code>lm()</code> function we used in for regression.</p>
<div id="using-lm-for-many-analyses" class="section level2">
<h2><span class="header-section-number">11.1</span> Using <code>lm()</code> for many analyses</h2>
<div id="one-sample-t-tests" class="section level3">
<h3><span class="header-section-number">11.1.1</span> One-sample t-tests</h3>
<p>In this model we are concerned with testing <span class="math display">\[\begin{aligned} 
  H_{0}: &amp;  \;\;    \mu=\mu_{0}\\
  H_{a}: &amp;  \;\;    \mu\ne\mu_{0}
  \end{aligned}\]</span> for some <span class="math inline">\(\mu_{0}\)</span>. For example, suppose we have the following data and we want to test <span class="math inline">\(H_{0}:\mu=5 vs H_{a}:\mu\ne5\)</span>. The R code we used previously was</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How we previously did a t.test</span>
test.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">y=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">13</span>) )
<span class="kw">t.test</span>( test.data<span class="op">$</span>y, <span class="dt">mu=</span><span class="dv">5</span> )</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  test.data$y
## t = 0.79361, df = 5, p-value = 0.4634
## alternative hypothesis: true mean is not equal to 5
## 95 percent confidence interval:
##  2.387727 9.945607
## sample estimates:
## mean of x 
##  6.166667</code></pre>
<p>but we can just as easily consider this a linear model with only an intercept term.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>test.data)
<span class="kw">summary</span>(m1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ 1, data = test.data)
## 
## Residuals:
##       1       2       3       4       5       6 
## -3.1667 -1.1667 -2.1667 -1.1667  0.8333  6.8333 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    6.167      1.470   4.195  0.00853 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.601 on 5 degrees of freedom</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(m1)</code></pre></div>
<pre><code>##                2.5 %   97.5 %
## (Intercept) 2.387727 9.945607</code></pre>
<p>Notice that we get the same point estimate and confidence interval for <span class="math inline">\(\mu\)</span>, but the p-value is different because the <code>t.test()</code> p-value is testing <span class="math inline">\(H_{0}:\;\mu=5\)</span> vs <span class="math inline">\(H_{a}:\;\mu\ne5\)</span> while the <code>lm()</code> function is testing <span class="math inline">\(H_{0}:\;\mu=0\)</span> vs <span class="math inline">\(H_{a}:\;\mu\ne0\)</span>.</p>
<p>If we really want the correct p-value, we should test if the difference between the <span class="math inline">\(y\)</span> variable and 5 is zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">-</span><span class="dv">5</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>test.data)
<span class="kw">summary</span>(m1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y - 5 ~ 1, data = test.data)
## 
## Residuals:
##       1       2       3       4       5       6 
## -3.1667 -1.1667 -2.1667 -1.1667  0.8333  6.8333 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)    1.167      1.470   0.794    0.463
## 
## Residual standard error: 3.601 on 5 degrees of freedom</code></pre>
</div>
<div id="two-sample-t-tests" class="section level3">
<h3><span class="header-section-number">11.1.2</span> Two-sample t-tests</h3>
<p>This model is concerned with testing <span class="math display">\[\begin{aligned} 
H_{0}: &amp;    \;\;    \mu_{1}=\mu_{2} \\
H_{a}: &amp;    \;\;    \mu_{1}\ne\mu_{2}
\end{aligned}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How we previously did a t.test</span>
test.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">y=</span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">4</span>,  <span class="dv">5</span>,  <span class="dv">7</span>, <span class="dv">13</span>, 
                             <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">4</span>, <span class="dv">16</span>, <span class="dv">12</span>, <span class="dv">13</span> ),
                         <span class="dt">group=</span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&#39;A&#39;</span>,<span class="st">&#39;B&#39;</span>), <span class="dt">each=</span><span class="dv">6</span>) )

<span class="kw">t.test</span>( y <span class="op">~</span><span class="st"> </span>group, <span class="dt">data=</span>test.data, <span class="dt">var.equal=</span><span class="ot">TRUE</span> )</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  y by group
## t = -1.838, df = 10, p-value = 0.09591
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -9.2176608  0.8843275
## sample estimates:
## mean in group A mean in group B 
##        6.166667       10.333333</code></pre>
<p>This analysis gave use the mean of each group and the confidence interval for the difference <span class="math inline">\(\mu_{2}-\mu_{1}\)</span>. We could get the same analysis an ANOVA with <span class="math inline">\(k=2\)</span> groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>group, <span class="dt">data=</span>test.data)
<span class="kw">summary</span>(m2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ group, data = test.data)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.333 -2.208 -1.167  1.917  6.833 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    6.167      1.603   3.847  0.00323 **
## groupB         4.167      2.267   1.838  0.09591 . 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.926 on 10 degrees of freedom
## Multiple R-squared:  0.2525, Adjusted R-squared:  0.1778 
## F-statistic: 3.378 on 1 and 10 DF,  p-value: 0.09591</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(m2)</code></pre></div>
<pre><code>## (Intercept)      groupB 
##    6.166667    4.166667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(m2)</code></pre></div>
<pre><code>##                  2.5 %   97.5 %
## (Intercept)  2.5950745 9.738259
## groupB      -0.8843275 9.217661</code></pre>
<p>Aside from <code>t.test()</code> reporting <span class="math inline">\(\mu_{2}-\mu_{1}\)</span> while the <code>lm()</code> function calculates <span class="math inline">\(\mu_{1}-\mu_{2}\)</span>, the estimates are identical.</p>
</div>
</div>
<div id="creating-simulated-data" class="section level2">
<h2><span class="header-section-number">11.2</span> Creating Simulated Data</h2>
<p>The basic goal of statistics is that we are interested in some population (which is described by some parameter <span class="math inline">\(\mu,\delta,\tau,\beta\)</span>, or generally, <span class="math inline">\(\theta\)</span>) and we take a random sample of size <span class="math inline">\(n\)</span> from the population of interest and we truly believe that the sample is representative of the population of interest. Then we use some statistic of the data <span class="math inline">\(\hat{\theta}\)</span> as an estimate <span class="math inline">\(\theta\)</span>. However we know that this estimates, <span class="math inline">\(\hat{\theta}\)</span>, vary from sample to sample. Previously we’ve used that the Central Limit Theorem gives <span class="math display">\[\hat{\theta}\stackrel{\cdot}{\sim}N\left(\theta,\,\sigma_{\hat{\theta}}\right)\]</span> to construct confidence intervals and perform hypothesis tests, but we don’t necessarily like this approximation. If we could somehow take repeated samples (call these repeated samples <span class="math inline">\(\mathbb{Y}_{j}\)</span> for <span class="math inline">\(j\in1,2,\dots,M\)</span>) from the population we would understand the distribution of <span class="math inline">\(\hat{\theta}\)</span> by just examining the distribution of many observed values of <span class="math inline">\(\hat{\theta}_{j}\)</span> where <span class="math inline">\(\hat{\theta}_{j}\)</span> is the statistic calculated from the ith sample data <span class="math inline">\(\mathbb{Y}_{j}\)</span>.</p>
<p>However, for practical reasons, we can’t just take 1000s of samples of size n from the population. However, because we truly believe that <span class="math inline">\(\mathbb{Y}\)</span> is representative of the entire population, then our best guess of what the population is just many repeated copies of our data.</p>
<p>Suppose we were to sample from a population of shapes, and we observed 4/9 of the sample were squares, 3/9 were circles, and a triangle and a diamond. Then our best guess of what the population that we sampled from was a population with 4/9 squares, 3/9 circles, and 1/9 of triangles and diamonds.</p>
<pre><code>## Loading required package: grid</code></pre>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Using this approximated population (which is just many many copies of our sample data), we can take many samples of size <span class="math inline">\(n\)</span>. We denote these bootstrap samples as <span class="math inline">\(\mathbb{Y}_{j}^{*}\)</span>, where the star denotes that the sample was taken from the approximate population, not the actual population. From each bootstrap sample <span class="math inline">\(\mathbb{Y}_{j}^{*}\)</span> a statistic of interest can be taken <span class="math inline">\(\hat{\theta}_{j}^{*}\)</span>.</p>
<p>Because our approximate population is just an infinite number of copies of our sample data, then sampling from the approximate population is equivalent to sampling with replacement from our sample data. If I take <span class="math inline">\(n\)</span> samples from <span class="math inline">\(n\)</span> distinct objects with replacement, then the process can be thought of as mixing the <span class="math inline">\(n\)</span> objects in a bowl and taking an object at random, noting which it is, replace it into the bowl, and then draw the next sample. Practically, this means some objects will be selected more than once and some will not be chosen at all. To sample our observed data with replacement, we’ll use the <code>resample()</code> function in the <code>mosaic</code> package. We see that some rows will be selected multiple times, and some will not be selected at all.</p>
<div id="observational-studies-vs-designed-experiments" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Observational Studies vs Designed Experiments</h3>
<p>The process of collecting data is a time consuming and laborious process but is critical to our understanding of the world. The fundamental goal is to collect a sample of data that is representative of the population of interest and can provide insight into the scientific question at hand. There are two primary classes about how this data could be gathered, observational studies and designed experiments.</p>
<p>In an observational study, a population is identified and a random sample of individuals are selected to be in the sample. Then each subject in the sample has explanatory and response variables measured (fish are weighed and length recorded, people asked their age, gender, occupation etc). The critical part of this data collection method is that the random selection from the population is done in a fashion so that each individual in the population could potentially be in the sample and there is no systematic exclusion of certain parts of the population.</p>
<p><em>Simple Random Samples</em> - Suppose that we could generate a list of every individual in the population and then we were to randomly select n of those to be our sample. Then each individual would have an equal chance to be in the sample and this selection scheme should result in sample data that is representative of the population of interest. Often though, it is difficult to generate a list of every individual, but other proxies might work. For example if we wanted to understand cougar behavior in the Grand Canyon, we might divide the park up into 100 regions and then random select 20 of those regions to sample and observe whatever cougar(s) are in that region.</p>
<p><em>Stratified Random Samples</em> - In a stratified random sample, the population can be broken up into different strata and we perform a simple random sample within each strata. For example when sampling lake fish, we might think about the lake having deep and shallow/shore water strata and perhaps our sampling technique is different for those two strata (electro-fishing on shore and trawling in the deep sections). For human populations, we might stratify on age and geographic location (older retired people will answer the phone more readily than younger people). For each of the strata, we often have population level information about the different strata (proportion of the lake that is deep water versus shallow, or proportion of the population 20-29, 30-39, etc. and sample each strata accordingly (e.g. if shallow water is 40% of the fish habitat, then 40% of our sampling effort is spent in the shallows).</p>
<p>Regardless of sample type, the key idea behind an observational study is that we don’t apply a treatment to the subject and then observe a response. While we might annoy animal or person, we don’t do any long-term manipulations. Instead the individuals are randomly selected and then observed, and it is the random selection from the population that results in a sample that is representative of the population.</p>
<p><em>Designed Experiments</em> - In an experimental setting, the subjects are taken from the population (usually not at random but rather by convenience) and then subjected to some treatments and we observe the individuals response to the treatment. There will usually be several levels of the treatment and there often is a control level. For example, we might want to understand how to maximize the growth of a type of fungus for a pharmaceutical application and we consider applying different nutrients to the substrate (nothing, +phosphorus, +nitrogen, +both). Another example is researchers looking at the efficacy of smoking cessation methods and taking a set of willing subjects and having them try different methods (no help, nicotine patches, nicotine patches and a support group). There might be other covariates that we expect might affect the success rate (individuals age, length of time smoking, gender) and we might make sure that our study include people in each of these groups (we call these blocks in the experimental design terminology, but they are equivalent to the strata in the observational study terminology). Because even within blocks, we expect variability in the success rates due to natural variation, we randomize the treatment assignment to the individual and it is this randomization that addresses any unrecognized lurking variables that also affect the response.</p>
<p>A designed experiment is vastly superior to an observational experiment because the randomization of the treatment accounts for variables that the researcher might not even suspect to be important. A nice example of the difference between observational studies and experiments is a set of studies done relating breast cancer and hormone replacement therapy (HRT) drugs used by post-menopausal women. Initial observational studies that looked at the rates of breast cancer showed that women taking HRT had lower rates of breast cancer. When these results were first published, physicians happily recommended HRT to manage menopause symptoms and to decrease risk of breast cancer. Unfortunately subsequent observational studies showed a weaker effect and among some populations there was an increase in breast cancer. To answer the question clearly, a massive designed experiment was undertaken where women would be randomly assigned either a placebo or the actual HRT drugs. This study conclusively showed that HRT drugs increased the risk of breast cancer.</p>
<p>Why was there a disconnect between the original observational studies and the experiment? The explanation given is that there was a lurking variable that the observational studies did not control for… socio-economic class. There are many drivers of breast cancer and some of them are strongly correlated with socio-economic class such as where you live (in a polluted area or not). Furthermore because HRT was initially only to relieve symptoms of menopause, it wasn’t “medically necessary” and insurance didn’t cover it and so mainly wealthy women (with already lower risk for breast cancer) took the HRT drugs and the simple association between lower breast cancer risk and HRT was actually the effect of socio-economic status. By randomly assigning women to the placebo and HRT groups, high socio-economic women ended up in both groups. So even if there was some other lurking variable that the researchers didn’t consider, the randomization would cause the unknown variable to be evenly distributed in the placebo and HRT groups.</p>
<p>Because the method of randomization is so different between observational studies and designed experiments, we should make certain that our method of creating bootstrap data sets respects that difference in randomization. So if there was some constraint on the data when it was originally taken, we want the bootstrap datasets to obey that same constraint. If our study protocol was to collect a sample of <span class="math inline">\(n_{1}=10\)</span> men and <span class="math inline">\(n_{2}=10\)</span> women, then we want our bootstrap samples to have <span class="math inline">\(10\)</span> men and <span class="math inline">\(10\)</span> women. If we designed an experiment with <span class="math inline">\(25\)</span> subjects to test the efficacy of a drug and chose to administer doses of <span class="math inline">\(5, 10, 20, 40,\)</span> and <span class="math inline">\(80\)</span> mg with each five subjects for each dose level, then we want those same dose levels to show up in the bootstrap datasets.</p>
<p>There are two common approaches, <em>case resampling</em> and <em>residual resampling</em>. In case re-sampling, we consider the data <span class="math inline">\(\left(x_{i,}y_{i}\right)\)</span> pairs as one unit and when creating a bootstrap sample, we re-sample those pairs, but if the <span class="math inline">\(i\)</span>th data point is included in the bootstrap sample, then it is included as the <span class="math inline">\(\left(x_{i,}y_{i}\right)\)</span> pair. In contrast, residual re-sampling is done by first fitting a model to the data, finding the residual values, re-sampling those residuals and then adding those bootstrap residuals to the predicted values <span class="math inline">\(\hat{y}_{i}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Testing.Data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">9</span>),
  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">7</span>,<span class="dv">7</span>,<span class="dv">11</span>))
Testing.Data</code></pre></div>
<pre><code>##   x  y
## 1 3  3
## 2 5  7
## 3 7  7
## 4 9 11</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Case resampling </span>
Boot.Data &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">resample</span>(Testing.Data)
Boot.Data</code></pre></div>
<pre><code>##     x  y orig.id
## 1   3  3       1
## 4   9 11       4
## 2   5  7       2
## 2.1 5  7       2</code></pre>
<p>Notice that we’ve sampled <span class="math inline">\(\left\{ x=5,y=7\right\}\)</span> twice and did not get the <span class="math inline">\(\left\{ 7,7\right\}\)</span> data point.</p>
<p>Residual sampling is done by re-sampling the residuals and calling them <span class="math inline">\(\hat{\epsilon}^{*}\)</span> and then the new y-values will be <span class="math inline">\(y_{i}^{*}=\hat{y}_{i}+\hat{\epsilon}_{i}^{*}\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Residual resampling</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>Testing.Data)
Boot.Data &lt;-<span class="st"> </span>Testing.Data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">fit =</span> <span class="kw">fitted</span>(model),
          <span class="dt">resid =</span> <span class="kw">resid</span>(model),
          <span class="dt">resid.star =</span> mosaic<span class="op">::</span><span class="kw">resample</span>(resid),
          <span class="dt">y.star =</span> fit <span class="op">+</span><span class="st"> </span>resid.star )
Boot.Data</code></pre></div>
<pre><code>##   x  y  fit resid resid.star y.star
## 1 3  3  3.4  -0.4       -1.2    2.2
## 2 5  7  5.8   1.2       -1.2    4.6
## 3 7  7  8.2  -1.2       -0.4    7.8
## 4 9 11 10.6   0.4        1.2   11.8</code></pre>
<p>Notice that the residuals re-sampling results in a data set where each of the x-values is retained, but a new y-value (possibly not seen in the original data) is created from the predicted value <span class="math inline">\(\hat{y}\)</span> and a randomly selected residual.</p>
<p>In general when we design an experiment, we choose which x-values we want to look at and so the bootstrap data should have those same x-values we chose. So for a designed experiment, we typically will create bootstrap data sets via residual re-sampling. For observational studies, we’ll create the bootstrap data sets via case re-sampling. In both cases if there is a blocking or strata variable to consider, we will want to do the re-sampling within the block/strata.</p>
</div>
</div>
<div id="confidence-interval-types" class="section level2">
<h2><span class="header-section-number">11.3</span> Confidence Interval Types</h2>
<p>We want to understand the relationship between the sample statistic <span class="math inline">\(\hat{\theta}\)</span> to the population parameter <span class="math inline">\(\theta\)</span>. We create an estimated population using many repeated copies of our data. By examining how the simulated <span class="math inline">\(\hat{\theta}^{*}\)</span> vary relative to <span class="math inline">\(\hat{\theta}\)</span>, we will understand how possible <span class="math inline">\(\hat{\theta}\)</span> values vary relative to <span class="math inline">\(\theta\)</span>.</p>
<p>We will outline several methods for producing confidence intervals (in the order of most assumptions to fewest).</p>
<div id="normal-intervals" class="section level3">
<h3><span class="header-section-number">11.3.1</span> Normal intervals</h3>
<p>This confidence interval assumes the sampling distribution of <span class="math inline">\(\hat{\theta}\)</span> is approximately normal (which is often true due to the central limit theorem). We can use the bootstrap replicate samples to get an estimate of the standard error of the statistic of interest by just calculating the sample standard deviation of the replicated statistics.</p>
<p>Let <span class="math inline">\(\theta\)</span> be the statistic of interest and <span class="math inline">\(\hat{\theta}\)</span> be the value of that statistic calculated from the observed data. Define <span class="math inline">\(\hat{SE}^{*}\)</span> as the sample standard deviation of the <span class="math inline">\(\hat{\theta}^{*}\)</span> values.</p>
<p>Our first guess as to a confidence interval is <span class="math display">\[\hat{\theta}\pm z_{1-\alpha/2}\hat{SE}^{*}\]</span> which we could write as <span class="math display">\[\left[\hat{\theta}-z_{1-\alpha/2}\hat{SE}^{*},\;\;\;\hat{\theta}+z_{1-\alpha/2}\hat{SE}^{*}\right]\]</span></p>
</div>
<div id="percentile-intervals" class="section level3">
<h3><span class="header-section-number">11.3.2</span> Percentile intervals</h3>
<p>The percentile interval doesn’t assume normality but it does assume that the bootstrap distribution is symmetric and unbiased for the population value. This is the method we used to calculate confidences intervals in the first several chapters. It is perhaps the easiest to calculate and understand. This method only uses <span class="math inline">\(\hat{\theta}^{*}\)</span>, and is <span class="math display">\[\left[\hat{\theta}_{\alpha/2}^{*}\;,\;\;\hat{\theta}_{1-\alpha/2}^{*}\right]\]</span></p>
</div>
<div id="basic-intervals" class="section level3">
<h3><span class="header-section-number">11.3.3</span> Basic intervals</h3>
<p>Unlike the percentile bootstrap interval, the basic interval does not assume the bootstrap distribution is symmetric but does assume that <span class="math inline">\(\hat{\theta}\)</span> is an unbiased estimate for <span class="math inline">\(\theta\)</span>.</p>
<p>To address this, we will using the observed distribution of our replicates <span class="math inline">\(\hat{\theta}^{*}\)</span>. Let <span class="math inline">\(\hat{\theta}_{\alpha/2}^{*}\)</span> and <span class="math inline">\(\hat{\theta}_{1-\alpha/2}^{*}\)</span> be the <span class="math inline">\(\alpha/2\)</span> and <span class="math inline">\(1-\alpha/2\)</span> quantiles of the replicates <span class="math inline">\(\hat{\theta}^{*}\)</span>. Then another way to form a confidence interval would be <span class="math display">\[\left[\hat{\theta}-\left(\hat{\theta}_{1-\alpha/2}^{*}-\hat{\theta}\right),\;\;\;\;\hat{\theta}-\left(\hat{\theta}_{\alpha/2}^{*}-\hat{\theta}\right)\right]\]</span> where the minus sign on the upper limit is because <span class="math inline">\(\left(\hat{\theta}_{\alpha/2}^{*}-\hat{\theta}\right)\)</span> is already negative. The idea behind this interval is that the sampling variability of <span class="math inline">\(\hat{\theta}\)</span> from <span class="math inline">\(\theta\)</span> is the same as the sampling variability of the replicates <span class="math inline">\(\hat{\theta}^{*}\)</span> from <span class="math inline">\(\hat{\theta}\)</span>, and that the distribution of <span class="math inline">\(\hat{\theta}\)</span> is possibly skewed, so we can’t add/subtract the same amounts. Suppose we observe the distribution of <span class="math inline">\(\hat{\theta}^{*}\)</span> as</p>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Then any particular value of <span class="math inline">\(\hat{\theta}^{*}\)</span> could be much larger than <span class="math inline">\(\hat{\theta}\)</span>. Therefore <span class="math inline">\(\hat{\theta}\)</span> could be much larger than <span class="math inline">\(\theta\)</span>. Therefore our confidence interval should be <span class="math inline">\(\left[\hat{\theta}-\textrm{big},\;\hat{\theta}+\textrm{small}\right]\)</span>.</p>
<p>This formula can be simplified to<br />
<span class="math display">\[\left[\hat{\theta}-\left(\hat{\theta}_{1-\alpha/2}^{*}-\hat{\theta}\right)\;,\,\hat{\theta}+\left(\hat{\theta}-\hat{\theta}_{\alpha/2}^{*}\right)\right]  
    \left[2\hat{\theta}-\hat{\theta}_{1-\alpha/2}^{*}\;,\;\;2\hat{\theta}-\hat{\theta}_{\alpha/2}^{*}\right]\]</span></p>
</div>
<div id="towards-bias-corrected-and-accelerated-intervals-bca" class="section level3">
<h3><span class="header-section-number">11.3.4</span> Towards bias-corrected and accelerated intervals (BCa)</h3>
<p>Different schemes for creating confidence intervals can get quite complicated. There is a thriving research community investigating different ways of creating intervals and which are better in what instances. The BCa interval is the most general of the bootstrap intervals and makes the fewest assumptions. Unfortunately is can sometimes fail to converge. The details of this method are too complicated to be presented here but can be found in texts such as chapter 12 in Efron and Tibshirani’s book An Introduction to the Bootstrap (1998).</p>
</div>
</div>
<div id="bootstrap-confidence-intervals-in-r" class="section level2">
<h2><span class="header-section-number">11.4</span> Bootstrap Confidence Intervals in R</h2>
<div id="using-carboot-function" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Using <code>car::Boot()</code> function</h3>
<p>For every model we’ve examined we can create simulated data sets using either case or residual re-sampling and produce confidence intervals for any of the parameters of interest. We won’t bother to do this by hand, but rather let R do the work for us. The package that contains most of the primary programs for bootstrapping is the package <code>boot</code>. The functions within this package are quite flexible but they are a little complex. While we will use this package directly later, for now we will use the package <code>car</code> which has a very convenient function <code>car::Boot()</code>.</p>
<p>We return to our ANOVA example of hostility scores after three different treatment methods. The first thing we will do (as we should do in all data analyses) is to graph our data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define the data</span>
Hostility &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">HLT =</span> <span class="kw">c</span>(<span class="dv">96</span>,<span class="dv">79</span>,<span class="dv">91</span>,<span class="dv">85</span>,<span class="dv">83</span>,<span class="dv">91</span>,<span class="dv">82</span>,<span class="dv">87</span>,
          <span class="dv">77</span>,<span class="dv">76</span>,<span class="dv">74</span>,<span class="dv">73</span>,<span class="dv">78</span>,<span class="dv">71</span>,<span class="dv">80</span>,
          <span class="dv">66</span>,<span class="dv">73</span>,<span class="dv">69</span>,<span class="dv">66</span>,<span class="dv">77</span>,<span class="dv">73</span>,<span class="dv">71</span>,<span class="dv">70</span>,<span class="dv">74</span>),
  <span class="dt">Method =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;M1&#39;</span>,<span class="dv">8</span>), <span class="kw">rep</span>(<span class="st">&#39;M2&#39;</span>,<span class="dv">7</span>), <span class="kw">rep</span>(<span class="st">&#39;M3&#39;</span>,<span class="dv">9</span>) ) )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Hostility, <span class="kw">aes</span>(<span class="dt">x=</span>Method, <span class="dt">y=</span>HLT)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>We can fit the cell-means model and examine the summary statistics using the following code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>( HLT <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility )
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HLT ~ -1 + Method, data = Hostility)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -7.750 -2.866  0.125  2.571  9.250 
## 
## Coefficients:
##          Estimate Std. Error t value Pr(&gt;|t|)    
## MethodM1   86.750      1.518   57.14   &lt;2e-16 ***
## MethodM2   75.571      1.623   46.56   &lt;2e-16 ***
## MethodM3   71.000      1.431   49.60   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.294 on 21 degrees of freedom
## Multiple R-squared:  0.9973, Adjusted R-squared:  0.997 
## F-statistic:  2631 on 3 and 21 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Confidence intervals using the <span class="math display">\[\epsilon_{ij}\stackrel{iid}{\sim}N\left(0,\sigma\right)\]</span> assumption are given by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##             2.5 %   97.5 %
## MethodM1 83.59279 89.90721
## MethodM2 72.19623 78.94663
## MethodM3 68.02335 73.97665</code></pre>
<p>To utilize the bootstrap confidence intervals, we will use the function <code>car::Boot</code> from the package <code>car</code>. It defaults to using case re-sampling, but <code>method='residual'</code> will cause it to use residual re-sampling. We can control the number of bootstrap replicates it using with the R parameter.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot.model &lt;-<span class="st"> </span><span class="kw">Boot</span>(model, <span class="dt">method=</span><span class="st">&#39;case&#39;</span>,     <span class="dt">R=</span><span class="dv">999</span>) <span class="co"># default case resampling </span>
boot.model &lt;-<span class="st"> </span><span class="kw">Boot</span>(model, <span class="dt">method=</span><span class="st">&#39;residual&#39;</span>, <span class="dt">R=</span><span class="dv">999</span>) <span class="co"># residual resampling </span></code></pre></div>
<p>The <code>car::Boot()</code> function has done all work of doing the re-sampling and storing values of <span class="math inline">\(\hat{\mu}_{1},\hat{\mu}_{2}\)</span>, and <span class="math inline">\(\hat{\mu}_{3}\)</span> for each bootstrap replicate data set created using case re-sampling. To look at the bootstrap estimate of the sampling distribution of these statistics, we use the <code>hist()</code> function. The <code>hist()</code> function is actually overloaded and will act differently depending on the type of object. We will send it an object of class boot and the <code>hist()</code> function looks for a function name <code>hist.boot()</code> and when it finds it, just calls it with the function arguments we passed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(boot.model, <span class="dt">layout=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) <span class="co"># 1 row, 3 columns of plots</span></code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>While this plot is aesthetically displeasing (we could do so much better using ggplot2!) this shows the observed bootstrap histogram of <span class="math inline">\(\hat{\mu}_{i}^{*}\)</span>, along with the normal distribution centered at <span class="math inline">\(\hat{\mu}_{i}\)</span> with spread equal to the <span class="math inline">\(StdDev\left(\hat{\mu}_{i}^{*}\right)\)</span>. In this case, the sampling distribution looks very normal and the bootstrap confidence intervals should line up well with the asymptotic intervals. The function <code>confint()</code> will report the BCa intervals by default, but you can ask for “bca”, “norm”, “basic”, “perc”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(boot.model)</code></pre></div>
<pre><code>## Bootstrap bca confidence intervals
## 
##             2.5 %   97.5 %
## MethodM1 83.67302 89.81350
## MethodM2 72.48592 78.97034
## MethodM3 68.37861 74.14954</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(boot.model, <span class="dt">type=</span><span class="st">&#39;perc&#39;</span>)</code></pre></div>
<pre><code>## Bootstrap percent confidence intervals
## 
##             2.5 %   97.5 %
## MethodM1 83.66222 89.80938
## MethodM2 72.43179 78.82929
## MethodM3 68.04848 73.89276</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##             2.5 %   97.5 %
## MethodM1 83.59279 89.90721
## MethodM2 72.19623 78.94663
## MethodM3 68.02335 73.97665</code></pre>
<p>In this case we see that the confidence intervals match up very well with asymptotic intervals.</p>
<p>The <code>car::Boot()</code> function will work for a regression model as well. In the following example, the data was generated from <span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\]</span> but the <span class="math inline">\(\epsilon_{i}\)</span> terms have a strong positive skew and are not normally distributed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">x =</span> <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>, <span class="dt">length=</span><span class="dv">20</span>),
  <span class="dt">y =</span> <span class="kw">c</span>( <span class="fl">15.49</span>, <span class="fl">17.42</span>, <span class="fl">15.17</span>, <span class="fl">14.99</span>, <span class="fl">13.96</span>, 
         <span class="fl">14.46</span>, <span class="fl">13.69</span>, <span class="fl">14.30</span>, <span class="fl">13.61</span>, <span class="fl">15.35</span>, 
         <span class="fl">12.94</span>, <span class="fl">13.26</span>, <span class="fl">12.65</span>, <span class="fl">12.33</span>, <span class="fl">12.04</span>, 
         <span class="fl">11.19</span>, <span class="fl">13.76</span>, <span class="fl">10.95</span>, <span class="fl">10.36</span>, <span class="fl">10.63</span>))
<span class="kw">ggplot</span>(my.data, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Fitting a linear model, we see a problem that the residuals don’t appear to be balanced. The large residuals are all positive. The Shapiro-Wilks test firmly rejects normality of the residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>my.data)
<span class="kw">plot</span>(model, <span class="dt">which=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>( <span class="kw">resid</span>(model) )</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(model)
## W = 0.77319, p-value = 0.0003534</code></pre>
<p>As a result, we don’t might not feel comfortable using the asymptotic distribution of <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> for the creation of our confidence intervals. The bootstrap procedure can give reasonable good intervals, however.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot.model &lt;-<span class="st"> </span><span class="kw">Boot</span>( model )  <span class="co"># by default method=&#39;case&#39;</span>
<span class="kw">hist</span>( boot.model )</code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>( boot.model )</code></pre></div>
<pre><code>## Bootstrap bca confidence intervals
## 
##                  2.5 %     97.5 %
## (Intercept) 15.4729799 16.9857123
## x           -0.6498092 -0.3817759</code></pre>
<p>Notice that both of the bootstrap distribution for both <span class="math inline">\(\hat{\beta}_{0}^{*}\)</span> and <span class="math inline">\(\hat{\beta}_{1}^{*}\)</span> are skewed, and the BCa intervals are likely to be the most appropriate intervals to use.</p>
</div>
<div id="using-the-boot-package" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Using the <code>boot</code> package</h3>
<p>The <code>car::Boot()</code> function is very handy, but it lacks flexibility; it assumes that you just want to create bootstrap confidence intervals for the model coefficients. The <code>car::Boot()</code> function is actually a nice simple user interface to the boot package which is more flexible, but requires the user to be more precise about what statistic should be stored and how the bootstrap samples should be created. We will next examine how to use this package.</p>
<div id="case-resampling" class="section level4">
<h4><span class="header-section-number">11.4.2.1</span> Case resampling</h4>
<p>Suppose that we have n observations in our sample data. Given some vector of numbers re-sampled from <code>1:n</code>, we need to either re-sample those cases or those residuals and then using the new dataset calculate some statistic. The function <code>boot()</code> will require the user to write a function that does this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>my.data )
<span class="kw">coef</span>(model)</code></pre></div>
<pre><code>## (Intercept)           x 
##  16.0355714  -0.5216143</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Do case resampling with the regression example</span>
<span class="co"># sample.data is the original data frame </span>
<span class="co"># indices - This is a vector of numbers from 1:n which tells</span>
<span class="co">#           us which cases to use.  It might be 1,3,3,6,7,7,...</span>
my.stat &lt;-<span class="st"> </span><span class="cf">function</span>(sample.data, indices){
  data.star &lt;-<span class="st"> </span>sample.data[indices, ]      
  model.star &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>data.star)
  output &lt;-<span class="st"> </span><span class="kw">coef</span>(model.star)
  <span class="kw">return</span>(output)
}

<span class="co"># original model coefficients</span>
<span class="kw">my.stat</span>(my.data, <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>)</code></pre></div>
<pre><code>## (Intercept)           x 
##  16.0355714  -0.5216143</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># one bootstrap replicate </span>
<span class="kw">my.stat</span>(my.data, mosaic<span class="op">::</span><span class="kw">resample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>))</code></pre></div>
<pre><code>## (Intercept)           x 
##  16.3069314  -0.5786995</code></pre>
<p>Notice that the function we write doesn’t need to determine the random sample of the indices to use. Our function will be told what indices to use (possibly to calculate the statistic of interest <span class="math inline">\(\hat{\theta}\)</span>, or perhaps a bootstrap replicate <span class="math inline">\(\hat{\theta}^{*}\)</span>. For example, the BCa method needs to know the original sample estimates <span class="math inline">\(\hat{\theta}\)</span> to calculate how far the mean of the <span class="math inline">\(\hat{\theta}^{*}\)</span> values is from <span class="math inline">\(\hat{\theta}\)</span>. To avoid the user having to see all of that, we just need to take the set of indices given and calculate the statistic of interest.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot.model &lt;-<span class="st"> </span><span class="kw">boot</span>(my.data, my.stat, <span class="dt">R=</span><span class="dv">10000</span>)
<span class="co">#boot.ci(boot.model, type=&#39;bca&#39;, index=1) # CI for Intercept</span>
<span class="co">#boot.ci(boot.model, type=&#39;bca&#39;, index=2) # CI for the Slope</span>
<span class="kw">confint</span>(boot.model)</code></pre></div>
<pre><code>## Bootstrap bca confidence intervals
## 
##        2.5 %    97.5 %
## 1 15.4340761 17.013663
## 2 -0.6507547 -0.374097</code></pre>
</div>
<div id="residual-resampling" class="section level4">
<h4><span class="header-section-number">11.4.2.2</span> Residual Resampling</h4>
<p>We will now consider the ANOVA problem and in this case we will re-sample the residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit the ANOVA model to the Hostility Data</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>( HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility )

<span class="co"># now include the predicted values and residuals to the data frame</span>
Hostility &lt;-<span class="st"> </span>Hostility <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(
  <span class="dt">fit    =</span> <span class="kw">fitted</span>(model),
  <span class="dt">resid  =</span> <span class="kw">resid</span>(model))

<span class="co"># Do residual resampling with the regression example</span>
my.stat &lt;-<span class="st"> </span><span class="cf">function</span>(sample.data, indices){
  data.star  &lt;-<span class="st"> </span>sample.data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">HLT =</span> fit <span class="op">+</span><span class="st"> </span>resid[indices])
  model.star &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>data.star)
  output     &lt;-<span class="st"> </span><span class="kw">coef</span>(model.star)
  <span class="kw">return</span>(output)
}

boot.model &lt;-<span class="st"> </span><span class="kw">boot</span>(Hostility, my.stat, <span class="dt">R=</span><span class="dv">10000</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(boot.model)</code></pre></div>
<pre><code>## Bootstrap bca confidence intervals
## 
##       2.5 %     97.5 %
## 1  84.10714  89.575893
## 2 -15.42106  -7.241673
## 3 -19.55282 -12.069872</code></pre>
<p>Fortunately the <code>hist()</code> command can print the nice histogram from the output of the <code>boot()</code> command.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>( boot.model, <span class="dt">layout=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) <span class="co"># 1 row, 3 columns)</span></code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Notice that we don’t need to have the model coefficients <span class="math inline">\(\hat{\mu}_{i}\)</span> be our statistic of interest, we could just as easily produce a confidence interval for the residual standard error <span class="math inline">\(\hat{\sigma}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Do residual resampling with the regression example</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>my.data )
my.data &lt;-<span class="st"> </span>my.data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(
  <span class="dt">fitted =</span> <span class="kw">fitted</span>(model),
  <span class="dt">resid  =</span> <span class="kw">resid</span>(model))

<span class="co"># Define the statisitc I care about</span>
my.stat &lt;-<span class="st"> </span><span class="cf">function</span>(sample.data, indices){
  data.star &lt;-<span class="st"> </span>sample.data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">y =</span> fitted <span class="op">+</span><span class="st"> </span>resid[indices])
  model.star &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>data.star)
  output &lt;-<span class="st"> </span><span class="kw">summary</span>(model.star)<span class="op">$</span>sigma
  <span class="kw">return</span>(output)
}

boot.model &lt;-<span class="st"> </span><span class="kw">boot</span>(my.data, my.stat, <span class="dt">R=</span><span class="dv">10000</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(boot.model, <span class="dt">layout=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(boot.model)</code></pre></div>
<pre><code>## Bootstrap bca confidence intervals
## 
##      2.5 %   97.5 %
## 1 0.566195 1.220835</code></pre>
</div>
<div id="including-blockingstratifying-variables" class="section level4">
<h4><span class="header-section-number">11.4.2.3</span> Including Blocking/Stratifying Variables</h4>
<p>When we introduced the ANOVA model we assumed that the groups had equal variance but we don’t have to. If we consider the model with unequal variances among groups <span class="math display">\[Y_{ij}=\mu_{i}+\epsilon_{ij}\;\;\;\;\textrm{where}\;\;\;E\left(\epsilon_{ij}\right)=0\;\;Var\left(\epsilon_{ij}\right)=\sigma_{i}^{2}\]</span> then our usual analysis is inappropriate but we could easily bootstrap our confidence intervals for <span class="math inline">\(\mu_{i}\)</span>. If we do case re-sampling, this isn’t an issue because each included observation is an <span class="math inline">\(\left(group,\ response\right)\)</span> pair and our groups will have large or small variances similar to the observed data. However if we do residual re-sampling, then we must continue to have this. We do this by only re-sampling residuals within the same group. One way to think of this is if your model has a subscript on the variance term, then your bootstrap samples must respect that.</p>
<p>If you want to perform the bootstrap by hand using dplyr commands, it can be done by using the <code>group_by()</code> with whatever the blocking/Stratifying variable is prior to the <code>mosaic::resample()</code> command. You could also use the optional group argument to the <code>mosaic::resample()</code> command.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y  =</span><span class="kw">c</span>(<span class="fl">9.8</span>,<span class="fl">9.9</span>,<span class="fl">10.1</span>,<span class="fl">10.2</span>,   <span class="dv">18</span>,<span class="dv">19</span>,<span class="dv">21</span>,<span class="dv">22</span>),
                   <span class="dt">grp=</span><span class="kw">c</span>(<span class="st">&#39;A&#39;</span>,<span class="st">&#39;A&#39;</span>,<span class="st">&#39;A&#39;</span>,<span class="st">&#39;A&#39;</span>,    <span class="st">&#39;B&#39;</span>,<span class="st">&#39;B&#39;</span>,<span class="st">&#39;B&#39;</span>,<span class="st">&#39;B&#39;</span>),
                   <span class="dt">fit=</span><span class="kw">c</span>( <span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">10</span>,        <span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">20</span>   ),
                   <span class="dt">resid=</span><span class="kw">c</span>(<span class="op">-</span>.<span class="dv">2</span>,<span class="op">-</span>.<span class="dv">1</span>,.<span class="dv">1</span>,.<span class="dv">2</span>,     <span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>   )) 
data.star &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(grp) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># do the grouping using dplyr</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">resid.star =</span> mosaic<span class="op">::</span><span class="kw">resample</span>(resid),
         <span class="dt">y.star     =</span> fit <span class="op">+</span><span class="st"> </span>resid.star)
data.star</code></pre></div>
<pre><code>## # A tibble: 8 x 6
## # Groups:   grp [2]
##       y grp     fit resid resid.star y.star
##   &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;
## 1   9.8 A        10  -0.2        0.2   10.2
## 2   9.9 A        10  -0.1       -0.1    9.9
## 3  10.1 A        10   0.1       -0.2    9.8
## 4  10.2 A        10   0.2        0.2   10.2
## 5  18   B        20  -2         -2     18  
## 6  19   B        20  -1          1     21  
## 7  21   B        20   1         -1     19  
## 8  22   B        20   2          1     21</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data.star &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">resid.star =</span> mosaic<span class="op">::</span><span class="kw">resample</span>(resid, <span class="dt">group=</span>grp), <span class="co"># do the grouping within resample </span>
         <span class="dt">y.star     =</span> fit <span class="op">+</span><span class="st"> </span>resid.star)
data.star</code></pre></div>
<pre><code>##      y grp fit resid resid.star y.star
## 1  9.8   A  10  -0.2        0.2   10.2
## 2  9.9   A  10  -0.1        0.1   10.1
## 3 10.1   A  10   0.1       -0.2    9.8
## 4 10.2   A  10   0.2       -0.2    9.8
## 5 18.0   B  20  -2.0       -1.0   19.0
## 6 19.0   B  20  -1.0       -2.0   18.0
## 7 21.0   B  20   1.0       -2.0   18.0
## 8 22.0   B  20   2.0        2.0   22.0</code></pre>
<p>Unfortunately the <code>car::Boot()</code> command doesn’t take a strata option, but the the <code>boot::boot()</code> command.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit the ANOVA model to the Hostility Data</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>( HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>Hostility )

<span class="co"># now include the predicted values and residuals to the data frame</span>
Hostility &lt;-<span class="st"> </span>Hostility <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(
  <span class="dt">fitted =</span> <span class="kw">fitted</span>(model),
  <span class="dt">resid  =</span> <span class="kw">resid</span>(model))

<span class="co"># Do residual resampling </span>
my.stat &lt;-<span class="st"> </span><span class="cf">function</span>(sample.data, indices){
  data.star &lt;-<span class="st"> </span>sample.data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">HLT =</span> fitted <span class="op">+</span><span class="st"> </span>resid[indices])
  model.star &lt;-<span class="st"> </span><span class="kw">lm</span>(HLT <span class="op">~</span><span class="st"> </span>Method, <span class="dt">data=</span>data.star)
  output &lt;-<span class="st"> </span><span class="kw">coef</span>(model.star)
  <span class="kw">return</span>(output)
}

<span class="co"># strata is a vector of the categorical variable we block/stratify on</span>
boot.model &lt;-<span class="st"> </span><span class="kw">boot</span>( Hostility, my.stat, <span class="dt">R=</span><span class="dv">1000</span>, <span class="dt">strata=</span>Hostility<span class="op">$</span>Method )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(boot.model, <span class="dt">layout=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</code></pre></div>
<p><img src="11_Resampling_LinearModels_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(boot.model)</code></pre></div>
<pre><code>## Bootstrap bca confidence intervals
## 
##       2.5 %     97.5 %
## 1  83.50000  91.000000
## 2 -15.59956  -7.152499
## 3 -20.29828 -11.599394</code></pre>
</div>
</div>
</div>
<div id="exercises-10" class="section level2">
<h2><span class="header-section-number">11.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>We will perform a regression analysis on the following data and use different bootstrap re-sampling methods to create a confidence interval for the slope parameter. In this case the residuals are symmetric, though perhaps we don’t want to assume normality.</p>
<table>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(x_{i}\)</span></td>
<td align="center">3</td>
<td align="center">4</td>
<td align="center">5</td>
<td align="center">6</td>
<td align="center">7</td>
<td align="center">8</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(y_{i}\)</span></td>
<td align="center">5</td>
<td align="center">9</td>
<td align="center">10</td>
<td align="center">12</td>
<td align="center">15</td>
<td align="center">15</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\hat{y}_{i}\)</span></td>
<td align="center">6</td>
<td align="center">8</td>
<td align="center">10</td>
<td align="center">12</td>
<td align="center">14</td>
<td align="center">16</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\hat{\epsilon}_{i}\)</span></td>
<td align="center">-1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">-1</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>We will first use case resampling.
<ol style="list-style-type: lower-roman">
<li>Suppose that the bootstrap indices are selected to be cases 1,3,3,4,6,6. Create a new dataset with those cases and calculate the regression coefficients <span class="math inline">\(\hat{\beta}_{0}^{*}\)</span> and <span class="math inline">\(\hat{\beta}_{1}^{*}\)</span> using R’s <code>lm()</code> function. Notice that the residual <span class="math inline">\(\hat{\epsilon}_{i}\)</span> is always paired with its value of <span class="math inline">\(x_{i}\)</span> and that in case resampling we don’t get the same x-values as our data.</li>
<li>Using the <code>mosaic::resample()</code> command, calculate several values of <span class="math inline">\(\hat{\beta}_{1}^{*}\)</span> using case resampling.</li>
<li>Use the <code>car::Boot()</code> function to calculate the BCa confidence interval for <span class="math inline">\(\hat{\beta}_{1}\)</span> with case resampling</li>
</ol></li>
<li>Next we will use Residual Resampling
<ol style="list-style-type: lower-roman">
<li>Suppose that the bootstrap indices are selected to be cases 1,3,3,4,6,6. Create a new dataset with those cases and calculate the regression coefficients <span class="math inline">\(\hat{\beta}_{0}^{*}\)</span> and <span class="math inline">\(\hat{\beta}_{1}^{*}\)</span> using R’s <code>lm()</code> function. Notice that the residual <span class="math inline">\(\hat{\epsilon}_{i}\)</span> is not necessarily paired with its value of <span class="math inline">\(x_{i}\)</span> and that the new data set has the same x-values as the original sampled data.</li>
<li>Using the <code>mosaic::resample</code> command, calculate several values of <span class="math inline">\(\hat{\beta}_{i}^{*}\)</span>. Hint: We can’t do this in one simple command, instead we have to make the new dataset and then fit the regression.</li>
<li>Use the <code>car::Boot()</code> function to calculate the BCa confidence interval for <span class="math inline">\(\hat{\beta}_{1}\)</span> using residual resampling.</li>
</ol></li>
</ol></li>
<li><p>The ratio of DDE (related to DDT) to PCB concentrations in bird eggs has been shown to have had a number of biological implications. The ratio is used as an indication of the movement of contamination through the food chain. The paper “The ratio of DDE to PCB concentrations in Great Lakes herring gull eggs and its us in interpreting contaminants data” reports the following ratios for eggs collected at sites from the five Great Lakes. The eggs were collected from both terrestrial and aquatic feeding birds. Suppose that we are interested in estimating <span class="math inline">\(\rho=\frac{\mu_{terrestial}}{\mu_{aquatic}}\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Pollution &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">value =</span> <span class="kw">c</span>(<span class="fl">76.50</span>, <span class="fl">6.03</span>, <span class="fl">3.51</span>, <span class="fl">9.96</span>, <span class="fl">4.24</span>, <span class="fl">7.74</span>, <span class="fl">9.54</span>, <span class="fl">41.70</span>, <span class="fl">1.84</span>, <span class="fl">2.50</span>, <span class="fl">1.54</span>,
             <span class="fl">0.27</span>, <span class="fl">0.61</span>, <span class="fl">0.54</span>, <span class="fl">0.14</span>, <span class="fl">0.63</span>, <span class="fl">0.23</span>, <span class="fl">0.56</span>,  <span class="fl">0.48</span>, <span class="fl">0.16</span>, <span class="fl">0.18</span>       ),
  <span class="dt">type  =</span> <span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&#39;Terrestrial&#39;</span>,<span class="dv">11</span>), <span class="kw">rep</span>(<span class="st">&#39;Aquatic&#39;</span>,<span class="dv">10</span>) ) )
model &lt;-<span class="st"> </span><span class="kw">lm</span>( value <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>type, <span class="dt">data=</span>Pollution)
<span class="kw">coef</span>(model)</code></pre></div>
<pre><code>##     typeAquatic typeTerrestrial 
##         0.38000        15.00909</code></pre>
<ol style="list-style-type: lower-alpha">
<li>Recall that the ANOVA with the cell mean representation will calculate the group means. Use the lm() function to calculate the means of the two groups. Notice that the p-values and any confidence intervals from this model are useless because we are egregiously violating the equal variance and normality assumptions on the residuals.</li>
<li>Using R, calculate the ratio <span class="math inline">\(\hat{\rho}=\bar{y}_{T}/\bar{y}_{A}\)</span>. <em>Hint: what is returned by <code>coef(model)[1]</code></em>?</li>
<li>Use the <code>mosaic::resample()</code> function to generate several bootstrap datasets using case resampling. Do you get 11 Terrestrial observations in each dataset? Do this ten or twenty times (don’t show these computations) and note the most unbalanced data set.</li>
<li>Use the <code>mosaic::resample()</code> function to generate several bootstrap datasets using residual resampling? Do you get data sets where a simulated aquatic observation has been paired with a huge residual term from the terrestrial. Does this seem appropriate?</li>
<li>The <code>mosaic::resample()</code> function includes an optional <code>groups=</code> argument that does the resampling within a specified group (thus we will always get 11 Terrestrial observations and 10 Aquatic). Use this to generate several bootstrap datasets.</li>
<li>The <code>car::Boot()</code> function cannot handle the grouping, but <code>boot::boot()</code> can.
<ol style="list-style-type: lower-roman">
<li><p>The following function will calculate <span class="math inline">\(\hat{\rho}\)</span>, the statistic of interest, given the original data and a set of indices to use. Notice that we’ve chosen to do case resampling here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">calc_rhohat &lt;-<span class="st"> </span><span class="cf">function</span>(data, indices){
  data.star &lt;-<span class="st"> </span>data[indices, ]
  model.star &lt;-<span class="st"> </span><span class="kw">lm</span>( value <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>type, <span class="dt">data=</span>data.star )
  <span class="kw">return</span>( <span class="kw">coef</span>(model.star)[<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span><span class="kw">coef</span>(model.star)[<span class="dv">1</span>] )
}</code></pre></div></li>
<li>Call this function using the Pollution data set and indices 1:21. Notice that this calculates the sample statistic <span class="math inline">\(\hat{\rho}\)</span> that we calculated previously.</li>
<li>Call this function using <code>indices = resample(1:21, groups=Pollution$type)</code>. Notice that this calculates the sample statistic <span class="math inline">\(\hat{\rho}^{*}\)</span> where we are doing case resampling within each group.</li>
<li>Use the <code>boot::boot()</code> to perform the full bootstrap analysis. Use the option <code>strata=Pollution$type</code> option, which is causes R to do the resampling within each group.</li>
<li><p>What is the 95% BCa CI for <span class="math inline">\(\rho\)</span>? Show the histogram of the bootstrap estimate of the distribution of <span class="math inline">\(\hat{\rho}\)</span>.</p></li>
</ol></li>
</ol></li>
</ol>
<!--chapter:end:11_Resampling_LinearModels.Rmd-->
</div>
</div>
<div id="contingency-tables" class="section level1">
<h1><span class="header-section-number">12</span> Contingency Tables</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tidyr)</code></pre></div>
<p>We are often interested in experiments and studies where the response variable is categorical and so is the explanatory.</p>
<ul>
<li><p>Treat plots with either Type A or Type B insecticides and after 2 weeks observe if the plots are infested or not infested with some insect.</p></li>
<li><p>Using survey data, we would like to investigate if there is a relationship between Gender and Political Party affiliation. (Are women more likely to be Democrats?)</p></li>
<li><p>Are children that are born second or third (or more!) more likely to be gay than the firstborn child?</p></li>
</ul>
<p>We will be interested in testing the null hypothesis of “No association” between the explanatory and response variable.</p>
<p>We will have two questions:</p>
<ol style="list-style-type: decimal">
<li><p>What statistic could be calculated from the observed data to measure how far the observed data is from the null hypothesis?</p></li>
<li><p>Given the statistic in part 1, how should it vary from sample to sample assuming the null hypothesis (no difference in treatments) is true?</p></li>
</ol>
<div id="expected-counts" class="section level2">
<h2><span class="header-section-number">12.1</span> Expected Counts</h2>
<p>We will develop our ideas using a sub-sample of data from surveys of undergraduate students in an Introductory statistics course. We will utilize <span class="math inline">\(40\)</span> males and <span class="math inline">\(40\)</span> females and consider the historical assumption that women should perform better on the verbal part of the SAT rather than the MATH part compared to their male counterparts.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(StudentSurvey, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)
StudentSurvey &lt;-<span class="st"> </span>StudentSurvey <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>( HigherSAT <span class="op">!=</span><span class="st"> &#39;&#39;</span>) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># remove a student that did not report SAT scores</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HigherSAT =</span> <span class="kw">factor</span>(HigherSAT)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># remove the MISSING level from the above student</span>
<span class="st">  </span><span class="kw">group_by</span>(Gender) <span class="op">%&gt;%</span><span class="st">          </span><span class="co"># Only consider the first 40 males</span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">40</span>) <span class="op">%&gt;%</span><span class="st">               </span><span class="co"># and Females... as a first example</span>
<span class="st">  </span><span class="kw">select</span>(Gender, HigherSAT) </code></pre></div>
<p>In this example, exactly <span class="math inline">\(60\%\)</span> of the students had a higher score on the math portion of the SAT than on the verbal. If the null hypothesis is true, then <span class="math inline">\(60\%\)</span> of the <span class="math inline">\(40\)</span> males should have a higher Math SAT score than verbal. So under the null, we expect to see <span class="math inline">\(40 * 0.60 = 24\)</span> males and <span class="math inline">\(40*0.60=24\)</span> females to have a higher Math SAT than verbal. Similarly we would expect <span class="math inline">\(40*0.40=16\)</span> males and <span class="math inline">\(16\)</span> females to score higher on the verbal section. Below is a table that summarizes both our observed data and the expected values under the null hypotheses of no association between superior SAT category with gender.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tab &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">tally</span>( HigherSAT <span class="op">~</span><span class="st"> </span>Gender, <span class="dt">data=</span>StudentSurvey, <span class="dt">format=</span><span class="st">&#39;count&#39;</span>)
descr<span class="op">::</span><span class="kw">CrossTable</span>( tab, <span class="dt">expected =</span> <span class="ot">TRUE</span>,
                   <span class="dt">prop.r =</span> <span class="ot">FALSE</span>, <span class="dt">prop.c=</span><span class="ot">FALSE</span>, <span class="dt">prop.t=</span><span class="ot">FALSE</span>, <span class="dt">prop.chisq =</span> <span class="ot">FALSE</span> )</code></pre></div>
<pre><code>##    Cell Contents 
## |-------------------------|
## |                       N | 
## |              Expected N | 
## |-------------------------|
## 
## ============================
##              Gender
## HigherSAT     F    M   Total
## ----------------------------
## Math         23   25      48
##              24   24        
## ----------------------------
## Verbal       17   15      32
##              16   16        
## ----------------------------
## Total        40   40      80
## ============================</code></pre>
<p>Notice that the expected cell counts can be written as <span class="math display">\[E_{ij} = \frac{ n_{i,\cdot}}{n} * n_{\cdot, j} = \frac{n_{i,\cdot} n_{\cdot,j}}{n}\]</span> where <span class="math inline">\(n_{i,\cdot}\)</span> is row total for the <span class="math inline">\(i\)</span>th row, <span class="math inline">\(n_{\cdot,j}\)</span> is the column total for the <span class="math inline">\(j\)</span>th row, and <span class="math inline">\(n\)</span> is the total number of observations in the table.</p>
<p>This is the first case where our test statistic will not be just plugging in the sample statistic into the null hypothesis. Instead we will consider a test statistic that is more flexible and will handle more general cases (say 3 or more response or treatment groups) Our statistic for assessing how far our observed data is from what we expect under the null hypothesis involves the difference between the observed and the expected for each of the cells, but again we don’t want to just sum the differences, instead will make the differences positive by squaring the differences. Second, a difference of 10 between the observed and expected cell count is very different if the number expected is 1000 than if it is 10, so we will scale the observed difference by dividing by the expected cell count.</p>
<p>We define <span class="math display">\[\begin{aligned}X^{2}  
  &amp;=    \sum_{\textrm{all ij cells}}\frac{\left(O_{ij}-E_{ij}\right)^{2}}{E_{ij}} \\
  &amp;=  \frac{(23-24)^2}{24} + \frac{(25-24)^2}{24} + \frac{(17-16)^2}{16} + \frac{(15-16)^2}{16} \\
  &amp;=  0.04167 + 0.04167 + 0.0625 + 0.0625 \\
  &amp;= 0.20834
  \end{aligned}\]</span></p>
<p>In the next section we will address if this test statistic is large enough to reject the null hypothesis.</p>
<p><em>Example</em></p>
<p>Researchers suspected that attack of a plant by one organism induce resistance to subsequent attack by a different organism. The <span class="math inline">\(47\)</span> individually potted cotton plants were randomly allocated to two groups: infestation by spider mites or no infestation. After two weeks the mites were dutifully removed by a conscientious research assistant, and both groups were inoculated with Verticillium, a fungus that causes Wilt disease.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Mites, <span class="dt">package=</span><span class="st">&quot;mosaicData&quot;</span>)
<span class="kw">str</span>(Mites)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    47 obs. of  2 variables:
##  $ treatment: Factor w/ 2 levels &quot;mites&quot;,&quot;no mites&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ outcome  : Factor w/ 2 levels &quot;no wilt&quot;,&quot;wilt&quot;: 2 2 2 2 2 2 2 2 2 2 ...</code></pre>
<p>We will summarize the data into a contingency table that counts the number of plants in each treatment/wilt category.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Using mosaic&#39;s tally function</span>
tab &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">tally</span>(outcome <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>Mites, <span class="co"># table of outcome by treatment</span>
              <span class="dt">format=</span><span class="st">&#39;count&#39;</span>)                  <span class="co"># give the raw counts, not percentages</span>
tab</code></pre></div>
<pre><code>##          treatment
## outcome   mites no mites
##   no wilt    15        4
##   wilt       11       17</code></pre>
<p>From this table we can see that <span class="math inline">\(28\)</span> out of the <span class="math inline">\(47\)</span> plants wilted, so the proportion that wilted was <span class="math inline">\(\frac{28}{47}=0.596\)</span>. Therefore under the null hypothesis we would expect that <span class="math inline">\(59.6\%\)</span> of the <span class="math inline">\(26\)</span> mite treated plants would have wilted, or <span class="math display">\[\left( \frac{28}{47} \right) 26 = 15.49\]</span></p>
<p>Similar calculations reveal the rest of the expected cell counts.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">descr<span class="op">::</span><span class="kw">CrossTable</span>( tab, <span class="dt">expected =</span> <span class="ot">TRUE</span>,
                   <span class="dt">prop.r =</span> <span class="ot">FALSE</span>, <span class="dt">prop.c=</span><span class="ot">FALSE</span>, <span class="dt">prop.t=</span><span class="ot">FALSE</span>, <span class="dt">prop.chisq =</span> <span class="ot">FALSE</span> )</code></pre></div>
<pre><code>##    Cell Contents 
## |-------------------------|
## |                       N | 
## |              Expected N | 
## |-------------------------|
## 
## ===================================
##            treatment
## outcome    mites   no mites   Total
## -----------------------------------
## no wilt       15          4      19
##             10.5        8.5        
## -----------------------------------
## wilt          11         17      28
##             15.5       12.5        
## -----------------------------------
## Total         26         21      47
## ===================================</code></pre>
<p>Is this data indicative of mites inferring a disease resistance? More formally we are interested in testing <span class="math display">\[H_{0}:\:  \pi_{w}=\pi_{w|m}\]</span> <span class="math display">\[H_{0}:\:  \pi_{w}\ne\pi_{w|m}\]</span><br />
where the relevant parameters are <span class="math inline">\(\pi_{w}\)</span>, the probability that a plant will wilt, and <span class="math inline">\(\pi_{w|m}\)</span>, the probability that a plant will wilt given that it has been treated with mites.</p>
<p>We calculate our test statistic as <span class="math display">\[\begin{aligned}X^{2}  
  &amp;=    \sum_{\textrm{all ij cells}}\frac{\left(O_{ij}-E_{ij}\right)^{2}}{E_{ij}} \\
    &amp;=  \frac{\left(15-10.51\right)^{2}}{10.51}+\frac{\left(4-8.49\right)^{2}}{8.49}+\frac{\left(11-15.49\right)^{2}}{15.49}+\frac{\left(17-12.51\right)^{2}}{12.51}\\
    &amp;=  1.92+2.37+1.30+1.61 \\
    &amp;=  7.20
    \end{aligned}\]</span></p>
<p>If the null hypothesis is true, then this statistic should be small, and a large value of the statistic is indicative of the null hypothesis being incorrect. But how large must the statistic be before we reject the null hypothesis?</p>
</div>
<div id="hypothesis-testing" class="section level2">
<h2><span class="header-section-number">12.2</span> Hypothesis Testing</h2>
<p>Similarly to the two-sample t-test, we randomly shuffle the treatment assignments and recalculate the statistic many times and examine the sampling distribution of our test statistic, <span class="math inline">\(X^{2}\)</span>.</p>
<p>To do this efficiently, we’ll need a way of easily calculating this test statistic. In a traditional course I would introduce this test by the name of “Pearson’s Chi-squared test” and we can obtain the test statistic using the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># function is chisq.test() and we need to tell it not to do the Yates continuity </span>
<span class="co"># correction and just calculate the test statistic as we&#39;ve described </span>
<span class="kw">chisq.test</span>( <span class="kw">table</span>(Mites), <span class="dt">correct=</span><span class="ot">FALSE</span> )   <span class="co"># do a Chi-sq test </span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  table(Mites)
## X-squared = 7.2037, df = 1, p-value = 0.007275</code></pre>
<p>R is performing the traditional Pearson’s Chi-Squared test which assumes our sample sizes are large enough for several approximations to be good. Fortunately, we don’t care about this approximation to the p-value and will use simulation methods which will be more accurate. In order to use the <code>chisq.test()</code> function to do our calculations, we need to extract the test-statistic from the output of the function. &lt;<warning=FALSE>&gt;=</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># extract the X^2 test statistic from the output</span>
X.sq &lt;-<span class="st"> </span><span class="kw">chisq.test</span>( <span class="kw">table</span>(Mites), <span class="dt">correct=</span><span class="ot">FALSE</span> )<span class="op">$</span>statistic <span class="co"># grab only the test statistic</span>
X.sq</code></pre></div>
<pre><code>## X-squared 
##  7.203748</code></pre>
<p>Next we wish to repeat our shuffling trick of the treatment labels to calculate the sampling distribution of <span class="math inline">\(X^{2*}\)</span>, which is the distribution of <span class="math inline">\(X^{2}\)</span> when the null hypothesis of no difference between treatments is true.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Mites.star &lt;-<span class="st"> </span>Mites <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">treatment =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(treatment))
<span class="kw">table</span>(Mites.star)</code></pre></div>
<pre><code>##           outcome
## treatment  no wilt wilt
##   mites          9   17
##   no mites      10   11</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>( <span class="kw">table</span>(Mites.star), <span class="dt">correct=</span><span class="ot">FALSE</span> )<span class="op">$</span>statistic <span class="co"># grab only the test statistic</span></code></pre></div>
<pre><code>## X-squared 
## 0.8156621</code></pre>
<p>We see that this code is creating a data frame with a single column called <code>X.squared</code> and next we simulate a large number of times and display the sampling distribution of <span class="math inline">\(X^{2*}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SamplingDist &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">10000</span>)<span class="op">*</span>{
  Mites.star &lt;-<span class="st"> </span>Mites <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">treatment =</span> mosaic<span class="op">::</span><span class="kw">shuffle</span>(treatment))
  <span class="kw">chisq.test</span>( <span class="kw">table</span>(Mites.star), <span class="dt">correct=</span><span class="ot">FALSE</span> )<span class="op">$</span>statistic 
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>( SamplingDist, <span class="kw">aes</span>(<span class="dt">x=</span>X.squared)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>()</code></pre></div>
<p><img src="12_ContingencyTables_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>At first glance this seems wrong because it is not a nice looking distribution. However there are only a small number of ways to allocate the treatments labels to the two possible outcomes. Second, for the test statistic we have chosen only the right hand side of the distribution (large values of <span class="math inline">\(X^{*}\)</span>) would be evidence against the null hypothesis, so we only look at <span class="math inline">\(X^{2*}&gt;7.20\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p.value &lt;-<span class="st"> </span>SamplingDist <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>( <span class="dt">p.value =</span> <span class="kw">mean</span>( X.squared <span class="op">&gt;=</span><span class="st"> </span>X.sq ) )
p.value</code></pre></div>
<pre><code>##   p.value
## 1  0.0167</code></pre>
<p>We see that the p-value is 0.0167 and conclude that there is strong evidence to reject the null hypothesis that the mite treatment does not affect the probability of wilting. That is to say, the probability of observing data as extreme as ours is unlikely to occur by random chance when the null hypothesis is true.</p>
<p>As usual, it is pretty annoying to have to program the permutation test ourselves. Fortunately the <code>chisq.test()</code> function allows us to option to tell it to do a permutation based test. There is an option <code>simulate.p.value</code> which reproduces the simulation test we just performed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>( <span class="kw">table</span>(Mites), <span class="dt">simulate.p.value=</span><span class="ot">TRUE</span>, <span class="dt">B=</span><span class="dv">10000</span> )</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with simulated p-value (based on 10000
##  replicates)
## 
## data:  table(Mites)
## X-squared = 7.2037, df = NA, p-value = 0.0167</code></pre>
<p>Before we had our excellent computers, we would have to compare the observed <span class="math inline">\(X^{2}\)</span> test statistic to some distribution to determine if it is large enough to be evidence against the null. It can be shown that if the null hypothesis is correct then <span class="math inline">\(X^{2}\stackrel{\cdot}{\sim}\chi_{1}^{2}\)</span> where this is the Chi-squared distribution with 1 degree of freedom. This is the distribution that the <code>chisq.test()</code> compares against if we don’t tell it to do a permutation based test. Furthermore, even if the null hypothesis is true the test statistic is only approximately normal but that approximation gets better and better as the total sample size increases.</p>
<p>The reason that we compare against a Chi-squared distribution with 1 degree of freedom is because when we shuffle the group labels, we still have the same number of wilted/non-wilted plants as well as the same number of mite/no-mite treated plants. So the row and column totals are identical in all the permuted tables. So once the number of observations in the <span class="math inline">\((1,1)\)</span> cell is decided, the other three cells are also indirectly determined as well due to the row/column totals being constant regardless of permutation. In the general case with <span class="math inline">\(R\)</span> rows and <span class="math inline">\(C\)</span> columns, the number of cells that are not set due to the row/column totals, is <span class="math inline">\((R-1)(C-1)\)</span>.</p>
<p>The asymptotic approximation is usually acceptable if the observed count in each cell is greater than 5. Even then, a slightly better approximation can be obtained by using the Yates’ continuity correction. Typically I will perform the analysis both ways and confirm we get the same inference. If the two methods disagree, I’d trust the permutation method.</p>
<p><em>Example</em>:</p>
<p>In a study to investigate possible treatments for human infertility, researchers (Harrison, R. F., Blades, M., De Louvois, J., &amp; Hurley, R. (1975). Doxycycline treatment and human infertility. The Lancet, 305(7907), 605-607.) performed a double-blind study and randomly divided 58 patients into two groups. The treatment group (<span class="math inline">\(n_{t}=30\)</span>) received 100 mg per day of Doxycycline and the placebo group (<span class="math inline">\(n_{p}=28\)</span>) received a placebo but were unaware that it was a placebo. Within 5 months, the treatment group had 5 pregnancies, while the placebo group had 4. Just looking at the observed vs expected there doesn’t seem to be much difference between the treatments. In fact, due to the discrete nature of the data (i.e. integer values) we can’t imagine data that any closer to the expected value that what we observed. The p-value here ought to be 1! To confirm this we do a similar test as before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Conceived &lt;-<span class="st">  </span><span class="kw">data.frame</span>(
  <span class="dt">Treatment=</span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;Doxycyline&#39;</span>,<span class="dv">30</span>), <span class="kw">rep</span>(<span class="st">&#39;Placebo&#39;</span>,<span class="dv">28</span>)),
  <span class="dt">Outcome=</span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;Conceived&#39;</span>,<span class="dv">5</span>), <span class="kw">rep</span>(<span class="st">&#39;Not Conceived&#39;</span>,<span class="dv">25</span>),
            <span class="kw">rep</span>(<span class="st">&#39;Conceived&#39;</span>,<span class="dv">4</span>), <span class="kw">rep</span>(<span class="st">&#39;Not Conceived&#39;</span>,<span class="dv">24</span>)))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the CrossTable function to generate the Expected Cell values</span>
descr<span class="op">::</span><span class="kw">CrossTable</span>(<span class="kw">table</span>(Conceived), <span class="dt">expected=</span><span class="ot">TRUE</span>, 
                  <span class="dt">prop.r=</span><span class="ot">FALSE</span>, <span class="dt">prop.c=</span><span class="ot">FALSE</span>, <span class="dt">prop.t=</span><span class="ot">FALSE</span>, <span class="dt">prop.chisq=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>##    Cell Contents 
## |-------------------------|
## |                       N | 
## |              Expected N | 
## |-------------------------|
## 
## ===============================================
##               Outcome
## Treatment     Conceived   Not Conceived   Total
## -----------------------------------------------
## Doxycyline            5              25      30
##                     4.7            25.3        
## -----------------------------------------------
## Placebo               4              24      28
##                     4.3            23.7        
## -----------------------------------------------
## Total                 9              49      58
## ===============================================</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>( <span class="kw">table</span>(Conceived), <span class="dt">simulate.p.value=</span><span class="ot">TRUE</span>, <span class="dt">B=</span><span class="dv">10000</span> )</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with simulated p-value (based on 10000
##  replicates)
## 
## data:  table(Conceived)
## X-squared = 0.062628, df = NA, p-value = 1</code></pre>
</div>
<div id="rxc-tables" class="section level2">
<h2><span class="header-section-number">12.3</span> RxC tables</h2>
<p>We next expand this same analysis to consider cases where we have explanatory variable with <span class="math inline">\(C\)</span> levels and the response variable has <span class="math inline">\(R\)</span> levels, and so the table of observations has <span class="math inline">\(R\)</span> rows and <span class="math inline">\(C\)</span> columns.</p>
<p>There was nothing special about the analysis that required only 2x2 tables. Expanding this the expected value for the <span class="math inline">\(i,j\)</span> cell in the table is still <span class="math display">\[E_{ij} = \frac{n_{i\cdot} n_{\cdot j}}{n}\]</span></p>
<p>As before we define the test statistic as <span class="math display">\[\begin{aligned}X^{2}  
  &amp;=    \sum_{\textrm{all ij cells}}\frac{\left(O_{ij}-E_{ij}\right)^{2}}{E_{ij}}
  \end{aligned}\]</span></p>
<p>If we have sufficient samples sizes in each cell (general rule-of-thumb is greater than 5 per cell), then we could compare this test statistic to a Chi-Squared distribution with <span class="math inline">\((R-1)(C-1)\)</span> degrees of freedom. <span class="math display">\[p.value = Pr( \chi_{(r-1)(c-1)} &gt; X^2 )\]</span></p>
<p>We consider some data from the American Community Survey, which is a survey administered by the US Census Bureau and given to approximately 3% of all US households. The package <code>Lock5Data</code> has a dataset, <code>ACS</code>, which is a sub-sample of <span class="math inline">\(n=1000\)</span> respondents of that 2010 survey. In particular, we want to examine the relationship between race and marriage status. In particular if white respondents are more likely to be married than Asian or black (or other) races.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(ACS, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)
ACS &lt;-<span class="st"> </span>ACS <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Married =</span> <span class="kw">ifelse</span>(Married<span class="op">==</span><span class="dv">1</span>, <span class="st">&#39;Married&#39;</span>,<span class="st">&#39;Single&#39;</span>))
tab &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">tally</span>(Married <span class="op">~</span><span class="st"> </span>Race, <span class="dt">data=</span>ACS)
tab</code></pre></div>
<pre><code>##          Race
## Married   asian black other white
##   Married    37    25    20   355
##   Single     33    81    43   406</code></pre>
<p>Often I find it is difficult to really understand a table and find a good graph more insightful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp &lt;-<span class="st"> </span>ACS <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Race, Married) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">count</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(Race) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">proportion =</span> n<span class="op">/</span><span class="kw">sum</span>(n))
<span class="kw">ggplot</span>(temp, <span class="kw">aes</span>(<span class="dt">x=</span>Race, <span class="dt">y=</span>proportion, <span class="dt">fill=</span>Married)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&#39;identity&#39;</span>)</code></pre></div>
<p><img src="12_ContingencyTables_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the CrossTable function to generate the Expected Cell values</span>
descr<span class="op">::</span><span class="kw">CrossTable</span>(tab, <span class="dt">expected=</span><span class="ot">TRUE</span>, 
                  <span class="dt">prop.r=</span><span class="ot">FALSE</span>, <span class="dt">prop.c=</span><span class="ot">FALSE</span>, <span class="dt">prop.t=</span><span class="ot">FALSE</span>, <span class="dt">prop.chisq=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>##    Cell Contents 
## |-------------------------|
## |                       N | 
## |              Expected N | 
## |-------------------------|
## 
## ================================================
##            Race
## Married    asian   black   other   white   Total
## ------------------------------------------------
## Married       37      25      20     355     437
##             30.6    46.3    27.5   332.6        
## ------------------------------------------------
## Single        33      81      43     406     563
##             39.4    59.7    35.5   428.4        
## ------------------------------------------------
## Total         70     106      63     761    1000
## ================================================</code></pre>
<p>Because the cell counts are quite large, the asymptotic approximations should be fine. We will compare the test statistic against a Chi-squared distribution with <span class="math inline">\((2-1)(4-1)=1*3=3\)</span> degrees of freedom.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">26.168</span>, <span class="dt">df=</span><span class="dv">3</span>)</code></pre></div>
<pre><code>## [1] 8.795319e-06</code></pre>
<p>therefore <span class="math display">\[p.value = Pr( \chi^2_3 &gt; 26.168 ) = 8.795\textrm{e-}06\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>( tab )</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab
## X-squared = 26.168, df = 3, p-value = 8.797e-06</code></pre>
<p>If we are worried about the sample size begin large enough, we could perform a permutation based test by repeatedly shuffling the <code>Race</code> labels calculating the test statistic and then comparing the observed test statistic <span class="math inline">\(X^2=26.168\)</span> to the permutation</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>( tab, <span class="dt">simulate.p.value=</span><span class="ot">TRUE</span>, <span class="dt">B=</span><span class="dv">100000</span> )</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with simulated p-value (based on 1e+05
##  replicates)
## 
## data:  tab
## X-squared = 26.168, df = NA, p-value = 2e-05</code></pre>
<p>With such a small p-value, we know that we are unlikely to have observed such a large difference in marriage rates among our different races. It appears that white respondents are much more likely to be married than the other races listed, but is there a difference in rates between blacks and Asians? What about Asian and other?</p>
<p>Just as we wanted to perform an analysis on all pairwise comparisons among levels in an ANOVA analysis and control the overall Type I error rate, we will do the same thing but now using the Chi-squared test.</p>
<p>Conceptually we will just perform all possible pairwise tests and then adjust the resulting p-values to control for the number of comparisons.</p>
</div>
</div>
<div id="r-we-will-use-a-function-from-the-package-fifer-chisq.post.hoc-wants-the-table-arranged-with-the-factor-you-want-to-pairwise-contasts-as-the-rows-t-tab-transpose-the-rows-and-columns-result---fiferchisq.post.hoc-ttab-testchisq.test-simulate.p.valuetrue-b10000-result" class="section level1">
<h1><span class="header-section-number">13</span> <code>{r} # # # We will use a function from the package fifer # # # chisq.post.hoc  wants the table arranged with the  # # # factor you want to pairwise contasts as the rows # # t( tab )   # transpose the rows and columns # # result &lt;- fifer::chisq.post.hoc( t(tab), # #     test=chisq.test, simulate.p.value=TRUE, B=10000 )  # # result #</code></h1>
</div>
<div id="r-we-really-want-to-get-the-compact-letter-display-for-graphing-purposes-but-there-is-some-annoying-details-that-we-really-ought-not-have-to-think-about.-so-lets-make-a-little-function-to-handle-this-stuff.-librarydplyr-librarystringr-librarymultcompview-cld.chisq.post.hoc---function-obj-name-p.values---objadj.p-just-the-p-values-contrasts---objcomparison-as.character-str_replace-patternfixed-vs.-replacement-fixed--namesp.values---contrasts-finally-we-can-pass-p.values-into-a-letters-function-my.letters---multcompviewmultcomplettersp.values-letter.df---data.frame-tempnamesmy.lettersletters-.group-my.lettersletters-colnamesletter.df1---name-rownamesletter.df---null-returnletter.df" class="section level1">
<h1><span class="header-section-number">14</span> <code>{r} # # We really want to get the compact letter display for  # # graphing purposes, but there is some annoying details # # that we really ought not have to think about.  So lets # # make a little function to handle this stuff. # library(dplyr) # library(stringr) # library(multcompView) # # cld.chisq.post.hoc &lt;- function( obj, name ){ # #   p.values &lt;- obj$adj.p                # just the p-values # #   contrasts &lt;- obj$comparison %&gt;% # #     as.character( ) %&gt;% # #     str_replace( pattern=fixed(' vs. '), replacement = fixed('-')) # #   names(p.values) &lt;- contrasts # #  # #   # finally we can pass p.values into a letters function # #   my.letters &lt;- multcompView::multcompLetters(p.values) # #   letter.df &lt;- data.frame( TEMP=names(my.letters$Letters),  # #                            .group = my.letters$Letters )  # #   colnames(letter.df)[1] &lt;- name # #   rownames(letter.df) &lt;- NULL # #   return(letter.df) # # }   #</code></h1>
</div>
<div id="r-cld.chisq.post.hocresult-race" class="section level1">
<h1><span class="header-section-number">15</span> <code>{r} # cld.chisq.post.hoc(result, 'Race') #</code></h1>
<p>There are a number of other questions that I might consider, such as confidence intervals for the proportions married in each race. However, those questions require a few more assumptions about the structure of the data and will be addressed when we study logistic regression.</p>
<div id="exercises-11" class="section level2">
<h2><span class="header-section-number">15.1</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>Is gender independent of education level? A random sample of <span class="math inline">\(n=501\)</span> people were surveyed and each person was asked to report the highest education level they obtained. The data that resulted from the survey is summarized in the following table:</p>
<table>
<colgroup>
<col width="16%" />
<col width="21%" />
<col width="19%" />
<col width="15%" />
<col width="17%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">&lt;= High School</th>
<th align="center">Some College</th>
<th align="center">Bachelors</th>
<th align="center">Adv. Degree</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Male</strong></td>
<td align="center">96</td>
<td align="center">72</td>
<td align="center">59</td>
<td align="center">34</td>
<td align="center">261</td>
</tr>
<tr class="even">
<td align="center"><strong>Female</strong></td>
<td align="center">56</td>
<td align="center">78</td>
<td align="center">67</td>
<td align="center">39</td>
<td align="center">240</td>
</tr>
<tr class="odd">
<td align="center"><strong>Total</strong></td>
<td align="center">152</td>
<td align="center">150</td>
<td align="center">126</td>
<td align="center">73</td>
<td align="center">501</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>Calculate the expected cell counts for each Gender and Degree combination.</li>
<li>Calculate the <span class="math inline">\(X^2\)</span> test statistic.</li>
<li>Calculate the appropriate p-value using the asymptotic approximation and interprete the results in terms of the problem.</li>
<li>Double check your hand-calculations using the <code>chisq.test()</code> function in R.</li>
</ol></li>
<li><p>We consider some data from the American Community Survey, which is a survey administered by the US Census Bureau and given to approximately 3% of all US households. The package <code>Lock5Data</code> has a dataset, <code>ACS</code>, which is a sub-sample of <span class="math inline">\(n=1000\)</span> respondents of that 2010 survey. In particular, we want to examine the relationship between race and having health insurance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(ACS, <span class="dt">package=</span><span class="st">&#39;Lock5Data&#39;</span>)
temp &lt;-<span class="st"> </span>ACS <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HealthInsurance =</span> <span class="kw">factor</span>(<span class="kw">ifelse</span>(HealthInsurance <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Have&quot;</span>,<span class="st">&quot;None&quot;</span>)),
         <span class="dt">Race =</span> <span class="kw">factor</span>(Race, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&#39;white&#39;</span>,<span class="st">&#39;asian&#39;</span>,<span class="st">&#39;black&#39;</span>,<span class="st">&#39;other&#39;</span>) ) ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(Race, HealthInsurance) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">count</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(Race) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">proportion =</span> n<span class="op">/</span><span class="kw">sum</span>(n))
<span class="kw">ggplot</span>(temp, <span class="kw">aes</span>(<span class="dt">x=</span>Race, <span class="dt">y=</span>proportion, <span class="dt">fill=</span>HealthInsurance)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&#39;identity&#39;</span>)</code></pre></div>
<p><img src="12_ContingencyTables_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<ol style="list-style-type: lower-alpha">
<li>Generate a table summarizing how many respondents of each race has health insurance.</li>
<li>Test the hypothesis that there is no association between race and having health insurance using both the asymptotic method and the permutation method. Is your inference the same in both cases?</li>
<li>Establish which racial groups are different in the proportion of respondents that have health insurance.</li>
</ol></li>
</ol>
<!--chapter:end:12_ContingencyTables.Rmd-->
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Actually this isn’t true as both gender and sex are far more complex. However from a statistical point of view it is often useful to simplify our model of the world. George Box famously said, “All models are wrong, but some are useful.”<a href="#fnref1">↩</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
